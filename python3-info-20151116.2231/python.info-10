This is python.info, produced by makeinfo version 5.2 from python.texi.

     Python 3.4.3, September 02, 2015

     Copyright © 1990-2015, Python Software Foundation

INFO-DIR-SECTION Python
START-INFO-DIR-ENTRY
* Python: (python.info). The Python reference manual.
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.3.1.


File: python.info,  Node: Ranges,  Prev: Tuples,  Up: Sequence Types --- list tuple range

5.4.6.6 Ranges
..............

The *note range: 396. type represents an immutable sequence of numbers
and is commonly used for looping a specific number of times in *note
for: 688. loops.

 -- Class: range (stop)

 -- Class: range (start, stop[, step])

     The arguments to the range constructor must be integers (either
     built-in *note int: 185. or any object that implements the
     ‘__index__’ special method).  If the `step' argument is omitted, it
     defaults to ‘1’.  If the `start' argument is omitted, it defaults
     to ‘0’.  If `step' is zero, *note ValueError: 321. is raised.

     For a positive `step', the contents of a range ‘r’ are determined
     by the formula ‘r[i] = start + step*i’ where ‘i >= 0’ and ‘r[i] <
     stop’.

     For a negative `step', the contents of the range are still
     determined by the formula ‘r[i] = start + step*i’, but the
     constraints are ‘i >= 0’ and ‘r[i] > stop’.

     A range object will be empty if ‘r[0]’ does not meet the value
     constraint.  Ranges do support negative indices, but these are
     interpreted as indexing from the end of the sequence determined by
     the positive indices.

     Ranges containing absolute values larger than *note sys.maxsize:
     56b. are permitted but some features (such as *note len(): 358.)
     may raise *note OverflowError: 325.

     Range examples:

          >>> list(range(10))
          [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
          >>> list(range(1, 11))
          [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
          >>> list(range(0, 30, 5))
          [0, 5, 10, 15, 20, 25]
          >>> list(range(0, 10, 3))
          [0, 3, 6, 9]
          >>> list(range(0, -10, -1))
          [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
          >>> list(range(0))
          []
          >>> list(range(1, 0))
          []

     Ranges implement all of the *note common: dd3. sequence operations
     except concatenation and repetition (due to the fact that range
     objects can only represent sequences that follow a strict pattern
     and repetition and concatenation will usually violate that
     pattern).

The advantage of the *note range: 396. type over a regular *note list:
397. or *note tuple: 84e. is that a *note range: 396. object will always
take the same (small) amount of memory, no matter the size of the range
it represents (as it only stores the ‘start’, ‘stop’ and ‘step’ values,
calculating individual items and subranges as needed).

Range objects implement the *note collections.abc.Sequence: dd5. ABC,
and provide features such as containment tests, element index lookup,
slicing and support for negative indices (see *note Sequence Types —
list, tuple, range: a5f.):

     >>> r = range(0, 20, 2)
     >>> r
     range(0, 20, 2)
     >>> 11 in r
     False
     >>> 10 in r
     True
     >>> r.index(10)
     5
     >>> r[5]
     10
     >>> r[:5]
     range(0, 10, 2)
     >>> r[-1]
     18

Testing range objects for equality with ‘==’ and ‘!=’ compares them as
sequences.  That is, two range objects are considered equal if they
represent the same sequence of values.  (Note that two range objects
that compare equal might have different ‘start’, ‘stop’ and ‘step’
attributes, for example ‘range(0) == range(2, 1, 3)’ or ‘range(0, 3, 2)
== range(0, 4, 2)’.)

Changed in version 3.2: Implement the Sequence ABC. Support slicing and
negative indices.  Test *note int: 185. objects for membership in
constant time instead of iterating through all items.

Changed in version 3.3: Define ’==’ and ’!=’ to compare range objects
based on the sequence of values they define (instead of comparing based
on object identity).

New in version 3.3: The ‘start’, ‘stop’ and ‘step’ attributes.


File: python.info,  Node: Text Sequence Type --- str,  Next: Binary Sequence Types --- bytes bytearray memoryview,  Prev: Sequence Types --- list tuple range,  Up: Built-in Types

5.4.7 Text Sequence Type — ‘str’
--------------------------------

Textual data in Python is handled with *note str: 178. objects, or
`strings'.  Strings are immutable *note sequences: a5f. of Unicode code
points.  String literals are written in a variety of ways:

   * Single quotes: ‘'allows embedded "double" quotes'’

   * Double quotes: ‘"allows embedded 'single' quotes"’.

   * Triple quoted: ‘'''Three single quotes'''’, ‘"""Three double
     quotes"""’

Triple quoted strings may span multiple lines - all associated
whitespace will be included in the string literal.

String literals that are part of a single expression and have only
whitespace between them will be implicitly converted to a single string
literal.  That is, ‘("spam " "eggs") == "spam eggs"’.

See *note String and Bytes literals: bbb. for more about the various
forms of string literal, including supported escape sequences, and the
‘r’ ("raw") prefix that disables most escape sequence processing.

Strings may also be created from other objects using the *note str: 178.
constructor.

Since there is no separate "character" type, indexing a string produces
strings of length 1.  That is, for a non-empty string `s', ‘s[0] ==
s[0:1]’.

There is also no mutable string type, but *note str.join(): dd6. or
*note io.StringIO: 1b1. can be used to efficiently construct strings
from multiple fragments.

Changed in version 3.3: For backwards compatibility with the Python 2
series, the ‘u’ prefix is once again permitted on string literals.  It
has no effect on the meaning of string literals and cannot be combined
with the ‘r’ prefix.

 -- Class: str (object='')

 -- Class: str (object=b'', encoding='utf-8', errors='strict')

     Return a *note string: a16. version of `object'.  If `object' is
     not provided, returns the empty string.  Otherwise, the behavior of
     ‘str()’ depends on whether `encoding' or `errors' is given, as
     follows.

     If neither `encoding' nor `errors' is given, ‘str(object)’ returns
     *note object.__str__(): 8c6, which is the "informal" or nicely
     printable string representation of `object'.  For string objects,
     this is the string itself.  If `object' does not have a *note
     __str__(): 8c6. method, then *note str(): 178. falls back to
     returning *note repr(object): 3db.

     If at least one of `encoding' or `errors' is given, `object' should
     be a *note bytes-like object: 19f. (e.g.  *note bytes: 179. or
     *note bytearray: 17a.).  In this case, if `object' is a *note
     bytes: 179. (or *note bytearray: 17a.) object, then ‘str(bytes,
     encoding, errors)’ is equivalent to *note bytes.decode(encoding,
     errors): 691.  Otherwise, the bytes object underlying the buffer
     object is obtained before calling *note bytes.decode(): 691.  See
     *note Binary Sequence Types — bytes, bytearray, memoryview: d8d.
     and *note Buffer Protocol: ddf. for information on buffer objects.

     Passing a *note bytes: 179. object to *note str(): 178. without the
     `encoding' or `errors' arguments falls under the first case of
     returning the informal string representation (see also the *note
     -b: 737. command-line option to Python).  For example:

          >>> str(b'Zoot!')
          "b'Zoot!'"

     For more information on the ‘str’ class and its methods, see *note
     Text Sequence Type — str: a16. and the *note String Methods: a17.
     section below.  To output formatted strings, see the *note String
     Formatting: a18. section.  In addition, see the *note Text
     Processing Services: de0. section.

* Menu:

* String Methods: String Methods<2>. 
* printf-style String Formatting:: 


File: python.info,  Node: String Methods<2>,  Next: printf-style String Formatting,  Up: Text Sequence Type --- str

5.4.7.1 String Methods
......................

Strings implement all of the *note common: dd3. sequence operations,
along with the additional methods described below.

Strings also support two styles of string formatting, one providing a
large degree of flexibility and customization (see *note str.format():
557, *note Format String Syntax: 78a. and *note String Formatting: a18.)
and the other based on C ‘printf’ style formatting that handles a
narrower range of types and is slightly harder to use correctly, but is
often faster for the cases it can handle (*note printf-style String
Formatting: a19.).

The *note Text Processing Services: de2. section of the standard library
covers a number of other modules that provide various text related
utilities (including regular expression support in the *note re: d9.
module).

 -- Method: str.capitalize ()

     Return a copy of the string with its first character capitalized
     and the rest lowercased.

 -- Method: str.casefold ()

     Return a casefolded copy of the string.  Casefolded strings may be
     used for caseless matching.

     Casefolding is similar to lowercasing but more aggressive because
     it is intended to remove all case distinctions in a string.  For
     example, the German lowercase letter ‘'ß'’ is equivalent to ‘"ss"’.
     Since it is already lowercase, *note lower(): de4. would do nothing
     to ‘'ß'’; *note casefold(): 3a1. converts it to ‘"ss"’.

     The casefolding algorithm is described in section 3.13 of the
     Unicode Standard.

     New in version 3.3.

 -- Method: str.center (width[, fillchar])

     Return centered in a string of length `width'.  Padding is done
     using the specified `fillchar' (default is an ASCII space).  The
     original string is returned if `width' is less than or equal to
     ‘len(s)’.

 -- Method: str.count (sub[, start[, end]])

     Return the number of non-overlapping occurrences of substring `sub'
     in the range [`start', `end'].  Optional arguments `start' and
     `end' are interpreted as in slice notation.

 -- Method: str.encode (encoding="utf-8", errors="strict")

     Return an encoded version of the string as a bytes object.  Default
     encoding is ‘'utf-8'’.  `errors' may be given to set a different
     error handling scheme.  The default for `errors' is ‘'strict'’,
     meaning that encoding errors raise a *note UnicodeError: 696.
     Other possible values are ‘'ignore'’, ‘'replace'’,
     ‘'xmlcharrefreplace'’, ‘'backslashreplace'’ and any other name
     registered via *note codecs.register_error(): 87c, see section
     *note Error Handlers: da1.  For a list of possible encodings, see
     section *note Standard Encodings: 184.

     Changed in version 3.1: Support for keyword arguments added.

 -- Method: str.endswith (suffix[, start[, end]])

     Return ‘True’ if the string ends with the specified `suffix',
     otherwise return ‘False’.  `suffix' can also be a tuple of suffixes
     to look for.  With optional `start', test beginning at that
     position.  With optional `end', stop comparing at that position.

 -- Method: str.expandtabs (tabsize=8)

     Return a copy of the string where all tab characters are replaced
     by one or more spaces, depending on the current column and the
     given tab size.  Tab positions occur every `tabsize' characters
     (default is 8, giving tab positions at columns 0, 8, 16 and so on).
     To expand the string, the current column is set to zero and the
     string is examined character by character.  If the character is a
     tab (‘\t’), one or more space characters are inserted in the result
     until the current column is equal to the next tab position.  (The
     tab character itself is not copied.)  If the character is a newline
     (‘\n’) or return (‘\r’), it is copied and the current column is
     reset to zero.  Any other character is copied unchanged and the
     current column is incremented by one regardless of how the
     character is represented when printed.

          >>> '01\t012\t0123\t01234'.expandtabs()
          '01      012     0123    01234'
          >>> '01\t012\t0123\t01234'.expandtabs(4)
          '01  012 0123    01234'

 -- Method: str.find (sub[, start[, end]])

     Return the lowest index in the string where substring `sub' is
     found, such that `sub' is contained in the slice ‘s[start:end]’.
     Optional arguments `start' and `end' are interpreted as in slice
     notation.  Return ‘-1’ if `sub' is not found.

          Note: The *note find(): de8. method should be used only if you
          need to know the position of `sub'.  To check if `sub' is a
          substring or not, use the *note in: 6d5. operator:

               >>> 'Py' in 'Python'
               True

 -- Method: str.format (*args, **kwargs)

     Perform a string formatting operation.  The string on which this
     method is called can contain literal text or replacement fields
     delimited by braces ‘{}’.  Each replacement field contains either
     the numeric index of a positional argument, or the name of a
     keyword argument.  Returns a copy of the string where each
     replacement field is replaced with the string value of the
     corresponding argument.

          >>> "The sum of 1 + 2 is {0}".format(1+2)
          'The sum of 1 + 2 is 3'

     See *note Format String Syntax: 78a. for a description of the
     various formatting options that can be specified in format strings.

 -- Method: str.format_map (mapping)

     Similar to ‘str.format(**mapping)’, except that ‘mapping’ is used
     directly and not copied to a *note dict: 380.  This is useful if
     for example ‘mapping’ is a dict subclass:

          >>> class Default(dict):
          ...     def __missing__(self, key):
          ...         return key
          ...
          >>> '{name} was born in {country}'.format_map(Default(name='Guido'))
          'Guido was born in country'

     New in version 3.2.

 -- Method: str.index (sub[, start[, end]])

     Like *note find(): de8, but raise *note ValueError: 321. when the
     substring is not found.

 -- Method: str.isalnum ()

     Return true if all characters in the string are alphanumeric and
     there is at least one character, false otherwise.  A character ‘c’
     is alphanumeric if one of the following returns ‘True’:
     ‘c.isalpha()’, ‘c.isdecimal()’, ‘c.isdigit()’, or ‘c.isnumeric()’.

 -- Method: str.isalpha ()

     Return true if all characters in the string are alphabetic and
     there is at least one character, false otherwise.  Alphabetic
     characters are those characters defined in the Unicode character
     database as "Letter", i.e., those with general category property
     being one of "Lm", "Lt", "Lu", "Ll", or "Lo".  Note that this is
     different from the "Alphabetic" property defined in the Unicode
     Standard.

 -- Method: str.isdecimal ()

     Return true if all characters in the string are decimal characters
     and there is at least one character, false otherwise.  Decimal
     characters are those from general category "Nd".  This category
     includes digit characters, and all characters that can be used to
     form decimal-radix numbers, e.g.  U+0660, ARABIC-INDIC DIGIT ZERO.

 -- Method: str.isdigit ()

     Return true if all characters in the string are digits and there is
     at least one character, false otherwise.  Digits include decimal
     characters and digits that need special handling, such as the
     compatibility superscript digits.  Formally, a digit is a character
     that has the property value Numeric_Type=Digit or
     Numeric_Type=Decimal.

 -- Method: str.isidentifier ()

     Return true if the string is a valid identifier according to the
     language definition, section *note Identifiers and keywords: bac.

     Use *note keyword.iskeyword(): def. to test for reserved
     identifiers such as *note def: 841. and *note class: 6ce.

 -- Method: str.islower ()

     Return true if all cased characters (1) in the string are lowercase
     and there is at least one cased character, false otherwise.

 -- Method: str.isnumeric ()

     Return true if all characters in the string are numeric characters,
     and there is at least one character, false otherwise.  Numeric
     characters include digit characters, and all characters that have
     the Unicode numeric value property, e.g.  U+2155, VULGAR FRACTION
     ONE FIFTH. Formally, numeric characters are those with the property
     value Numeric_Type=Digit, Numeric_Type=Decimal or
     Numeric_Type=Numeric.

 -- Method: str.isprintable ()

     Return true if all characters in the string are printable or the
     string is empty, false otherwise.  Nonprintable characters are
     those characters defined in the Unicode character database as
     "Other" or "Separator", excepting the ASCII space (0x20) which is
     considered printable.  (Note that printable characters in this
     context are those which should not be escaped when *note repr():
     3db. is invoked on a string.  It has no bearing on the handling of
     strings written to *note sys.stdout: 1b0. or *note sys.stderr:
     5ac.)

 -- Method: str.isspace ()

     Return true if there are only whitespace characters in the string
     and there is at least one character, false otherwise.  Whitespace
     characters are those characters defined in the Unicode character
     database as "Other" or "Separator" and those with bidirectional
     property being one of "WS", "B", or "S".

 -- Method: str.istitle ()

     Return true if the string is a titlecased string and there is at
     least one character, for example uppercase characters may only
     follow uncased characters and lowercase characters only cased ones.
     Return false otherwise.

 -- Method: str.isupper ()

     Return true if all cased characters (2) in the string are uppercase
     and there is at least one cased character, false otherwise.

 -- Method: str.join (iterable)

     Return a string which is the concatenation of the strings in the
     *note iterable: 5f6. `iterable'.  A *note TypeError: 309. will be
     raised if there are any non-string values in `iterable', including
     *note bytes: 179. objects.  The separator between elements is the
     string providing this method.

 -- Method: str.ljust (width[, fillchar])

     Return the string left justified in a string of length `width'.
     Padding is done using the specified `fillchar' (default is an ASCII
     space).  The original string is returned if `width' is less than or
     equal to ‘len(s)’.

 -- Method: str.lower ()

     Return a copy of the string with all the cased characters (3)
     converted to lowercase.

     The lowercasing algorithm used is described in section 3.13 of the
     Unicode Standard.

 -- Method: str.lstrip ([chars])

     Return a copy of the string with leading characters removed.  The
     `chars' argument is a string specifying the set of characters to be
     removed.  If omitted or ‘None’, the `chars' argument defaults to
     removing whitespace.  The `chars' argument is not a prefix; rather,
     all combinations of its values are stripped:

          >>> '   spacious   '.lstrip()
          'spacious   '
          >>> 'www.example.com'.lstrip('cmowz.')
          'example.com'

 -- Static Method: str.maketrans (x[, y[, z]])

     This static method returns a translation table usable for *note
     str.translate(): df8.

     If there is only one argument, it must be a dictionary mapping
     Unicode ordinals (integers) or characters (strings of length 1) to
     Unicode ordinals, strings (of arbitrary lengths) or None.
     Character keys will then be converted to ordinals.

     If there are two arguments, they must be strings of equal length,
     and in the resulting dictionary, each character in x will be mapped
     to the character at the same position in y.  If there is a third
     argument, it must be a string, whose characters will be mapped to
     None in the result.

 -- Method: str.partition (sep)

     Split the string at the first occurrence of `sep', and return a
     3-tuple containing the part before the separator, the separator
     itself, and the part after the separator.  If the separator is not
     found, return a 3-tuple containing the string itself, followed by
     two empty strings.

 -- Method: str.replace (old, new[, count])

     Return a copy of the string with all occurrences of substring `old'
     replaced by `new'.  If the optional argument `count' is given, only
     the first `count' occurrences are replaced.

 -- Method: str.rfind (sub[, start[, end]])

     Return the highest index in the string where substring `sub' is
     found, such that `sub' is contained within ‘s[start:end]’.
     Optional arguments `start' and `end' are interpreted as in slice
     notation.  Return ‘-1’ on failure.

 -- Method: str.rindex (sub[, start[, end]])

     Like *note rfind(): dfb. but raises *note ValueError: 321. when the
     substring `sub' is not found.

 -- Method: str.rjust (width[, fillchar])

     Return the string right justified in a string of length `width'.
     Padding is done using the specified `fillchar' (default is an ASCII
     space).  The original string is returned if `width' is less than or
     equal to ‘len(s)’.

 -- Method: str.rpartition (sep)

     Split the string at the last occurrence of `sep', and return a
     3-tuple containing the part before the separator, the separator
     itself, and the part after the separator.  If the separator is not
     found, return a 3-tuple containing two empty strings, followed by
     the string itself.

 -- Method: str.rsplit (sep=None, maxsplit=-1)

     Return a list of the words in the string, using `sep' as the
     delimiter string.  If `maxsplit' is given, at most `maxsplit'
     splits are done, the `rightmost' ones.  If `sep' is not specified
     or ‘None’, any whitespace string is a separator.  Except for
     splitting from the right, *note rsplit(): dfe. behaves like *note
     split(): dff. which is described in detail below.

 -- Method: str.rstrip ([chars])

     Return a copy of the string with trailing characters removed.  The
     `chars' argument is a string specifying the set of characters to be
     removed.  If omitted or ‘None’, the `chars' argument defaults to
     removing whitespace.  The `chars' argument is not a suffix; rather,
     all combinations of its values are stripped:

          >>> '   spacious   '.rstrip()
          '   spacious'
          >>> 'mississippi'.rstrip('ipz')
          'mississ'

 -- Method: str.split (sep=None, maxsplit=-1)

     Return a list of the words in the string, using `sep' as the
     delimiter string.  If `maxsplit' is given, at most `maxsplit'
     splits are done (thus, the list will have at most ‘maxsplit+1’
     elements).  If `maxsplit' is not specified or ‘-1’, then there is
     no limit on the number of splits (all possible splits are made).

     If `sep' is given, consecutive delimiters are not grouped together
     and are deemed to delimit empty strings (for example,
     ‘'1,,2'.split(',')’ returns ‘['1', '', '2']’).  The `sep' argument
     may consist of multiple characters (for example,
     ‘'1<>2<>3'.split('<>')’ returns ‘['1', '2', '3']’).  Splitting an
     empty string with a specified separator returns ‘['']’.

     For example:

          >>> '1,2,3'.split(',')
          ['1', '2', '3']
          >>> '1,2,3'.split(',', maxsplit=1)
          ['1', '2,3']
          >>> '1,2,,3,'.split(',')
          ['1', '2', '', '3', '']

     If `sep' is not specified or is ‘None’, a different splitting
     algorithm is applied: runs of consecutive whitespace are regarded
     as a single separator, and the result will contain no empty strings
     at the start or end if the string has leading or trailing
     whitespace.  Consequently, splitting an empty string or a string
     consisting of just whitespace with a ‘None’ separator returns ‘[]’.

     For example:

          >>> '1 2 3'.split()
          ['1', '2', '3']
          >>> '1 2 3'.split(maxsplit=1)
          ['1', '2 3']
          >>> '   1   2   3   '.split()
          ['1', '2', '3']

 -- Method: str.splitlines ([keepends])

     Return a list of the lines in the string, breaking at line
     boundaries.  This method uses the *note universal newlines: 794.
     approach to splitting lines.  Line breaks are not included in the
     resulting list unless `keepends' is given and true.

     For example:

          >>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
          ['ab c', '', 'de fg', 'kl']
          >>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
          ['ab c\n', '\n', 'de fg\r', 'kl\r\n']

     Unlike *note split(): dff. when a delimiter string `sep' is given,
     this method returns an empty list for the empty string, and a
     terminal line break does not result in an extra line:

          >>> "".splitlines()
          []
          >>> "One line\n".splitlines()
          ['One line']

     For comparison, ‘split('\n')’ gives:

          >>> ''.split('\n')
          ['']
          >>> 'Two lines\n'.split('\n')
          ['Two lines', '']

 -- Method: str.startswith (prefix[, start[, end]])

     Return ‘True’ if string starts with the `prefix', otherwise return
     ‘False’.  `prefix' can also be a tuple of prefixes to look for.
     With optional `start', test string beginning at that position.
     With optional `end', stop comparing string at that position.

 -- Method: str.strip ([chars])

     Return a copy of the string with the leading and trailing
     characters removed.  The `chars' argument is a string specifying
     the set of characters to be removed.  If omitted or ‘None’, the
     `chars' argument defaults to removing whitespace.  The `chars'
     argument is not a prefix or suffix; rather, all combinations of its
     values are stripped:

          >>> '   spacious   '.strip()
          'spacious'
          >>> 'www.example.com'.strip('cmowz.')
          'example'

 -- Method: str.swapcase ()

     Return a copy of the string with uppercase characters converted to
     lowercase and vice versa.  Note that it is not necessarily true
     that ‘s.swapcase().swapcase() == s’.

 -- Method: str.title ()

     Return a titlecased version of the string where words start with an
     uppercase character and the remaining characters are lowercase.

     For example:

          >>> 'Hello world'.title()
          'Hello World'

     The algorithm uses a simple language-independent definition of a
     word as groups of consecutive letters.  The definition works in
     many contexts but it means that apostrophes in contractions and
     possessives form word boundaries, which may not be the desired
     result:

          >>> "they're bill's friends from the UK".title()
          "They'Re Bill'S Friends From The Uk"

     A workaround for apostrophes can be constructed using regular
     expressions:

          >>> import re
          >>> def titlecase(s):
          ...     return re.sub(r"[A-Za-z]+('[A-Za-z]+)?",
          ...                   lambda mo: mo.group(0)[0].upper() +
          ...                              mo.group(0)[1:].lower(),
          ...                   s)
          ...
          >>> titlecase("they're bill's friends.")
          "They're Bill's Friends."

 -- Method: str.translate (map)

     Return a copy of the `s' where all characters have been mapped
     through the `map' which must be a dictionary of Unicode ordinals
     (integers) to Unicode ordinals, strings or ‘None’.  Unmapped
     characters are left untouched.  Characters mapped to ‘None’ are
     deleted.

     You can use *note str.maketrans(): df7. to create a translation map
     from character-to-character mappings in different formats.

          Note: An even more flexible approach is to create a custom
          character mapping codec using the *note codecs: 1c. module
          (see ‘encodings.cp1251’ for an example).

 -- Method: str.upper ()

     Return a copy of the string with all the cased characters (4)
     converted to uppercase.  Note that ‘str.upper().isupper()’ might be
     ‘False’ if ‘s’ contains uncased characters or if the Unicode
     category of the resulting character(s) is not "Lu" (Letter,
     uppercase), but e.g.  "Lt" (Letter, titlecase).

     The uppercasing algorithm used is described in section 3.13 of the
     Unicode Standard.

 -- Method: str.zfill (width)

     Return a copy of the string left filled with ASCII ‘'0'’ digits to
     make a string of length `width'.  A leading sign prefix
     (‘'+'’/‘'-'’ is handled by inserting the padding `after' the sign
     character rather than before.  The original string is returned if
     `width' is less than or equal to ‘len(s)’.

     For example:

          >>> "42".zfill(5)
          '00042'
          >>> "-42".zfill(5)
          '-0042'

   ---------- Footnotes ----------

   (1) Cased characters are those with general category property being
one of "Lu" (Letter, uppercase), "Ll" (Letter, lowercase), or "Lt"
(Letter, titlecase).

   (2) Cased characters are those with general category property being
one of "Lu" (Letter, uppercase), "Ll" (Letter, lowercase), or "Lt"
(Letter, titlecase).

   (3) Cased characters are those with general category property being
one of "Lu" (Letter, uppercase), "Ll" (Letter, lowercase), or "Lt"
(Letter, titlecase).

   (4) Cased characters are those with general category property being
one of "Lu" (Letter, uppercase), "Ll" (Letter, lowercase), or "Lt"
(Letter, titlecase).


File: python.info,  Node: printf-style String Formatting,  Prev: String Methods<2>,  Up: Text Sequence Type --- str

5.4.7.2 ‘printf’-style String Formatting
........................................

     Note: The formatting operations described here exhibit a variety of
     quirks that lead to a number of common errors (such as failing to
     display tuples and dictionaries correctly).  Using the newer *note
     str.format(): 557. interface helps avoid these errors, and also
     provides a generally more powerful, flexible and extensible
     approach to formatting text.

String objects have one unique built-in operation: the ‘%’ operator
(modulo).  This is also known as the string `formatting' or
`interpolation' operator.  Given ‘format % values’ (where `format' is a
string), ‘%’ conversion specifications in `format' are replaced with
zero or more elements of `values'.  The effect is similar to using the
‘sprintf()’ in the C language.

If `format' requires a single argument, `values' may be a single
non-tuple object.  (1) Otherwise, `values' must be a tuple with exactly
the number of items specified by the format string, or a single mapping
object (for example, a dictionary).

A conversion specifier contains two or more characters and has the
following components, which must occur in this order:

  1. The ‘'%'’ character, which marks the start of the specifier.

  2. Mapping key (optional), consisting of a parenthesised sequence of
     characters (for example, ‘(somename)’).

  3. Conversion flags (optional), which affect the result of some
     conversion types.

  4. Minimum field width (optional).  If specified as an ‘'*'’
     (asterisk), the actual width is read from the next element of the
     tuple in `values', and the object to convert comes after the
     minimum field width and optional precision.

  5. Precision (optional), given as a ‘'.'’ (dot) followed by the
     precision.  If specified as ‘'*'’ (an asterisk), the actual
     precision is read from the next element of the tuple in `values',
     and the value to convert comes after the precision.

  6. Length modifier (optional).

  7. Conversion type.

When the right argument is a dictionary (or other mapping type), then
the formats in the string `must' include a parenthesised mapping key
into that dictionary inserted immediately after the ‘'%'’ character.
The mapping key selects the value to be formatted from the mapping.  For
example:

     >>> print('%(language)s has %(number)03d quote types.' %
     ...       {'language': "Python", "number": 2})
     Python has 002 quote types.

In this case no ‘*’ specifiers may occur in a format (since they require
a sequential parameter list).

The conversion flag characters are:

Flag          Meaning
              
----------------------------------------------------------------------------------------
              
‘'#'’         The value conversion will use the "alternate form" (where defined
              below).
              
              
‘'0'’         The conversion will be zero padded for numeric values.
              
              
‘'-'’         The converted value is left adjusted (overrides the ‘'0'’ conversion if
              both are given).
              
              
‘' '’         (a space) A blank should be left before a positive number (or empty
              string) produced by a signed conversion.
              
              
‘'+'’         A sign character (‘'+'’ or ‘'-'’) will precede the conversion
              (overrides a "space" flag).
              

A length modifier (‘h’, ‘l’, or ‘L’) may be present, but is ignored as
it is not necessary for Python – so e.g.  ‘%ld’ is identical to ‘%d’.

The conversion types are:

Conversion       Meaning                                                   Notes
                                                                           
---------------------------------------------------------------------------------------
                                                                           
‘'d'’            Signed integer decimal.
                 
                                                                           
‘'i'’            Signed integer decimal.
                 
                                                                           
‘'o'’            Signed octal value.                                       (1)
                                                                           
                                                                           
‘'u'’            Obsolete type – it is identical to ‘'d'’.                 (7)
                                                                           
                                                                           
‘'x'’            Signed hexadecimal (lowercase).                           (2)
                                                                           
                                                                           
‘'X'’            Signed hexadecimal (uppercase).                           (2)
                                                                           
                                                                           
‘'e'’            Floating point exponential format (lowercase).            (3)
                                                                           
                                                                           
‘'E'’            Floating point exponential format (uppercase).            (3)
                                                                           
                                                                           
‘'f'’            Floating point decimal format.                            (3)
                                                                           
                                                                           
‘'F'’            Floating point decimal format.                            (3)
                                                                           
                                                                           
‘'g'’            Floating point format.  Uses lowercase exponential        (4)
                 format if exponent is less than -4 or not less than       
                 precision, decimal format otherwise.
                 
                                                                           
‘'G'’            Floating point format.  Uses uppercase exponential        (4)
                 format if exponent is less than -4 or not less than       
                 precision, decimal format otherwise.
                 
                                                                           
‘'c'’            Single character (accepts integer or single character
                 string).
                 
                                                                           
‘'r'’            String (converts any Python object using *note repr():    (5)
                 3db.).                                                    
                 
                                                                           
‘'s'’            String (converts any Python object using *note str():     (5)
                 178.).                                                    
                 
                                                                           
‘'a'’            String (converts any Python object using *note ascii():   (5)
                 7c8.).                                                    
                 
                                                                           
‘'%'’            No argument is converted, results in a ‘'%'’ character
                 in the result.
                 

Notes:

  1. The alternate form causes a leading zero (‘'0'’) to be inserted
     between left-hand padding and the formatting of the number if the
     leading character of the result is not already a zero.

  2. The alternate form causes a leading ‘'0x'’ or ‘'0X'’ (depending on
     whether the ‘'x'’ or ‘'X'’ format was used) to be inserted between
     left-hand padding and the formatting of the number if the leading
     character of the result is not already a zero.

  3. The alternate form causes the result to always contain a decimal
     point, even if no digits follow it.

     The precision determines the number of digits after the decimal
     point and defaults to 6.

  4. The alternate form causes the result to always contain a decimal
     point, and trailing zeroes are not removed as they would otherwise
     be.

     The precision determines the number of significant digits before
     and after the decimal point and defaults to 6.

  5. If precision is ‘N’, the output is truncated to ‘N’ characters.

  7. See PEP 237(2).

Since Python strings have an explicit length, ‘%s’ conversions do not
assume that ‘'\0'’ is the end of the string.

Changed in version 3.1: ‘%f’ conversions for numbers whose absolute
value is over 1e50 are no longer replaced by ‘%g’ conversions.

   ---------- Footnotes ----------

   (1) To format only a tuple you should therefore provide a singleton
tuple whose only element is the tuple to be formatted.

   (2) https://www.python.org/dev/peps/pep-0237


File: python.info,  Node: Binary Sequence Types --- bytes bytearray memoryview,  Next: Set Types --- set frozenset,  Prev: Text Sequence Type --- str,  Up: Built-in Types

5.4.8 Binary Sequence Types — ‘bytes’, ‘bytearray’, ‘memoryview’
----------------------------------------------------------------

The core built-in types for manipulating binary data are *note bytes:
179. and *note bytearray: 17a.  They are supported by *note memoryview:
187. which uses the *note buffer protocol: ddf. to access the memory of
other binary objects without needing to make a copy.

The *note array: 7. module supports efficient storage of basic data
types like 32-bit integers and IEEE754 double-precision floating values.

* Menu:

* Bytes:: 
* Bytearray Objects:: 
* Bytes and Bytearray Operations:: 
* Memory Views:: 


File: python.info,  Node: Bytes,  Next: Bytearray Objects,  Up: Binary Sequence Types --- bytes bytearray memoryview

5.4.8.1 Bytes
.............

Bytes objects are immutable sequences of single bytes.  Since many major
binary protocols are based on the ASCII text encoding, bytes objects
offer several methods that are only valid when working with ASCII
compatible data and are closely related to string objects in a variety
of other ways.

Firstly, the syntax for bytes literals is largely the same as that for
string literals, except that a ‘b’ prefix is added:

   * Single quotes: ‘b'still allows embedded "double" quotes'’

   * Double quotes: ‘b"still allows embedded 'single' quotes"’.

   * Triple quoted: ‘b'''3 single quotes'''’, ‘b"""3 double quotes"""’

Only ASCII characters are permitted in bytes literals (regardless of the
declared source code encoding).  Any binary values over 127 must be
entered into bytes literals using the appropriate escape sequence.

As with string literals, bytes literals may also use a ‘r’ prefix to
disable processing of escape sequences.  See *note String and Bytes
literals: bbb. for more about the various forms of bytes literal,
including supported escape sequences.

While bytes literals and representations are based on ASCII text, bytes
objects actually behave like immutable sequences of integers, with each
value in the sequence restricted such that ‘0 <= x < 256’ (attempts to
violate this restriction will trigger *note ValueError: 321.  This is
done deliberately to emphasise that while many binary formats include
ASCII based elements and can be usefully manipulated with some
text-oriented algorithms, this is not generally the case for arbitrary
binary data (blindly applying text processing algorithms to binary data
formats that are not ASCII compatible will usually lead to data
corruption).

In addition to the literal forms, bytes objects can be created in a
number of other ways:

   * A zero-filled bytes object of a specified length: ‘bytes(10)’

   * From an iterable of integers: ‘bytes(range(20))’

   * Copying existing binary data via the buffer protocol: ‘bytes(obj)’

Also see the *note bytes: d8f. built-in.

Since 2 hexadecimal digits correspond precisely to a single byte,
hexadecimal numbers are a commonly used format for describing binary
data.  Accordingly, the bytes type has an additional class method to
read data in that format:

 -- Class Method: bytes.fromhex (string)

     This *note bytes: 179. class method returns a bytes object,
     decoding the given string object.  The string must contain two
     hexadecimal digits per byte, with ASCII spaces being ignored.

          >>> bytes.fromhex('2Ef0 F1f2  ')
          b'.\xf0\xf1\xf2'

Since bytes objects are sequences of integers (akin to a tuple), for a
bytes object `b', ‘b[0]’ will be an integer, while ‘b[0:1]’ will be a
bytes object of length 1.  (This contrasts with text strings, where both
indexing and slicing will produce a string of length 1)

The representation of bytes objects uses the literal format (‘b'...'’)
since it is often more useful than e.g.  ‘bytes([46, 46, 46])’.  You can
always convert a bytes object into a list of integers using ‘list(b)’.

     Note: For Python 2.x users: In the Python 2.x series, a variety of
     implicit conversions between 8-bit strings (the closest thing 2.x
     offers to a built-in binary data type) and Unicode strings were
     permitted.  This was a backwards compatibility workaround to
     account for the fact that Python originally only supported 8-bit
     text, and Unicode text was a later addition.  In Python 3.x, those
     implicit conversions are gone - conversions between 8-bit binary
     data and Unicode text must be explicit, and bytes and string
     objects will always compare unequal.


File: python.info,  Node: Bytearray Objects,  Next: Bytes and Bytearray Operations,  Prev: Bytes,  Up: Binary Sequence Types --- bytes bytearray memoryview

5.4.8.2 Bytearray Objects
.........................

*note bytearray: 17a. objects are a mutable counterpart to *note bytes:
179. objects.  There is no dedicated literal syntax for bytearray
objects, instead they are always created by calling the constructor:

   * Creating an empty instance: ‘bytearray()’

   * Creating a zero-filled instance with a given length:
     ‘bytearray(10)’

   * From an iterable of integers: ‘bytearray(range(20))’

   * Copying existing binary data via the buffer protocol:
     ‘bytearray(b'Hi!')’

As bytearray objects are mutable, they support the *note mutable: d8b.
sequence operations in addition to the common bytes and bytearray
operations described in *note Bytes and Bytearray Operations: d8c.

Also see the *note bytearray: d8a. built-in.

Since 2 hexadecimal digits correspond precisely to a single byte,
hexadecimal numbers are a commonly used format for describing binary
data.  Accordingly, the bytearray type has an additional class method to
read data in that format:

 -- Class Method: bytearray.fromhex (string)

     This *note bytearray: 17a. class method returns bytearray object,
     decoding the given string object.  The string must contain two
     hexadecimal digits per byte, with ASCII spaces being ignored.

          >>> bytearray.fromhex('2Ef0 F1f2  ')
          bytearray(b'.\xf0\xf1\xf2')

Since bytearray objects are sequences of integers (akin to a list), for
a bytearray object `b', ‘b[0]’ will be an integer, while ‘b[0:1]’ will
be a bytearray object of length 1.  (This contrasts with text strings,
where both indexing and slicing will produce a string of length 1)

The representation of bytearray objects uses the bytes literal format
(‘bytearray(b'...')’) since it is often more useful than e.g.
‘bytearray([46, 46, 46])’.  You can always convert a bytearray object
into a list of integers using ‘list(b)’.


File: python.info,  Node: Bytes and Bytearray Operations,  Next: Memory Views,  Prev: Bytearray Objects,  Up: Binary Sequence Types --- bytes bytearray memoryview

5.4.8.3 Bytes and Bytearray Operations
......................................

Both bytes and bytearray objects support the *note common: dd3. sequence
operations.  They interoperate not just with operands of the same type,
but with any *note bytes-like object: 19f.  Due to this flexibility,
they can be freely mixed in operations without causing errors.  However,
the return type of the result may depend on the order of operands.

     Note: The methods on bytes and bytearray objects don’t accept
     strings as their arguments, just as the methods on strings don’t
     accept bytes as their arguments.  For example, you have to write:

          a = "abc"
          b = a.replace("a", "f")

     and:

          a = b"abc"
          b = a.replace(b"a", b"f")

Some bytes and bytearray operations assume the use of ASCII compatible
binary formats, and hence should be avoided when working with arbitrary
binary data.  These restrictions are covered below.

     Note: Using these ASCII based operations to manipulate binary data
     that is not stored in an ASCII based format may lead to data
     corruption.

The following methods on bytes and bytearray objects can be used with
arbitrary binary data.

 -- Method: bytes.count (sub[, start[, end]])
 -- Method: bytearray.count (sub[, start[, end]])

     Return the number of non-overlapping occurrences of subsequence
     `sub' in the range [`start', `end'].  Optional arguments `start'
     and `end' are interpreted as in slice notation.

     The subsequence to search for may be any *note bytes-like object:
     19f. or an integer in the range 0 to 255.

     Changed in version 3.3: Also accept an integer in the range 0 to
     255 as the subsequence.

 -- Method: bytes.decode (encoding="utf-8", errors="strict")
 -- Method: bytearray.decode (encoding="utf-8", errors="strict")

     Return a string decoded from the given bytes.  Default encoding is
     ‘'utf-8'’.  `errors' may be given to set a different error handling
     scheme.  The default for `errors' is ‘'strict'’, meaning that
     encoding errors raise a *note UnicodeError: 696.  Other possible
     values are ‘'ignore'’, ‘'replace'’ and any other name registered
     via *note codecs.register_error(): 87c, see section *note Error
     Handlers: da1.  For a list of possible encodings, see section *note
     Standard Encodings: 184.

          Note: Passing the `encoding' argument to *note str: 178.
          allows decoding any *note bytes-like object: 19f. directly,
          without needing to make a temporary bytes or bytearray object.

     Changed in version 3.1: Added support for keyword arguments.

 -- Method: bytes.endswith (suffix[, start[, end]])
 -- Method: bytearray.endswith (suffix[, start[, end]])

     Return ‘True’ if the binary data ends with the specified `suffix',
     otherwise return ‘False’.  `suffix' can also be a tuple of suffixes
     to look for.  With optional `start', test beginning at that
     position.  With optional `end', stop comparing at that position.

     The suffix(es) to search for may be any *note bytes-like object:
     19f.

 -- Method: bytes.find (sub[, start[, end]])
 -- Method: bytearray.find (sub[, start[, end]])

     Return the lowest index in the data where the subsequence `sub' is
     found, such that `sub' is contained in the slice ‘s[start:end]’.
     Optional arguments `start' and `end' are interpreted as in slice
     notation.  Return ‘-1’ if `sub' is not found.

     The subsequence to search for may be any *note bytes-like object:
     19f. or an integer in the range 0 to 255.

          Note: The *note find(): e13. method should be used only if you
          need to know the position of `sub'.  To check if `sub' is a
          substring or not, use the *note in: 6d5. operator:

               >>> b'Py' in b'Python'
               True

     Changed in version 3.3: Also accept an integer in the range 0 to
     255 as the subsequence.

 -- Method: bytes.index (sub[, start[, end]])
 -- Method: bytearray.index (sub[, start[, end]])

     Like *note find(): e13, but raise *note ValueError: 321. when the
     subsequence is not found.

     The subsequence to search for may be any *note bytes-like object:
     19f. or an integer in the range 0 to 255.

     Changed in version 3.3: Also accept an integer in the range 0 to
     255 as the subsequence.

 -- Method: bytes.join (iterable)
 -- Method: bytearray.join (iterable)

     Return a bytes or bytearray object which is the concatenation of
     the binary data sequences in the *note iterable: 5f6. `iterable'.
     A *note TypeError: 309. will be raised if there are any values in
     `iterable' that are note *note bytes-like objects: 19f, including
     *note str: 178. objects.  The separator between elements is the
     contents of the bytes or bytearray object providing this method.

 -- Static Method: bytes.maketrans (from, to)
 -- Static Method: bytearray.maketrans (from, to)

     This static method returns a translation table usable for *note
     bytes.translate(): e18. that will map each character in `from' into
     the character at the same position in `to'; `from' and `to' must
     both be *note bytes-like objects: 19f. and have the same length.

     New in version 3.1.

 -- Method: bytes.partition (sep)
 -- Method: bytearray.partition (sep)

     Split the sequence at the first occurrence of `sep', and return a
     3-tuple containing the part before the separator, the separator,
     and the part after the separator.  If the separator is not found,
     return a 3-tuple containing a copy of the original sequence,
     followed by two empty bytes or bytearray objects.

     The separator to search for may be any *note bytes-like object:
     19f.

 -- Method: bytes.replace (old, new[, count])
 -- Method: bytearray.replace (old, new[, count])

     Return a copy of the sequence with all occurrences of subsequence
     `old' replaced by `new'.  If the optional argument `count' is
     given, only the first `count' occurrences are replaced.

     The subsequence to search for and its replacement may be any *note
     bytes-like object: 19f.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.rfind (sub[, start[, end]])
 -- Method: bytearray.rfind (sub[, start[, end]])

     Return the highest index in the sequence where the subsequence
     `sub' is found, such that `sub' is contained within ‘s[start:end]’.
     Optional arguments `start' and `end' are interpreted as in slice
     notation.  Return ‘-1’ on failure.

     The subsequence to search for may be any *note bytes-like object:
     19f. or an integer in the range 0 to 255.

     Changed in version 3.3: Also accept an integer in the range 0 to
     255 as the subsequence.

 -- Method: bytes.rindex (sub[, start[, end]])
 -- Method: bytearray.rindex (sub[, start[, end]])

     Like *note rfind(): e1d. but raises *note ValueError: 321. when the
     subsequence `sub' is not found.

     The subsequence to search for may be any *note bytes-like object:
     19f. or an integer in the range 0 to 255.

     Changed in version 3.3: Also accept an integer in the range 0 to
     255 as the subsequence.

 -- Method: bytes.rpartition (sep)
 -- Method: bytearray.rpartition (sep)

     Split the sequence at the last occurrence of `sep', and return a
     3-tuple containing the part before the separator, the separator,
     and the part after the separator.  If the separator is not found,
     return a 3-tuple containing a copy of the original sequence,
     followed by two empty bytes or bytearray objects.

     The separator to search for may be any *note bytes-like object:
     19f.

 -- Method: bytes.startswith (prefix[, start[, end]])
 -- Method: bytearray.startswith (prefix[, start[, end]])

     Return ‘True’ if the binary data starts with the specified
     `prefix', otherwise return ‘False’.  `prefix' can also be a tuple
     of prefixes to look for.  With optional `start', test beginning at
     that position.  With optional `end', stop comparing at that
     position.

     The prefix(es) to search for may be any *note bytes-like object:
     19f.

 -- Method: bytes.translate (table[, delete])
 -- Method: bytearray.translate (table[, delete])

     Return a copy of the bytes or bytearray object where all bytes
     occurring in the optional argument `delete' are removed, and the
     remaining bytes have been mapped through the given translation
     table, which must be a bytes object of length 256.

     You can use the *note bytes.maketrans(): 65b. method to create a
     translation table.

     Set the `table' argument to ‘None’ for translations that only
     delete characters:

          >>> b'read this short text'.translate(None, b'aeiou')
          b'rd ths shrt txt'

The following methods on bytes and bytearray objects have default
behaviours that assume the use of ASCII compatible binary formats, but
can still be used with arbitrary binary data by passing appropriate
arguments.  Note that all of the bytearray methods in this section do
`not' operate in place, and instead produce new objects.

 -- Method: bytes.center (width[, fillbyte])
 -- Method: bytearray.center (width[, fillbyte])

     Return a copy of the object centered in a sequence of length
     `width'.  Padding is done using the specified `fillbyte' (default
     is an ASCII space).  For *note bytes: 179. objects, the original
     sequence is returned if `width' is less than or equal to ‘len(s)’.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.ljust (width[, fillbyte])
 -- Method: bytearray.ljust (width[, fillbyte])

     Return a copy of the object left justified in a sequence of length
     `width'.  Padding is done using the specified `fillbyte' (default
     is an ASCII space).  For *note bytes: 179. objects, the original
     sequence is returned if `width' is less than or equal to ‘len(s)’.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.lstrip ([chars])
 -- Method: bytearray.lstrip ([chars])

     Return a copy of the sequence with specified leading bytes removed.
     The `chars' argument is a binary sequence specifying the set of
     byte values to be removed - the name refers to the fact this method
     is usually used with ASCII characters.  If omitted or ‘None’, the
     `chars' argument defaults to removing ASCII whitespace.  The
     `chars' argument is not a prefix; rather, all combinations of its
     values are stripped:

          >>> b'   spacious   '.lstrip()
          b'spacious   '
          >>> b'www.example.com'.lstrip(b'cmowz.')
          b'example.com'

     The binary sequence of byte values to remove may be any *note
     bytes-like object: 19f.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.rjust (width[, fillbyte])
 -- Method: bytearray.rjust (width[, fillbyte])

     Return a copy of the object right justified in a sequence of length
     `width'.  Padding is done using the specified `fillbyte' (default
     is an ASCII space).  For *note bytes: 179. objects, the original
     sequence is returned if `width' is less than or equal to ‘len(s)’.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.rsplit (sep=None, maxsplit=-1)
 -- Method: bytearray.rsplit (sep=None, maxsplit=-1)

     Split the binary sequence into subsequences of the same type, using
     `sep' as the delimiter string.  If `maxsplit' is given, at most
     `maxsplit' splits are done, the `rightmost' ones.  If `sep' is not
     specified or ‘None’, any subsequence consisting solely of ASCII
     whitespace is a separator.  Except for splitting from the right,
     *note rsplit(): e2e. behaves like *note split(): e2f. which is
     described in detail below.

 -- Method: bytes.rstrip ([chars])
 -- Method: bytearray.rstrip ([chars])

     Return a copy of the sequence with specified trailing bytes
     removed.  The `chars' argument is a binary sequence specifying the
     set of byte values to be removed - the name refers to the fact this
     method is usually used with ASCII characters.  If omitted or
     ‘None’, the `chars' argument defaults to removing ASCII whitespace.
     The `chars' argument is not a suffix; rather, all combinations of
     its values are stripped:

          >>> b'   spacious   '.rstrip()
          b'   spacious'
          >>> b'mississippi'.rstrip(b'ipz')
          b'mississ'

     The binary sequence of byte values to remove may be any *note
     bytes-like object: 19f.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.split (sep=None, maxsplit=-1)
 -- Method: bytearray.split (sep=None, maxsplit=-1)

     Split the binary sequence into subsequences of the same type, using
     `sep' as the delimiter string.  If `maxsplit' is given and
     non-negative, at most `maxsplit' splits are done (thus, the list
     will have at most ‘maxsplit+1’ elements).  If `maxsplit' is not
     specified or is ‘-1’, then there is no limit on the number of
     splits (all possible splits are made).

     If `sep' is given, consecutive delimiters are not grouped together
     and are deemed to delimit empty subsequences (for example,
     ‘b'1,,2'.split(b',')’ returns ‘[b'1', b'', b'2']’).  The `sep'
     argument may consist of a multibyte sequence (for example,
     ‘b'1<>2<>3'.split(b'<>')’ returns ‘[b'1', b'2', b'3']’).  Splitting
     an empty sequence with a specified separator returns ‘[b'']’ or
     ‘[bytearray(b'')]’ depending on the type of object being split.
     The `sep' argument may be any *note bytes-like object: 19f.

     For example:

          >>> b'1,2,3'.split(b',')
          [b'1', b'2', b'3']
          >>> b'1,2,3'.split(b',', maxsplit=1)
          [b'1', b'2,3']
          >>> b'1,2,,3,'.split(b',')
          [b'1', b'2', b'', b'3', b'']

     If `sep' is not specified or is ‘None’, a different splitting
     algorithm is applied: runs of consecutive ASCII whitespace are
     regarded as a single separator, and the result will contain no
     empty strings at the start or end if the sequence has leading or
     trailing whitespace.  Consequently, splitting an empty sequence or
     a sequence consisting solely of ASCII whitespace without a
     specified separator returns ‘[]’.

     For example:

          >>> b'1 2 3'.split()
          [b'1', b'2', b'3']
          >>> b'1 2 3'.split(maxsplit=1)
          [b'1', b'2 3']
          >>> b'   1   2   3   '.split()
          [b'1', b'2', b'3']

 -- Method: bytes.strip ([chars])
 -- Method: bytearray.strip ([chars])

     Return a copy of the sequence with specified leading and trailing
     bytes removed.  The `chars' argument is a binary sequence
     specifying the set of byte values to be removed - the name refers
     to the fact this method is usually used with ASCII characters.  If
     omitted or ‘None’, the `chars' argument defaults to removing ASCII
     whitespace.  The `chars' argument is not a prefix or suffix;
     rather, all combinations of its values are stripped:

          >>> b'   spacious   '.strip()
          b'spacious'
          >>> b'www.example.com'.strip(b'cmowz.')
          b'example'

     The binary sequence of byte values to remove may be any *note
     bytes-like object: 19f.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

The following methods on bytes and bytearray objects assume the use of
ASCII compatible binary formats and should not be applied to arbitrary
binary data.  Note that all of the bytearray methods in this section do
`not' operate in place, and instead produce new objects.

 -- Method: bytes.capitalize ()
 -- Method: bytearray.capitalize ()

     Return a copy of the sequence with each byte interpreted as an
     ASCII character, and the first byte capitalized and the rest
     lowercased.  Non-ASCII byte values are passed through unchanged.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.expandtabs (tabsize=8)
 -- Method: bytearray.expandtabs (tabsize=8)

     Return a copy of the sequence where all ASCII tab characters are
     replaced by one or more ASCII spaces, depending on the current
     column and the given tab size.  Tab positions occur every `tabsize'
     bytes (default is 8, giving tab positions at columns 0, 8, 16 and
     so on).  To expand the sequence, the current column is set to zero
     and the sequence is examined byte by byte.  If the byte is an ASCII
     tab character (‘b'\t'’), one or more space characters are inserted
     in the result until the current column is equal to the next tab
     position.  (The tab character itself is not copied.)  If the
     current byte is an ASCII newline (‘b'\n'’) or carriage return
     (‘b'\r'’), it is copied and the current column is reset to zero.
     Any other byte value is copied unchanged and the current column is
     incremented by one regardless of how the byte value is represented
     when printed:

          >>> b'01\t012\t0123\t01234'.expandtabs()
          b'01      012     0123    01234'
          >>> b'01\t012\t0123\t01234'.expandtabs(4)
          b'01  012 0123    01234'

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.isalnum ()
 -- Method: bytearray.isalnum ()

     Return true if all bytes in the sequence are alphabetical ASCII
     characters or ASCII decimal digits and the sequence is not empty,
     false otherwise.  Alphabetic ASCII characters are those byte values
     in the sequence
     ‘b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'’.  ASCII
     decimal digits are those byte values in the sequence
     ‘b'0123456789'’.

     For example:

          >>> b'ABCabc1'.isalnum()
          True
          >>> b'ABC abc1'.isalnum()
          False

 -- Method: bytes.isalpha ()
 -- Method: bytearray.isalpha ()

     Return true if all bytes in the sequence are alphabetic ASCII
     characters and the sequence is not empty, false otherwise.
     Alphabetic ASCII characters are those byte values in the sequence
     ‘b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'’.

     For example:

          >>> b'ABCabc'.isalpha()
          True
          >>> b'ABCabc1'.isalpha()
          False

 -- Method: bytes.isdigit ()
 -- Method: bytearray.isdigit ()

     Return true if all bytes in the sequence are ASCII decimal digits
     and the sequence is not empty, false otherwise.  ASCII decimal
     digits are those byte values in the sequence ‘b'0123456789'’.

     For example:

          >>> b'1234'.isdigit()
          True
          >>> b'1.23'.isdigit()
          False

 -- Method: bytes.islower ()
 -- Method: bytearray.islower ()

     Return true if there is at least one lowercase ASCII character in
     the sequence and no uppercase ASCII characters, false otherwise.

     For example:

          >>> b'hello world'.islower()
          True
          >>> b'Hello world'.islower()
          False

     Lowercase ASCII characters are those byte values in the sequence
     ‘b'abcdefghijklmnopqrstuvwxyz'’.  Uppercase ASCII characters are
     those byte values in the sequence ‘b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'’.

 -- Method: bytes.isspace ()
 -- Method: bytearray.isspace ()

     Return true if all bytes in the sequence are ASCII whitespace and
     the sequence is not empty, false otherwise.  ASCII whitespace
     characters are those byte values in the sequence b’ tnrx0bf’
     (space, tab, newline, carriage return, vertical tab, form feed).

 -- Method: bytes.istitle ()
 -- Method: bytearray.istitle ()

     Return true if the sequence is ASCII titlecase and the sequence is
     not empty, false otherwise.  See *note bytes.title(): e45. for more
     details on the definition of "titlecase".

     For example:

          >>> b'Hello World'.istitle()
          True
          >>> b'Hello world'.istitle()
          False

 -- Method: bytes.isupper ()
 -- Method: bytearray.isupper ()

     Return true if there is at least one lowercase alphabetic ASCII
     character in the sequence and no uppercase ASCII characters, false
     otherwise.

     For example:

          >>> b'HELLO WORLD'.isupper()
          True
          >>> b'Hello world'.isupper()
          False

     Lowercase ASCII characters are those byte values in the sequence
     ‘b'abcdefghijklmnopqrstuvwxyz'’.  Uppercase ASCII characters are
     those byte values in the sequence ‘b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'’.

 -- Method: bytes.lower ()
 -- Method: bytearray.lower ()

     Return a copy of the sequence with all the uppercase ASCII
     characters converted to their corresponding lowercase counterpart.

     For example:

          >>> b'Hello World'.lower()
          b'hello world'

     Lowercase ASCII characters are those byte values in the sequence
     ‘b'abcdefghijklmnopqrstuvwxyz'’.  Uppercase ASCII characters are
     those byte values in the sequence ‘b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'’.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.splitlines (keepends=False)
 -- Method: bytearray.splitlines (keepends=False)

     Return a list of the lines in the binary sequence, breaking at
     ASCII line boundaries.  This method uses the *note universal
     newlines: 794. approach to splitting lines.  Line breaks are not
     included in the resulting list unless `keepends' is given and true.

     For example:

          >>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
          [b'ab c', b'', b'de fg', b'kl']
          >>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
          [b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']

     Unlike *note split(): e32. when a delimiter string `sep' is given,
     this method returns an empty list for the empty string, and a
     terminal line break does not result in an extra line:

          >>> b"".split(b'\n'), b"Two lines\n".split(b'\n')
          ([b''], [b'Two lines', b''])
          >>> b"".splitlines(), b"One line\n".splitlines()
          ([], [b'One line'])

 -- Method: bytes.swapcase ()
 -- Method: bytearray.swapcase ()

     Return a copy of the sequence with all the lowercase ASCII
     characters converted to their corresponding uppercase counterpart
     and vice-versa.

     For example:

          >>> b'Hello World'.swapcase()
          b'hELLO wORLD'

     Lowercase ASCII characters are those byte values in the sequence
     ‘b'abcdefghijklmnopqrstuvwxyz'’.  Uppercase ASCII characters are
     those byte values in the sequence ‘b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'’.

     Unlike *note str.swapcase(): e04, it is always the case that
     ‘bin.swapcase().swapcase() == bin’ for the binary versions.  Case
     conversions are symmetrical in ASCII, even though that is not
     generally true for arbitrary Unicode code points.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.title ()
 -- Method: bytearray.title ()

     Return a titlecased version of the binary sequence where words
     start with an uppercase ASCII character and the remaining
     characters are lowercase.  Uncased byte values are left unmodified.

     For example:

          >>> b'Hello world'.title()
          b'Hello World'

     Lowercase ASCII characters are those byte values in the sequence
     ‘b'abcdefghijklmnopqrstuvwxyz'’.  Uppercase ASCII characters are
     those byte values in the sequence ‘b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'’.
     All other byte values are uncased.

     The algorithm uses a simple language-independent definition of a
     word as groups of consecutive letters.  The definition works in
     many contexts but it means that apostrophes in contractions and
     possessives form word boundaries, which may not be the desired
     result:

          >>> b"they're bill's friends from the UK".title()
          b"They'Re Bill'S Friends From The Uk"

     A workaround for apostrophes can be constructed using regular
     expressions:

          >>> import re
          >>> def titlecase(s):
          ...     return re.sub(rb"[A-Za-z]+('[A-Za-z]+)?",
          ...                   lambda mo: mo.group(0)[0:1].upper() +
          ...                              mo.group(0)[1:].lower(),
          ...                   s)
          ...
          >>> titlecase(b"they're bill's friends.")
          b"They're Bill's Friends."

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.upper ()
 -- Method: bytearray.upper ()

     Return a copy of the sequence with all the lowercase ASCII
     characters converted to their corresponding uppercase counterpart.

     For example:

          >>> b'Hello World'.upper()
          b'HELLO WORLD'

     Lowercase ASCII characters are those byte values in the sequence
     ‘b'abcdefghijklmnopqrstuvwxyz'’.  Uppercase ASCII characters are
     those byte values in the sequence ‘b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'’.

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.

 -- Method: bytes.zfill (width)
 -- Method: bytearray.zfill (width)

     Return a copy of the sequence left filled with ASCII ‘b'0'’ digits
     to make a sequence of length `width'.  A leading sign prefix
     (‘b'+'’/ ‘b'-'’ is handled by inserting the padding `after' the
     sign character rather than before.  For *note bytes: 179. objects,
     the original sequence is returned if `width' is less than or equal
     to ‘len(seq)’.

     For example:

          >>> b"42".zfill(5)
          b'00042'
          >>> b"-42".zfill(5)
          b'-0042'

          Note: The bytearray version of this method does `not' operate
          in place - it always produces a new object, even if no changes
          were made.


File: python.info,  Node: Memory Views,  Prev: Bytes and Bytearray Operations,  Up: Binary Sequence Types --- bytes bytearray memoryview

5.4.8.4 Memory Views
....................

*note memoryview: 187. objects allow Python code to access the internal
data of an object that supports the *note buffer protocol: ddf. without
copying.

 -- Class: memoryview (obj)

     Create a *note memoryview: 187. that references `obj'.  `obj' must
     support the buffer protocol.  Built-in objects that support the
     buffer protocol include *note bytes: 179. and *note bytearray: 17a.

     A *note memoryview: 187. has the notion of an `element', which is
     the atomic memory unit handled by the originating object `obj'.
     For many simple types such as *note bytes: 179. and *note
     bytearray: 17a, an element is a single byte, but other types such
     as *note array.array: 6b8. may have bigger elements.

     ‘len(view)’ is equal to the length of *note tolist: e54.  If
     ‘view.ndim = 0’, the length is 1.  If ‘view.ndim = 1’, the length
     is equal to the number of elements in the view.  For higher
     dimensions, the length is equal to the length of the nested list
     representation of the view.  The *note itemsize: e55. attribute
     will give you the number of bytes in a single element.

     A *note memoryview: 187. supports slicing to expose its data.  If
     *note format: e56. is one of the native format specifiers from the
     *note struct: f3. module, indexing will return a single element
     with the correct type.  Full slicing will result in a subview:

          >>> v = memoryview(b'abcefg')
          >>> v[1]
          98
          >>> v[-1]
          103
          >>> v[1:4]
          <memory at 0x7f3ddc9f4350>
          >>> bytes(v[1:4])
          b'bce'

     Other native formats:

          >>> import array
          >>> a = array.array('l', [-11111111, 22222222, -33333333, 44444444])
          >>> a[0]
          -11111111
          >>> a[-1]
          44444444
          >>> a[2:3].tolist()
          [-33333333]
          >>> a[::2].tolist()
          [-11111111, -33333333]
          >>> a[::-1].tolist()
          [44444444, -33333333, 22222222, -11111111]

     New in version 3.3.

     If the underlying object is writable, the memoryview supports slice
     assignment.  Resizing is not allowed:

          >>> data = bytearray(b'abcefg')
          >>> v = memoryview(data)
          >>> v.readonly
          False
          >>> v[0] = ord(b'z')
          >>> data
          bytearray(b'zbcefg')
          >>> v[1:4] = b'123'
          >>> data
          bytearray(b'z123fg')
          >>> v[2:3] = b'spam'
          Traceback (most recent call last):
            File "<stdin>", line 1, in <module>
          ValueError: memoryview assignment: lvalue and rvalue have different structures
          >>> v[2:6] = b'spam'
          >>> data
          bytearray(b'z1spam')

     One-dimensional memoryviews of hashable (read-only) types with
     formats ’B’, ’b’ or ’c’ are also hashable.  The hash is defined as
     ‘hash(m) == hash(m.tobytes())’:

          >>> v = memoryview(b'abcefg')
          >>> hash(v) == hash(b'abcefg')
          True
          >>> hash(v[2:4]) == hash(b'ce')
          True
          >>> hash(v[::-2]) == hash(b'abcefg'[::-2])
          True

     Changed in version 3.3: One-dimensional memoryviews with formats
     ’B’, ’b’ or ’c’ are now hashable.

     Changed in version 3.4: memoryview is now registered automatically
     with *note collections.abc.Sequence: dd5.

     *note memoryview: 187. has several methods:

      -- Method: __eq__ (exporter)

          A memoryview and a PEP 3118(1) exporter are equal if their
          shapes are equivalent and if all corresponding values are
          equal when the operands’ respective format codes are
          interpreted using *note struct: f3. syntax.

          For the subset of *note struct: f3. format strings currently
          supported by *note tolist(): e54, ‘v’ and ‘w’ are equal if
          ‘v.tolist() == w.tolist()’:

               >>> import array
               >>> a = array.array('I', [1, 2, 3, 4, 5])
               >>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
               >>> c = array.array('b', [5, 3, 1])
               >>> x = memoryview(a)
               >>> y = memoryview(b)
               >>> x == a == y == b
               True
               >>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
               True
               >>> z = y[::-2]
               >>> z == c
               True
               >>> z.tolist() == c.tolist()
               True

          If either format string is not supported by the *note struct:
          f3. module, then the objects will always compare as unequal
          (even if the format strings and buffer contents are
          identical):

               >>> from ctypes import BigEndianStructure, c_long
               >>> class BEPoint(BigEndianStructure):
               ...     _fields_ = [("x", c_long), ("y", c_long)]
               ...
               >>> point = BEPoint(100, 200)
               >>> a = memoryview(point)
               >>> b = memoryview(point)
               >>> a == point
               False
               >>> a == b
               False

          Note that, as with floating point numbers, ‘v is w’ does `not'
          imply ‘v == w’ for memoryview objects.

          Changed in version 3.3: Previous versions compared the raw
          memory disregarding the item format and the logical array
          structure.

      -- Method: tobytes ()

          Return the data in the buffer as a bytestring.  This is
          equivalent to calling the *note bytes: 179. constructor on the
          memoryview.

               >>> m = memoryview(b"abc")
               >>> m.tobytes()
               b'abc'
               >>> bytes(m)
               b'abc'

          For non-contiguous arrays the result is equal to the flattened
          list representation with all elements converted to bytes.
          *note tobytes(): e58. supports all format strings, including
          those that are not in *note struct: f3. module syntax.

      -- Method: tolist ()

          Return the data in the buffer as a list of elements.

               >>> memoryview(b'abc').tolist()
               [97, 98, 99]
               >>> import array
               >>> a = array.array('d', [1.1, 2.2, 3.3])
               >>> m = memoryview(a)
               >>> m.tolist()
               [1.1, 2.2, 3.3]

          Changed in version 3.3: *note tolist(): e54. now supports all
          single character native formats in *note struct: f3. module
          syntax as well as multi-dimensional representations.

      -- Method: release ()

          Release the underlying buffer exposed by the memoryview
          object.  Many objects take special actions when a view is held
          on them (for example, a *note bytearray: 17a. would
          temporarily forbid resizing); therefore, calling release() is
          handy to remove these restrictions (and free any dangling
          resources) as soon as possible.

          After this method has been called, any further operation on
          the view raises a *note ValueError: 321. (except *note
          release(): 562. itself which can be called multiple times):

               >>> m = memoryview(b'abc')
               >>> m.release()
               >>> m[0]
               Traceback (most recent call last):
                 File "<stdin>", line 1, in <module>
               ValueError: operation forbidden on released memoryview object

          The context management protocol can be used for a similar
          effect, using the ‘with’ statement:

               >>> with memoryview(b'abc') as m:
               ...     m[0]
               ...
               97
               >>> m[0]
               Traceback (most recent call last):
                 File "<stdin>", line 1, in <module>
               ValueError: operation forbidden on released memoryview object

          New in version 3.2.

      -- Method: cast (format[, shape])

          Cast a memoryview to a new format or shape.  `shape' defaults
          to ‘[byte_length//new_itemsize]’, which means that the result
          view will be one-dimensional.  The return value is a new
          memoryview, but the buffer itself is not copied.  Supported
          casts are 1D -> C-contiguous and C-contiguous -> 1D.

          Both formats are restricted to single element native formats
          in *note struct: f3. syntax.  One of the formats must be a
          byte format (’B’, ’b’ or ’c’).  The byte length of the result
          must be the same as the original length.

          Cast 1D/long to 1D/unsigned bytes:

               >>> import array
               >>> a = array.array('l', [1,2,3])
               >>> x = memoryview(a)
               >>> x.format
               'l'
               >>> x.itemsize
               8
               >>> len(x)
               3
               >>> x.nbytes
               24
               >>> y = x.cast('B')
               >>> y.format
               'B'
               >>> y.itemsize
               1
               >>> len(y)
               24
               >>> y.nbytes
               24

          Cast 1D/unsigned bytes to 1D/char:

               >>> b = bytearray(b'zyz')
               >>> x = memoryview(b)
               >>> x[0] = b'a'
               Traceback (most recent call last):
                 File "<stdin>", line 1, in <module>
               ValueError: memoryview: invalid value for format "B"
               >>> y = x.cast('c')
               >>> y[0] = b'a'
               >>> b
               bytearray(b'ayz')

          Cast 1D/bytes to 3D/ints to 1D/signed char:

               >>> import struct
               >>> buf = struct.pack("i"*12, *list(range(12)))
               >>> x = memoryview(buf)
               >>> y = x.cast('i', shape=[2,2,3])
               >>> y.tolist()
               [[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
               >>> y.format
               'i'
               >>> y.itemsize
               4
               >>> len(y)
               2
               >>> y.nbytes
               48
               >>> z = y.cast('b')
               >>> z.format
               'b'
               >>> z.itemsize
               1
               >>> len(z)
               48
               >>> z.nbytes
               48

          Cast 1D/unsigned char to 2D/unsigned long:

               >>> buf = struct.pack("L"*6, *list(range(6)))
               >>> x = memoryview(buf)
               >>> y = x.cast('L', shape=[2,3])
               >>> len(y)
               2
               >>> y.nbytes
               48
               >>> y.tolist()
               [[0, 1, 2], [3, 4, 5]]

          New in version 3.3.

     There are also several readonly attributes available:

      -- Attribute: obj

          The underlying object of the memoryview:

               >>> b  = bytearray(b'xyz')
               >>> m = memoryview(b)
               >>> m.obj is b
               True

          New in version 3.3.

      -- Attribute: nbytes

          ‘nbytes == product(shape) * itemsize == len(m.tobytes())’.
          This is the amount of space in bytes that the array would use
          in a contiguous representation.  It is not necessarily equal
          to len(m):

               >>> import array
               >>> a = array.array('i', [1,2,3,4,5])
               >>> m = memoryview(a)
               >>> len(m)
               5
               >>> m.nbytes
               20
               >>> y = m[::2]
               >>> len(y)
               3
               >>> y.nbytes
               12
               >>> len(y.tobytes())
               12

          Multi-dimensional arrays:

               >>> import struct
               >>> buf = struct.pack("d"*12, *[1.5*x for x in range(12)])
               >>> x = memoryview(buf)
               >>> y = x.cast('d', shape=[3,4])
               >>> y.tolist()
               [[0.0, 1.5, 3.0, 4.5], [6.0, 7.5, 9.0, 10.5], [12.0, 13.5, 15.0, 16.5]]
               >>> len(y)
               3
               >>> y.nbytes
               96

          New in version 3.3.

      -- Attribute: readonly

          A bool indicating whether the memory is read only.

      -- Attribute: format

          A string containing the format (in *note struct: f3. module
          style) for each element in the view.  A memoryview can be
          created from exporters with arbitrary format strings, but some
          methods (e.g.  *note tolist(): e54.) are restricted to native
          single element formats.

          Changed in version 3.3: format ‘'B'’ is now handled according
          to the struct module syntax.  This means that
          ‘memoryview(b'abc')[0] == b'abc'[0] == 97’.

      -- Attribute: itemsize

          The size in bytes of each element of the memoryview:

               >>> import array, struct
               >>> m = memoryview(array.array('H', [32000, 32001, 32002]))
               >>> m.itemsize
               2
               >>> m[0]
               32000
               >>> struct.calcsize('H') == m.itemsize
               True

      -- Attribute: ndim

          An integer indicating how many dimensions of a
          multi-dimensional array the memory represents.

      -- Attribute: shape

          A tuple of integers the length of *note ndim: e5d. giving the
          shape of the memory as an N-dimensional array.

          Changed in version 3.3: An empty tuple instead of None when
          ndim = 0.

      -- Attribute: strides

          A tuple of integers the length of *note ndim: e5d. giving the
          size in bytes to access each element for each dimension of the
          array.

          Changed in version 3.3: An empty tuple instead of None when
          ndim = 0.

      -- Attribute: suboffsets

          Used internally for PIL-style arrays.  The value is
          informational only.

      -- Attribute: c_contiguous

          A bool indicating whether the memory is C-contiguous.

          New in version 3.3.

      -- Attribute: f_contiguous

          A bool indicating whether the memory is Fortran contiguous.

          New in version 3.3.

      -- Attribute: contiguous

          A bool indicating whether the memory is contiguous.

          New in version 3.3.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3118


File: python.info,  Node: Set Types --- set frozenset,  Next: Mapping Types --- dict,  Prev: Binary Sequence Types --- bytes bytearray memoryview,  Up: Built-in Types

5.4.9 Set Types — ‘set’, ‘frozenset’
------------------------------------

A `set' object is an unordered collection of distinct *note hashable:
bfd. objects.  Common uses include membership testing, removing
duplicates from a sequence, and computing mathematical operations such
as intersection, union, difference, and symmetric difference.  (For
other containers see the built-in *note dict: 380, *note list: 397, and
*note tuple: 84e. classes, and the *note collections: 1e. module.)

Like other collections, sets support ‘x in set’, ‘len(set)’, and ‘for x
in set’.  Being an unordered collection, sets do not record element
position or order of insertion.  Accordingly, sets do not support
indexing, slicing, or other sequence-like behavior.

There are currently two built-in set types, *note set: 5a4. and *note
frozenset: 63c.  The *note set: 5a4. type is mutable — the contents can
be changed using methods like *note add(): bfc. and *note remove(): e65.
Since it is mutable, it has no hash value and cannot be used as either a
dictionary key or as an element of another set.  The *note frozenset:
63c. type is immutable and *note hashable: bfd. — its contents cannot be
altered after it is created; it can therefore be used as a dictionary
key or as an element of another set.

Non-empty sets (not frozensets) can be created by placing a
comma-separated list of elements within braces, for example: ‘{'jack',
'sjoerd'}’, in addition to the *note set: 5a4. constructor.

The constructors for both classes work the same:

 -- Class: set ([iterable])
 -- Class: frozenset ([iterable])

     Return a new set or frozenset object whose elements are taken from
     `iterable'.  The elements of a set must be *note hashable: bfd.  To
     represent sets of sets, the inner sets must be *note frozenset:
     63c. objects.  If `iterable' is not specified, a new empty set is
     returned.

     Instances of *note set: 5a4. and *note frozenset: 63c. provide the
     following operations:

      -- Describe: len(s)

          Return the cardinality of set `s'.

      -- Describe: x in s

          Test `x' for membership in `s'.

      -- Describe: x not in s

          Test `x' for non-membership in `s'.

      -- Method: isdisjoint (other)

          Return ‘True’ if the set has no elements in common with
          `other'.  Sets are disjoint if and only if their intersection
          is the empty set.

      -- Method: issubset (other)

      -- Method: set <= other

          Test whether every element in the set is in `other'.

      -- Method: set < other

          Test whether the set is a proper subset of `other', that is,
          ‘set <= other and set != other’.

      -- Method: issuperset (other)

      -- Method: set >= other

          Test whether every element in `other' is in the set.

      -- Method: set > other

          Test whether the set is a proper superset of `other', that is,
          ‘set >= other and set != other’.

      -- Method: union (other, ...)

      -- Method: set | other | ...

          Return a new set with elements from the set and all others.

      -- Method: intersection (other, ...)

      -- Method: set & other & ...

          Return a new set with elements common to the set and all
          others.

      -- Method: difference (other, ...)

      -- Method: set - other - ...

          Return a new set with elements in the set that are not in the
          others.

      -- Method: symmetric_difference (other)

      -- Method: set ^ other

          Return a new set with elements in either the set or `other'
          but not both.

      -- Method: copy ()

          Return a new set with a shallow copy of `s'.

     Note, the non-operator versions of *note union(): e69, *note
     intersection(): e6a, *note difference(): e6b, and *note
     symmetric_difference(): e6c, *note issubset(): e67, and *note
     issuperset(): e68. methods will accept any iterable as an argument.
     In contrast, their operator based counterparts require their
     arguments to be sets.  This precludes error-prone constructions
     like ‘set('abc') & 'cbs'’ in favor of the more readable
     ‘set('abc').intersection('cbs')’.

     Both *note set: 5a4. and *note frozenset: 63c. support set to set
     comparisons.  Two sets are equal if and only if every element of
     each set is contained in the other (each is a subset of the other).
     A set is less than another set if and only if the first set is a
     proper subset of the second set (is a subset, but is not equal).  A
     set is greater than another set if and only if the first set is a
     proper superset of the second set (is a superset, but is not
     equal).

     Instances of *note set: 5a4. are compared to instances of *note
     frozenset: 63c. based on their members.  For example, ‘set('abc')
     == frozenset('abc')’ returns ‘True’ and so does ‘set('abc') in
     set([frozenset('abc')])’.

     The subset and equality comparisons do not generalize to a total
     ordering function.  For example, any two nonempty disjoint sets are
     not equal and are not subsets of each other, so `all' of the
     following return ‘False’: ‘a<b’, ‘a==b’, or ‘a>b’.

     Since sets only define partial ordering (subset relationships), the
     output of the *note list.sort(): 63d. method is undefined for lists
     of sets.

     Set elements, like dictionary keys, must be *note hashable: bfd.

     Binary operations that mix *note set: 5a4. instances with *note
     frozenset: 63c. return the type of the first operand.  For example:
     ‘frozenset('ab') | set('bc')’ returns an instance of *note
     frozenset: 63c.

     The following table lists operations available for *note set: 5a4.
     that do not apply to immutable instances of *note frozenset: 63c.:

      -- Method: update (other, ...)

      -- Method: set |= other | ...

          Update the set, adding elements from all others.

      -- Method: intersection_update (other, ...)

      -- Method: set &= other & ...

          Update the set, keeping only elements found in it and all
          others.

      -- Method: difference_update (other, ...)

      -- Method: set -= other | ...

          Update the set, removing elements found in others.

      -- Method: symmetric_difference_update (other)

      -- Method: set ^= other

          Update the set, keeping only elements found in either set, but
          not in both.

      -- Method: add (elem)

          Add element `elem' to the set.

      -- Method: remove (elem)

          Remove element `elem' from the set.  Raises *note KeyError:
          706. if `elem' is not contained in the set.

      -- Method: discard (elem)

          Remove element `elem' from the set if it is present.

      -- Method: pop ()

          Remove and return an arbitrary element from the set.  Raises
          *note KeyError: 706. if the set is empty.

      -- Method: clear ()

          Remove all elements from the set.

     Note, the non-operator versions of the *note update(): e6e, *note
     intersection_update(): e6f, *note difference_update(): e70, and
     *note symmetric_difference_update(): e71. methods will accept any
     iterable as an argument.

     Note, the `elem' argument to the *note __contains__(): 79c, *note
     remove(): e65, and *note discard(): e72. methods may be a set.  To
     support searching for an equivalent frozenset, the `elem' set is
     temporarily mutated during the search and then restored.  During
     the search, the `elem' set should not be read or mutated since it
     does not have a meaningful value.


File: python.info,  Node: Mapping Types --- dict,  Next: Context Manager Types,  Prev: Set Types --- set frozenset,  Up: Built-in Types

5.4.10 Mapping Types — ‘dict’
-----------------------------

A *note mapping: 559. object maps *note hashable: bfd. values to
arbitrary objects.  Mappings are mutable objects.  There is currently
only one standard mapping type, the `dictionary'.  (For other containers
see the built-in *note list: 397, *note set: 5a4, and *note tuple: 84e.
classes, and the *note collections: 1e. module.)

A dictionary’s keys are `almost' arbitrary values.  Values that are not
*note hashable: bfd, that is, values containing lists, dictionaries or
other mutable types (that are compared by value rather than by object
identity) may not be used as keys.  Numeric types used for keys obey the
normal rules for numeric comparison: if two numbers compare equal (such
as ‘1’ and ‘1.0’) then they can be used interchangeably to index the
same dictionary entry.  (Note however, that since computers store
floating-point numbers as approximations it is usually unwise to use
them as dictionary keys.)

Dictionaries can be created by placing a comma-separated list of ‘key:
value’ pairs within braces, for example: ‘{'jack': 4098, 'sjoerd':
4127}’ or ‘{4098: 'jack', 4127: 'sjoerd'}’, or by the *note dict: 380.
constructor.

 -- Class: dict (**kwarg)

 -- Class: dict (mapping, **kwarg)

 -- Class: dict (iterable, **kwarg)

     Return a new dictionary initialized from an optional positional
     argument and a possibly empty set of keyword arguments.

     If no positional argument is given, an empty dictionary is created.
     If a positional argument is given and it is a mapping object, a
     dictionary is created with the same key-value pairs as the mapping
     object.  Otherwise, the positional argument must be an *note
     iterable: 5f6. object.  Each item in the iterable must itself be an
     iterable with exactly two objects.  The first object of each item
     becomes a key in the new dictionary, and the second object the
     corresponding value.  If a key occurs more than once, the last
     value for that key becomes the corresponding value in the new
     dictionary.

     If keyword arguments are given, the keyword arguments and their
     values are added to the dictionary created from the positional
     argument.  If a key being added is already present, the value from
     the keyword argument replaces the value from the positional
     argument.

     To illustrate, the following examples all return a dictionary equal
     to ‘{"one": 1, "two": 2, "three": 3}’:

          >>> a = dict(one=1, two=2, three=3)
          >>> b = {'one': 1, 'two': 2, 'three': 3}
          >>> c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))
          >>> d = dict([('two', 2), ('one', 1), ('three', 3)])
          >>> e = dict({'three': 3, 'one': 1, 'two': 2})
          >>> a == b == c == d == e
          True

     Providing keyword arguments as in the first example only works for
     keys that are valid Python identifiers.  Otherwise, any valid keys
     can be used.

     These are the operations that dictionaries support (and therefore,
     custom mapping types should support too):

      -- Describe: len(d)

          Return the number of items in the dictionary `d'.

      -- Describe: d[key]

          Return the item of `d' with key `key'.  Raises a *note
          KeyError: 706. if `key' is not in the map.

          If a subclass of dict defines a method *note __missing__():
          55c. and `key' is not present, the ‘d[key]’ operation calls
          that method with the key `key' as argument.  The ‘d[key]’
          operation then returns or raises whatever is returned or
          raised by the ‘__missing__(key)’ call.  No other operations or
          methods invoke *note __missing__(): 55c.  If *note
          __missing__(): 55c. is not defined, *note KeyError: 706. is
          raised.  *note __missing__(): 55c. must be a method; it cannot
          be an instance variable:

               >>> class Counter(dict):
               ...     def __missing__(self, key):
               ...         return 0
               >>> c = Counter()
               >>> c['red']
               0
               >>> c['red'] += 1
               >>> c['red']
               1

          The example above shows part of the implementation of *note
          collections.Counter: 3bd.  A different ‘__missing__’ method is
          used by *note collections.defaultdict: 55a.

      -- Describe: d[key] = value

          Set ‘d[key]’ to `value'.

      -- Describe: del d[key]

          Remove ‘d[key]’ from `d'.  Raises a *note KeyError: 706. if
          `key' is not in the map.

      -- Describe: key in d

          Return ‘True’ if `d' has a key `key', else ‘False’.

      -- Describe: key not in d

          Equivalent to ‘not key in d’.

      -- Describe: iter(d)

          Return an iterator over the keys of the dictionary.  This is a
          shortcut for ‘iter(d.keys())’.

      -- Method: clear ()

          Remove all items from the dictionary.

      -- Method: copy ()

          Return a shallow copy of the dictionary.

      -- Class Method: fromkeys (seq[, value])

          Create a new dictionary with keys from `seq' and values set to
          `value'.

          *note fromkeys(): e78. is a class method that returns a new
          dictionary.  `value' defaults to ‘None’.

      -- Method: get (key[, default])

          Return the value for `key' if `key' is in the dictionary, else
          `default'.  If `default' is not given, it defaults to ‘None’,
          so that this method never raises a *note KeyError: 706.

      -- Method: items ()

          Return a new view of the dictionary’s items (‘(key, value)’
          pairs).  See the *note documentation of view objects: e7a.

      -- Method: keys ()

          Return a new view of the dictionary’s keys.  See the *note
          documentation of view objects: e7a.

      -- Method: pop (key[, default])

          If `key' is in the dictionary, remove it and return its value,
          else return `default'.  If `default' is not given and `key' is
          not in the dictionary, a *note KeyError: 706. is raised.

      -- Method: popitem ()

          Remove and return an arbitrary ‘(key, value)’ pair from the
          dictionary.

          *note popitem(): e7c. is useful to destructively iterate over
          a dictionary, as often used in set algorithms.  If the
          dictionary is empty, calling *note popitem(): e7c. raises a
          *note KeyError: 706.

      -- Method: setdefault (key[, default])

          If `key' is in the dictionary, return its value.  If not,
          insert `key' with a value of `default' and return `default'.
          `default' defaults to ‘None’.

      -- Method: update ([other])

          Update the dictionary with the key/value pairs from `other',
          overwriting existing keys.  Return ‘None’.

          *note update(): 84c. accepts either another dictionary object
          or an iterable of key/value pairs (as tuples or other
          iterables of length two).  If keyword arguments are specified,
          the dictionary is then updated with those key/value pairs:
          ‘d.update(red=1, blue=2)’.

      -- Method: values ()

          Return a new view of the dictionary’s values.  See the *note
          documentation of view objects: e7a.

See also
........

*note types.MappingProxyType: 4c8. can be used to create a read-only
view of a *note dict: 380.

* Menu:

* Dictionary view objects:: 


File: python.info,  Node: Dictionary view objects,  Up: Mapping Types --- dict

5.4.10.1 Dictionary view objects
................................

The objects returned by *note dict.keys(): 682, *note dict.values():
684. and *note dict.items(): 683. are `view objects'.  They provide a
dynamic view on the dictionary’s entries, which means that when the
dictionary changes, the view reflects these changes.

Dictionary views can be iterated over to yield their respective data,
and support membership tests:

 -- Describe: len(dictview)

     Return the number of entries in the dictionary.

 -- Describe: iter(dictview)

     Return an iterator over the keys, values or items (represented as
     tuples of ‘(key, value)’) in the dictionary.

     Keys and values are iterated over in an arbitrary order which is
     non-random, varies across Python implementations, and depends on
     the dictionary’s history of insertions and deletions.  If keys,
     values and items views are iterated over with no intervening
     modifications to the dictionary, the order of items will directly
     correspond.  This allows the creation of ‘(value, key)’ pairs using
     *note zip(): 68a.: ‘pairs = zip(d.values(), d.keys())’.  Another
     way to create the same list is ‘pairs = [(v, k) for (k, v) in
     d.items()]’.

     Iterating views while adding or deleting entries in the dictionary
     may raise a *note RuntimeError: 7f0. or fail to iterate over all
     entries.

 -- Describe: x in dictview

     Return ‘True’ if `x' is in the underlying dictionary’s keys, values
     or items (in the latter case, `x' should be a ‘(key, value)’
     tuple).

Keys views are set-like since their entries are unique and hashable.  If
all values are hashable, so that ‘(key, value)’ pairs are unique and
hashable, then the items view is also set-like.  (Values views are not
treated as set-like since the entries are generally not unique.)  For
set-like views, all of the operations defined for the abstract base
class *note collections.abc.Set: e7e. are available (for example, ‘==’,
‘<’, or ‘^’).

An example of dictionary view usage:

     >>> dishes = {'eggs': 2, 'sausage': 1, 'bacon': 1, 'spam': 500}
     >>> keys = dishes.keys()
     >>> values = dishes.values()

     >>> # iteration
     >>> n = 0
     >>> for val in values:
     ...     n += val
     >>> print(n)
     504

     >>> # keys and values are iterated over in the same order
     >>> list(keys)
     ['eggs', 'bacon', 'sausage', 'spam']
     >>> list(values)
     [2, 1, 1, 500]

     >>> # view objects are dynamic and reflect dict changes
     >>> del dishes['eggs']
     >>> del dishes['sausage']
     >>> list(keys)
     ['spam', 'bacon']

     >>> # set operations
     >>> keys & {'eggs', 'bacon', 'salad'}
     {'bacon'}
     >>> keys ^ {'sausage', 'juice'}
     {'juice', 'sausage', 'bacon', 'spam'}


File: python.info,  Node: Context Manager Types,  Next: Other Built-in Types,  Prev: Mapping Types --- dict,  Up: Built-in Types

5.4.11 Context Manager Types
----------------------------

Python’s *note with: 19b. statement supports the concept of a runtime
context defined by a context manager.  This is implemented using a pair
of methods that allow user-defined classes to define a runtime context
that is entered before the statement body is executed and exited when
the statement ends:

 -- Method: contextmanager.__enter__ ()

     Enter the runtime context and return either this object or another
     object related to the runtime context.  The value returned by this
     method is bound to the identifier in the *note as: 69e. clause of
     *note with: 19b. statements using this context manager.

     An example of a context manager that returns itself is a *note file
     object: 56a.  File objects return themselves from __enter__() to
     allow *note open(): 1a2. to be used as the context expression in a
     *note with: 19b. statement.

     An example of a context manager that returns a related object is
     the one returned by *note decimal.localcontext(): e81.  These
     managers set the active decimal context to a copy of the original
     decimal context and then return the copy.  This allows changes to
     be made to the current decimal context in the body of the *note
     with: 19b. statement without affecting code outside the *note with:
     19b. statement.

 -- Method: contextmanager.__exit__ (exc_type, exc_val, exc_tb)

     Exit the runtime context and return a Boolean flag indicating if
     any exception that occurred should be suppressed.  If an exception
     occurred while executing the body of the *note with: 19b.
     statement, the arguments contain the exception type, value and
     traceback information.  Otherwise, all three arguments are ‘None’.

     Returning a true value from this method will cause the *note with:
     19b. statement to suppress the exception and continue execution
     with the statement immediately following the *note with: 19b.
     statement.  Otherwise the exception continues propagating after
     this method has finished executing.  Exceptions that occur during
     execution of this method will replace any exception that occurred
     in the body of the *note with: 19b. statement.

     The exception passed in should never be reraised explicitly -
     instead, this method should return a false value to indicate that
     the method completed successfully and does not want to suppress the
     raised exception.  This allows context management code to easily
     detect whether or not an *note __exit__(): e82. method has actually
     failed.

Python defines several context managers to support easy thread
synchronisation, prompt closure of files or other objects, and simpler
manipulation of the active decimal arithmetic context.  The specific
types are not treated specially beyond their implementation of the
context management protocol.  See the *note contextlib: 24. module for
some examples.

Python’s *note generator: 374.s and the *note contextlib.contextmanager:
5b5. decorator provide a convenient way to implement these protocols.
If a generator function is decorated with the *note
contextlib.contextmanager: 5b5. decorator, it will return a context
manager implementing the necessary *note __enter__(): 702. and *note
__exit__(): 703. methods, rather than the iterator produced by an
undecorated generator function.

Note that there is no specific slot for any of these methods in the type
structure for Python objects in the Python/C API. Extension types
wanting to define these methods must provide them as a normal Python
accessible method.  Compared to the overhead of setting up the runtime
context, the overhead of a single class dictionary lookup is negligible.


File: python.info,  Node: Other Built-in Types,  Next: Special Attributes,  Prev: Context Manager Types,  Up: Built-in Types

5.4.12 Other Built-in Types
---------------------------

The interpreter supports several other kinds of objects.  Most of these
support only one or two operations.

* Menu:

* Modules: Modules<2>. 
* Classes and Class Instances:: 
* Functions:: 
* Methods:: 
* Code Objects:: 
* Type Objects:: 
* The Null Object:: 
* The Ellipsis Object:: 
* The NotImplemented Object:: 
* Boolean Values:: 
* Internal Objects:: 


File: python.info,  Node: Modules<2>,  Next: Classes and Class Instances,  Up: Other Built-in Types

5.4.12.1 Modules
................

The only special operation on a module is attribute access: ‘m.name’,
where `m' is a module and `name' accesses a name defined in `m'’s symbol
table.  Module attributes can be assigned to.  (Note that the *note
import: 674. statement is not, strictly speaking, an operation on a
module object; ‘import foo’ does not require a module object named `foo'
to exist, rather it requires an (external) `definition' for a module
named `foo' somewhere.)

A special attribute of every module is *note __dict__: c07.  This is the
dictionary containing the module’s symbol table.  Modifying this
dictionary will actually change the module’s symbol table, but direct
assignment to the ‘__dict__’ attribute is not possible (you can write
‘m.__dict__['a'] = 1’, which defines ‘m.a’ to be ‘1’, but you can’t
write ‘m.__dict__ = {}’).  Modifying ‘__dict__’ directly is not
recommended.

Modules built into the interpreter are written like this: ‘<module 'sys'
(built-in)>’.  If loaded from a file, they are written as ‘<module 'os'
from '/usr/local/lib/pythonX.Y/os.pyc'>’.


File: python.info,  Node: Classes and Class Instances,  Next: Functions,  Prev: Modules<2>,  Up: Other Built-in Types

5.4.12.2 Classes and Class Instances
....................................

See *note Objects, values and types: bf0. and *note Class definitions:
6ce. for these.


File: python.info,  Node: Functions,  Next: Methods,  Prev: Classes and Class Instances,  Up: Other Built-in Types

5.4.12.3 Functions
..................

Function objects are created by function definitions.  The only
operation on a function object is to call it: ‘func(argument-list)’.

There are really two flavors of function objects: built-in functions and
user-defined functions.  Both support the same operation (to call the
function), but the implementation is different, hence the different
object types.

See *note Function definitions: a4b. for more information.


File: python.info,  Node: Methods,  Next: Code Objects,  Prev: Functions,  Up: Other Built-in Types

5.4.12.4 Methods
................

Methods are functions that are called using the attribute notation.
There are two flavors: built-in methods (such as ‘append()’ on lists)
and class instance methods.  Built-in methods are described with the
types that support them.

If you access a method (a function defined in a class namespace) through
an instance, you get a special object: a `bound method' (also called
`instance method') object.  When called, it will add the ‘self’ argument
to the argument list.  Bound methods have two special read-only
attributes: ‘m.__self__’ is the object on which the method operates, and
‘m.__func__’ is the function implementing the method.  Calling ‘m(arg-1,
arg-2, ..., arg-n)’ is completely equivalent to calling
‘m.__func__(m.__self__, arg-1, arg-2, ..., arg-n)’.

Like function objects, bound method objects support getting arbitrary
attributes.  However, since method attributes are actually stored on the
underlying function object (‘meth.__func__’), setting method attributes
on bound methods is disallowed.  Attempting to set an attribute on a
method results in an *note AttributeError: 320. being raised.  In order
to set a method attribute, you need to explicitly set it on the
underlying function object:

     >>> class C:
     ...     def method(self):
     ...         pass
     ...
     >>> c = C()
     >>> c.method.whoami = 'my name is method'  # can't set on the method
     Traceback (most recent call last):
       File "<stdin>", line 1, in <module>
     AttributeError: 'method' object has no attribute 'whoami'
     >>> c.method.__func__.whoami = 'my name is method'
     >>> c.method.whoami
     'my name is method'

See *note The standard type hierarchy: bf3. for more information.


File: python.info,  Node: Code Objects,  Next: Type Objects,  Prev: Methods,  Up: Other Built-in Types

5.4.12.5 Code Objects
.....................

Code objects are used by the implementation to represent
"pseudo-compiled" executable Python code such as a function body.  They
differ from function objects because they don’t contain a reference to
their global execution environment.  Code objects are returned by the
built-in *note compile(): 6fe. function and can be extracted from
function objects through their ‘__code__’ attribute.  See also the *note
code: 1b. module.

A code object can be executed or evaluated by passing it (instead of a
source string) to the *note exec(): 6a0. or *note eval(): 5d2. built-in
functions.

See *note The standard type hierarchy: bf3. for more information.


File: python.info,  Node: Type Objects,  Next: The Null Object,  Prev: Code Objects,  Up: Other Built-in Types

5.4.12.6 Type Objects
.....................

Type objects represent the various object types.  An object’s type is
accessed by the built-in function *note type(): 8c1.  There are no
special operations on types.  The standard module *note types: 112.
defines names for all standard built-in types.

Types are written like this: ‘<class 'int'>’.


File: python.info,  Node: The Null Object,  Next: The Ellipsis Object,  Prev: Type Objects,  Up: Other Built-in Types

5.4.12.7 The Null Object
........................

This object is returned by functions that don’t explicitly return a
value.  It supports no special operations.  There is exactly one null
object, named ‘None’ (a built-in name).  ‘type(None)()’ produces the
same singleton.

It is written as ‘None’.


File: python.info,  Node: The Ellipsis Object,  Next: The NotImplemented Object,  Prev: The Null Object,  Up: Other Built-in Types

5.4.12.8 The Ellipsis Object
............................

This object is commonly used by slicing (see *note Slicings: cd2.).  It
supports no special operations.  There is exactly one ellipsis object,
named *note Ellipsis: db0. (a built-in name).  ‘type(Ellipsis)()’
produces the *note Ellipsis: db0. singleton.

It is written as ‘Ellipsis’ or ‘...’.


File: python.info,  Node: The NotImplemented Object,  Next: Boolean Values,  Prev: The Ellipsis Object,  Up: Other Built-in Types

5.4.12.9 The NotImplemented Object
..................................

This object is returned from comparisons and binary operations when they
are asked to operate on types they don’t support.  See *note
Comparisons: cf6. for more information.  There is exactly one
‘NotImplemented’ object.  ‘type(NotImplemented)()’ produces the
singleton instance.

It is written as ‘NotImplemented’.


File: python.info,  Node: Boolean Values,  Next: Internal Objects,  Prev: The NotImplemented Object,  Up: Other Built-in Types

5.4.12.10 Boolean Values
........................

Boolean values are the two constant objects ‘False’ and ‘True’.  They
are used to represent truth values (although other values can also be
considered false or true).  In numeric contexts (for example when used
as the argument to an arithmetic operator), they behave like the
integers 0 and 1, respectively.  The built-in function *note bool():
87a. can be used to convert any value to a Boolean, if the value can be
interpreted as a truth value (see section *note Truth Value Testing:
d88. above).

They are written as ‘False’ and ‘True’, respectively.


File: python.info,  Node: Internal Objects,  Prev: Boolean Values,  Up: Other Built-in Types

5.4.12.11 Internal Objects
..........................

See *note The standard type hierarchy: bf3. for this information.  It
describes stack frame objects, traceback objects, and slice objects.


File: python.info,  Node: Special Attributes,  Prev: Other Built-in Types,  Up: Built-in Types

5.4.13 Special Attributes
-------------------------

The implementation adds a few special read-only attributes to several
object types, where they are relevant.  Some of these are not reported
by the *note dir(): 7a8. built-in function.

 -- Attribute: object.__dict__

     A dictionary or other mapping object used to store an object’s
     (writable) attributes.

 -- Attribute: instance.__class__

     The class to which a class instance belongs.

 -- Attribute: class.__bases__

     The tuple of base classes of a class object.

 -- Attribute: class.__name__

     The name of the class or type.

 -- Attribute: class.__qualname__

     The *note qualified name: c00. of the class or type.

     New in version 3.3.

 -- Attribute: class.__mro__

     This attribute is a tuple of classes that are considered when
     looking for base classes during method resolution.

 -- Method: class.mro ()

     This method can be overridden by a metaclass to customize the
     method resolution order for its instances.  It is called at class
     instantiation, and its result is stored in *note __mro__: da9.

 -- Method: class.__subclasses__ ()

     Each class keeps a list of weak references to its immediate
     subclasses.  This method returns a list of all those references
     still alive.  Example:

          >>> int.__subclasses__()
          [<class 'bool'>]


File: python.info,  Node: Built-in Exceptions,  Next: Text Processing Services,  Prev: Built-in Types,  Up: The Python Standard Library

5.5 Built-in Exceptions
=======================

In Python, all exceptions must be instances of a class that derives from
*note BaseException: 6bd.  In a *note try: 7ee. statement with an *note
except: 563. clause that mentions a particular class, that clause also
handles any exception classes derived from that class (but not exception
classes from which `it' is derived).  Two exception classes that are not
related via subclassing are never equivalent, even if they have the same
name.

The built-in exceptions listed below can be generated by the interpreter
or built-in functions.  Except where mentioned, they have an "associated
value" indicating the detailed cause of the error.  This may be a string
or a tuple of several items of information (e.g., an error code and a
string explaining the code).  The associated value is usually passed as
arguments to the exception class’s constructor.

User code can raise built-in exceptions.  This can be used to test an
exception handler or to report an error condition "just like" the
situation in which the interpreter raises the same exception; but beware
that there is nothing to prevent user code from raising an inappropriate
error.

The built-in exception classes can be subclassed to define new
exceptions; programmers are encouraged to derive new exceptions from the
*note Exception: 6be. class or one of its subclasses, and not from *note
BaseException: 6bd.  More information on defining exceptions is
available in the Python Tutorial under *note User-defined Exceptions:
a9d.

When raising (or re-raising) an exception in an *note except: 563. or
*note finally: 2c5. clause ‘__context__’ is automatically set to the
last exception caught; if the new exception is not handled the traceback
that is eventually displayed will include the originating exception(s)
and the final exception.

When raising a new exception (rather than using a bare ‘raise’ to
re-raise the exception currently being handled), the implicit exception
context can be supplemented with an explicit cause by using *note from:
6a1. with *note raise: 69d.:

     raise new_exc from original_exc

The expression following *note from: 6a1. must be an exception or
‘None’.  It will be set as ‘__cause__’ on the raised exception.  Setting
‘__cause__’ also implicitly sets the ‘__suppress_context__’ attribute to
‘True’, so that using ‘raise new_exc from None’ effectively replaces the
old exception with the new one for display purposes (e.g.  converting
*note KeyError: 706. to *note AttributeError: 320, while leaving the old
exception available in ‘__context__’ for introspection when debugging.

The default traceback display code shows these chained exceptions in
addition to the traceback for the exception itself.  An explicitly
chained exception in ‘__cause__’ is always shown when present.  An
implicitly chained exception in ‘__context__’ is shown only if
‘__cause__’ is *note None: 2c6. and ‘__suppress_context__’ is false.

In either case, the exception itself is always shown after any chained
exceptions so that the final line of the traceback always shows the last
exception that was raised.

* Menu:

* Base classes:: 
* Concrete exceptions:: 
* Warnings:: 
* Exception hierarchy:: 


File: python.info,  Node: Base classes,  Next: Concrete exceptions,  Up: Built-in Exceptions

5.5.1 Base classes
------------------

The following exceptions are used mostly as base classes for other
exceptions.

 -- Exception: BaseException

     The base class for all built-in exceptions.  It is not meant to be
     directly inherited by user-defined classes (for that, use *note
     Exception: 6be.).  If *note str(): 178. is called on an instance of
     this class, the representation of the argument(s) to the instance
     are returned, or the empty string when there were no arguments.

      -- Attribute: args

          The tuple of arguments given to the exception constructor.
          Some built-in exceptions (like *note OSError: 254.) expect a
          certain number of arguments and assign a special meaning to
          the elements of this tuple, while others are usually called
          only with a single string giving an error message.

      -- Method: with_traceback (tb)

          This method sets `tb' as the new traceback for the exception
          and returns the exception object.  It is usually used in
          exception handling code like this:

               try:
                   ...
               except SomeException:
                   tb = sys.exc_info()[2]
                   raise OtherException(...).with_traceback(tb)

 -- Exception: Exception

     All built-in, non-system-exiting exceptions are derived from this
     class.  All user-defined exceptions should also be derived from
     this class.

 -- Exception: ArithmeticError

     The base class for those built-in exceptions that are raised for
     various arithmetic errors: *note OverflowError: 325, *note
     ZeroDivisionError: a98, *note FloatingPointError: ea4.

 -- Exception: BufferError

     Raised when a *note buffer: ddf. related operation cannot be
     performed.

 -- Exception: LookupError

     The base class for the exceptions that are raised when a key or
     index used on a mapping or sequence is invalid: *note IndexError:
     908, *note KeyError: 706.  This can be raised directly by *note
     codecs.lookup(): ea7.


File: python.info,  Node: Concrete exceptions,  Next: Warnings,  Prev: Base classes,  Up: Built-in Exceptions

5.5.2 Concrete exceptions
-------------------------

The following exceptions are the exceptions that are usually raised.

 -- Exception: AssertionError

     Raised when an *note assert: 890. statement fails.

 -- Exception: AttributeError

     Raised when an attribute reference (see *note Attribute references:
     ccc.) or assignment fails.  (When an object does not support
     attribute references or attribute assignments at all, *note
     TypeError: 309. is raised.)

 -- Exception: EOFError

     Raised when the *note input(): 6cf. function hits an end-of-file
     condition (EOF) without reading any data.  (N.B.: the
     ‘io.IOBase.read()’ and *note io.IOBase.readline(): ea9. methods
     return an empty string when they hit EOF.)

 -- Exception: FloatingPointError

     Raised when a floating point operation fails.  This exception is
     always defined, but can only be raised when Python is configured
     with the ‘--with-fpectl’ option, or the ‘WANT_SIGFPE_HANDLER’
     symbol is defined in the ‘pyconfig.h’ file.

 -- Exception: GeneratorExit

     Raised when a *note generator: 374.’s ‘close()’ method is called.
     It directly inherits from *note BaseException: 6bd. instead of
     *note Exception: 6be. since it is technically not an error.

 -- Exception: ImportError

     Raised when an *note import: 674. statement fails to find the
     module definition or when a ‘from ... import’ fails to find a name
     that is to be imported.

     The ‘name’ and ‘path’ attributes can be set using keyword-only
     arguments to the constructor.  When set they represent the name of
     the module that was attempted to be imported and the path to any
     file which triggered the exception, respectively.

     Changed in version 3.3: Added the ‘name’ and ‘path’ attributes.

 -- Exception: IndexError

     Raised when a sequence subscript is out of range.  (Slice indices
     are silently truncated to fall in the allowed range; if an index is
     not an integer, *note TypeError: 309. is raised.)

 -- Exception: KeyError

     Raised when a mapping (dictionary) key is not found in the set of
     existing keys.

 -- Exception: KeyboardInterrupt

     Raised when the user hits the interrupt key (normally ‘Control-C’
     or ‘Delete’).  During execution, a check for interrupts is made
     regularly.  The exception inherits from *note BaseException: 6bd.
     so as to not be accidentally caught by code that catches *note
     Exception: 6be. and thus prevent the interpreter from exiting.

 -- Exception: MemoryError

     Raised when an operation runs out of memory but the situation may
     still be rescued (by deleting some objects).  The associated value
     is a string indicating what kind of (internal) operation ran out of
     memory.  Note that because of the underlying memory management
     architecture (C’s ‘malloc()’ function), the interpreter may not
     always be able to completely recover from this situation; it
     nevertheless raises an exception so that a stack traceback can be
     printed, in case a run-away program was the cause.

 -- Exception: NameError

     Raised when a local or global name is not found.  This applies only
     to unqualified names.  The associated value is an error message
     that includes the name that could not be found.

 -- Exception: NotImplementedError

     This exception is derived from *note RuntimeError: 7f0.  In user
     defined base classes, abstract methods should raise this exception
     when they require derived classes to override the method.

 -- Exception: OSError

     This exception is raised when a system function returns a
     system-related error, including I/O failures such as "file not
     found" or "disk full" (not for illegal argument types or other
     incidental errors).  Often a subclass of *note OSError: 254. will
     actually be raised as described in *note OS exceptions: eab. below.
     The *note errno: 7a. attribute is a numeric error code from the C
     variable ‘errno’.

     Under Windows, the ‘winerror’ attribute gives you the native
     Windows error code.  The *note errno: 7a. attribute is then an
     approximate translation, in POSIX terms, of that native error code.

     Under all platforms, the ‘strerror’ attribute is the corresponding
     error message as provided by the operating system (as formatted by
     the C functions ‘perror()’ under POSIX, and ‘FormatMessage()’
     Windows).

     For exceptions that involve a file system path (such as *note
     open(): 1a2. or *note os.unlink(): 435.), the exception instance
     will contain an additional attribute, ‘filename’, which is the file
     name passed to the function.  For functions that involve two file
     system paths (such as *note os.rename(): 431.), the exception
     instance will contain a second ‘filename2’ attribute corresponding
     to the second file name passed to the function.

     Changed in version 3.3: *note EnvironmentError: 361, *note IOError:
     360, *note WindowsError: 362, ‘VMSError’, *note socket.error: 363,
     *note select.error: 364. and ‘mmap.error’ have been merged into
     *note OSError: 254.

     Changed in version 3.4: The ‘filename’ attribute is now the
     original file name passed to the function, instead of the name
     encoded to or decoded from the filesystem encoding.  Also, the
     ‘filename2’ attribute was added.

 -- Exception: OverflowError

     Raised when the result of an arithmetic operation is too large to
     be represented.  This cannot occur for integers (which would rather
     raise *note MemoryError: eaa. than give up).  However, for
     historical reasons, OverflowError is sometimes raised for integers
     that are outside a required range.  Because of the lack of
     standardization of floating point exception handling in C, most
     floating point operations are not checked.

 -- Exception: ReferenceError

     This exception is raised when a weak reference proxy, created by
     the *note weakref.proxy(): eac. function, is used to access an
     attribute of the referent after it has been garbage collected.  For
     more information on weak references, see the *note weakref: 121.
     module.

 -- Exception: RuntimeError

     Raised when an error is detected that doesn’t fall in any of the
     other categories.  The associated value is a string indicating what
     precisely went wrong.

 -- Exception: StopIteration

     Raised by built-in function *note next(): 6c6. and an *note
     iterator: d91.’s *note __next__(): 6c7. method to signal that there
     are no further items produced by the iterator.

     The exception object has a single attribute ‘value’, which is given
     as an argument when constructing the exception, and defaults to
     *note None: 2c6.

     When a generator function returns, a new *note StopIteration: 7a5.
     instance is raised, and the value returned by the function is used
     as the ‘value’ parameter to the constructor of the exception.

     Changed in version 3.3: Added ‘value’ attribute and the ability for
     generator functions to use it to return a value.

 -- Exception: SyntaxError

     Raised when the parser encounters a syntax error.  This may occur
     in an *note import: 674. statement, in a call to the built-in
     functions *note exec(): 6a0. or *note eval(): 5d2, or when reading
     the initial script or standard input (also interactively).

     Instances of this class have attributes ‘filename’, ‘lineno’,
     ‘offset’ and ‘text’ for easier access to the details.  *note str():
     178. of the exception instance returns only the message.

 -- Exception: IndentationError

     Base class for syntax errors related to incorrect indentation.
     This is a subclass of *note SyntaxError: 319.

 -- Exception: TabError

     Raised when indentation contains an inconsistent use of tabs and
     spaces.  This is a subclass of *note IndentationError: 90b.

 -- Exception: SystemError

     Raised when the interpreter finds an internal error, but the
     situation does not look so serious to cause it to abandon all hope.
     The associated value is a string indicating what went wrong (in
     low-level terms).

     You should report this to the author or maintainer of your Python
     interpreter.  Be sure to report the version of the Python
     interpreter (‘sys.version’; it is also printed at the start of an
     interactive Python session), the exact error message (the
     exception’s associated value) and if possible the source of the
     program that triggered the error.

 -- Exception: SystemExit

     This exception is raised by the *note sys.exit(): 758. function.
     When it is not handled, the Python interpreter exits; no stack
     traceback is printed.  If the associated value is an integer, it
     specifies the system exit status (passed to C’s ‘exit()’ function);
     if it is ‘None’, the exit status is zero; if it has another type
     (such as a string), the object’s value is printed and the exit
     status is one.

     Instances have an attribute ‘code’ which is set to the proposed
     exit status or error message (defaulting to ‘None’).  Also, this
     exception derives directly from *note BaseException: 6bd. and not
     *note Exception: 6be, since it is not technically an error.

     A call to *note sys.exit(): 758. is translated into an exception so
     that clean-up handlers (*note finally: 2c5. clauses of *note try:
     7ee. statements) can be executed, and so that a debugger can
     execute a script without running the risk of losing control.  The
     *note os._exit(): eae. function can be used if it is absolutely
     positively necessary to exit immediately (for example, in the child
     process after a call to *note os.fork(): 328.).

     The exception inherits from *note BaseException: 6bd. instead of
     *note Exception: 6be. so that it is not accidentally caught by code
     that catches *note Exception: 6be.  This allows the exception to
     properly propagate up and cause the interpreter to exit.

 -- Exception: TypeError

     Raised when an operation or function is applied to an object of
     inappropriate type.  The associated value is a string giving
     details about the type mismatch.

 -- Exception: UnboundLocalError

     Raised when a reference is made to a local variable in a function
     or method, but no value has been bound to that variable.  This is a
     subclass of *note NameError: 7f8.

 -- Exception: UnicodeError

     Raised when a Unicode-related encoding or decoding error occurs.
     It is a subclass of *note ValueError: 321.

     *note UnicodeError: 696. has attributes that describe the encoding
     or decoding error.  For example, ‘err.object[err.start:err.end]’
     gives the particular invalid input that the codec failed on.

      -- Attribute: encoding

          The name of the encoding that raised the error.

      -- Attribute: reason

          A string describing the specific codec error.

      -- Attribute: object

          The object the codec was attempting to encode or decode.

      -- Attribute: start

          The first index of invalid data in *note object: 381.

      -- Attribute: end

          The index after the last invalid data in *note object: 381.

 -- Exception: UnicodeEncodeError

     Raised when a Unicode-related error occurs during encoding.  It is
     a subclass of *note UnicodeError: 696.

 -- Exception: UnicodeDecodeError

     Raised when a Unicode-related error occurs during decoding.  It is
     a subclass of *note UnicodeError: 696.

 -- Exception: UnicodeTranslateError

     Raised when a Unicode-related error occurs during translating.  It
     is a subclass of *note UnicodeError: 696.

 -- Exception: ValueError

     Raised when a built-in operation or function receives an argument
     that has the right type but an inappropriate value, and the
     situation is not described by a more precise exception such as
     *note IndexError: 908.

 -- Exception: ZeroDivisionError

     Raised when the second argument of a division or modulo operation
     is zero.  The associated value is a string indicating the type of
     the operands and the operation.

The following exceptions are kept for compatibility with previous
versions; starting from Python 3.3, they are aliases of *note OSError:
254.

 -- Exception: EnvironmentError

 -- Exception: IOError

 -- Exception: WindowsError

     Only available on Windows.

* Menu:

* OS exceptions:: 


File: python.info,  Node: OS exceptions,  Up: Concrete exceptions

5.5.2.1 OS exceptions
.....................

The following exceptions are subclasses of *note OSError: 254, they get
raised depending on the system error code.

 -- Exception: BlockingIOError

     Raised when an operation would block on an object (e.g.  socket)
     set for non-blocking operation.  Corresponds to ‘errno’ ‘EAGAIN’,
     ‘EALREADY’, ‘EWOULDBLOCK’ and ‘EINPROGRESS’.

     In addition to those of *note OSError: 254, *note BlockingIOError:
     365. can have one more attribute:

      -- Attribute: characters_written

          An integer containing the number of characters written to the
          stream before it blocked.  This attribute is available when
          using the buffered I/O classes from the *note io: 9e. module.

 -- Exception: ChildProcessError

     Raised when an operation on a child process failed.  Corresponds to
     ‘errno’ ‘ECHILD’.

 -- Exception: ConnectionError

     A base class for connection-related issues.

     Subclasses are *note BrokenPipeError: 36f, *note
     ConnectionAbortedError: 370, *note ConnectionRefusedError: 371. and
     *note ConnectionResetError: 372.

 -- Exception: BrokenPipeError

     A subclass of *note ConnectionError: 367, raised when trying to
     write on a pipe while the other end has been closed, or trying to
     write on a socket which has been shutdown for writing.  Corresponds
     to ‘errno’ ‘EPIPE’ and ‘ESHUTDOWN’.

 -- Exception: ConnectionAbortedError

     A subclass of *note ConnectionError: 367, raised when a connection
     attempt is aborted by the peer.  Corresponds to ‘errno’
     ‘ECONNABORTED’.

 -- Exception: ConnectionRefusedError

     A subclass of *note ConnectionError: 367, raised when a connection
     attempt is refused by the peer.  Corresponds to ‘errno’
     ‘ECONNREFUSED’.

 -- Exception: ConnectionResetError

     A subclass of *note ConnectionError: 367, raised when a connection
     is reset by the peer.  Corresponds to ‘errno’ ‘ECONNRESET’.

 -- Exception: FileExistsError

     Raised when trying to create a file or directory which already
     exists.  Corresponds to ‘errno’ ‘EEXIST’.

 -- Exception: FileNotFoundError

     Raised when a file or directory is requested but doesn’t exist.
     Corresponds to ‘errno’ ‘ENOENT’.

 -- Exception: InterruptedError

     Raised when a system call is interrupted by an incoming signal.
     Corresponds to ‘errno’ ‘EINTR’.

 -- Exception: IsADirectoryError

     Raised when a file operation (such as *note os.remove(): 430.) is
     requested on a directory.  Corresponds to ‘errno’ ‘EISDIR’.

 -- Exception: NotADirectoryError

     Raised when a directory operation (such as *note os.listdir():
     43a.) is requested on something which is not a directory.
     Corresponds to ‘errno’ ‘ENOTDIR’.

 -- Exception: PermissionError

     Raised when trying to run an operation without the adequate access
     rights - for example filesystem permissions.  Corresponds to
     ‘errno’ ‘EACCES’ and ‘EPERM’.

 -- Exception: ProcessLookupError

     Raised when a given process doesn’t exist.  Corresponds to ‘errno’
     ‘ESRCH’.

 -- Exception: TimeoutError

     Raised when a system function timed out at the system level.
     Corresponds to ‘errno’ ‘ETIMEDOUT’.

New in version 3.3: All the above *note OSError: 254. subclasses were
added.

See also
........

PEP 3151(1) - Reworking the OS and IO exception hierarchy

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3151


File: python.info,  Node: Warnings,  Next: Exception hierarchy,  Prev: Concrete exceptions,  Up: Built-in Exceptions

5.5.3 Warnings
--------------

The following exceptions are used as warning categories; see the *note
warnings: 11f. module for more information.

 -- Exception: Warning

     Base class for warning categories.

 -- Exception: UserWarning

     Base class for warnings generated by user code.

 -- Exception: DeprecationWarning

     Base class for warnings about deprecated features.

 -- Exception: PendingDeprecationWarning

     Base class for warnings about features which will be deprecated in
     the future.

 -- Exception: SyntaxWarning

     Base class for warnings about dubious syntax

 -- Exception: RuntimeWarning

     Base class for warnings about dubious runtime behavior.

 -- Exception: FutureWarning

     Base class for warnings about constructs that will change
     semantically in the future.

 -- Exception: ImportWarning

     Base class for warnings about probable mistakes in module imports.

 -- Exception: UnicodeWarning

     Base class for warnings related to Unicode.

 -- Exception: BytesWarning

     Base class for warnings related to *note bytes: 179. and *note
     bytearray: 17a.

 -- Exception: ResourceWarning

     Base class for warnings related to resource usage.

     New in version 3.2.


File: python.info,  Node: Exception hierarchy,  Prev: Warnings,  Up: Built-in Exceptions

5.5.4 Exception hierarchy
-------------------------

The class hierarchy for built-in exceptions is:

     BaseException
      +-- SystemExit
      +-- KeyboardInterrupt
      +-- GeneratorExit
      +-- Exception
           +-- StopIteration
           +-- ArithmeticError
           |    +-- FloatingPointError
           |    +-- OverflowError
           |    +-- ZeroDivisionError
           +-- AssertionError
           +-- AttributeError
           +-- BufferError
           +-- EOFError
           +-- ImportError
           +-- LookupError
           |    +-- IndexError
           |    +-- KeyError
           +-- MemoryError
           +-- NameError
           |    +-- UnboundLocalError
           +-- OSError
           |    +-- BlockingIOError
           |    +-- ChildProcessError
           |    +-- ConnectionError
           |    |    +-- BrokenPipeError
           |    |    +-- ConnectionAbortedError
           |    |    +-- ConnectionRefusedError
           |    |    +-- ConnectionResetError
           |    +-- FileExistsError
           |    +-- FileNotFoundError
           |    +-- InterruptedError
           |    +-- IsADirectoryError
           |    +-- NotADirectoryError
           |    +-- PermissionError
           |    +-- ProcessLookupError
           |    +-- TimeoutError
           +-- ReferenceError
           +-- RuntimeError
           |    +-- NotImplementedError
           +-- SyntaxError
           |    +-- IndentationError
           |         +-- TabError
           +-- SystemError
           +-- TypeError
           +-- ValueError
           |    +-- UnicodeError
           |         +-- UnicodeDecodeError
           |         +-- UnicodeEncodeError
           |         +-- UnicodeTranslateError
           +-- Warning
                +-- DeprecationWarning
                +-- PendingDeprecationWarning
                +-- RuntimeWarning
                +-- SyntaxWarning
                +-- UserWarning
                +-- FutureWarning
                +-- ImportWarning
                +-- UnicodeWarning
                +-- BytesWarning
                +-- ResourceWarning


File: python.info,  Node: Text Processing Services,  Next: Binary Data Services,  Prev: Built-in Exceptions,  Up: The Python Standard Library

5.6 Text Processing Services
============================

The modules described in this chapter provide a wide range of string
manipulation operations and other text processing services.

The *note codecs: 1c. module described under *note Binary Data Services:
ebe. is also highly relevant to text processing.  In addition, see the
documentation for Python’s built-in string type in *note Text Sequence
Type — str: a16.

* Menu:

* string: string --- Common string operations. Common string operations
* re: re --- Regular expression operations. Regular expression operations
* difflib: difflib --- Helpers for computing deltas. Helpers for computing deltas
* textwrap: textwrap --- Text wrapping and filling. Text wrapping and filling
* unicodedata: unicodedata --- Unicode Database. Unicode Database
* stringprep: stringprep --- Internet String Preparation. Internet String Preparation
* readline: readline --- GNU readline interface. GNU readline interface
* rlcompleter: rlcompleter --- Completion function for GNU readline. Completion function for GNU readline


File: python.info,  Node: string --- Common string operations,  Next: re --- Regular expression operations,  Up: Text Processing Services

5.6.1 ‘string’ — Common string operations
-----------------------------------------

`Source code:' Lib/string.py(1)

__________________________________________________________________

See also
........

*note Text Sequence Type — str: a16.

*note String Methods: a17.

* Menu:

* String constants:: 
* String Formatting:: 
* Format String Syntax:: 
* Template strings:: 
* Helper functions:: 

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/3.4/Lib/string.py


File: python.info,  Node: String constants,  Next: String Formatting,  Up: string --- Common string operations

5.6.1.1 String constants
........................

The constants defined in this module are:

 -- Data: string.ascii_letters

     The concatenation of the *note ascii_lowercase: ec2. and *note
     ascii_uppercase: ec3. constants described below.  This value is not
     locale-dependent.

 -- Data: string.ascii_lowercase

     The lowercase letters ‘'abcdefghijklmnopqrstuvwxyz'’.  This value
     is not locale-dependent and will not change.

 -- Data: string.ascii_uppercase

     The uppercase letters ‘'ABCDEFGHIJKLMNOPQRSTUVWXYZ'’.  This value
     is not locale-dependent and will not change.

 -- Data: string.digits

     The string ‘'0123456789'’.

 -- Data: string.hexdigits

     The string ‘'0123456789abcdefABCDEF'’.

 -- Data: string.octdigits

     The string ‘'01234567'’.

 -- Data: string.punctuation

     String of ASCII characters which are considered punctuation
     characters in the ‘C’ locale.

 -- Data: string.printable

     String of ASCII characters which are considered printable.  This is
     a combination of *note digits: ec4, *note ascii_letters: 6ba, *note
     punctuation: ec7, and *note whitespace: ec9.

 -- Data: string.whitespace

     A string containing all ASCII characters that are considered
     whitespace.  This includes the characters space, tab, linefeed,
     return, formfeed, and vertical tab.


File: python.info,  Node: String Formatting,  Next: Format String Syntax,  Prev: String constants,  Up: string --- Common string operations

5.6.1.2 String Formatting
.........................

The built-in string class provides the ability to do complex variable
substitutions and value formatting via the *note format(): 556. method
described in PEP 3101(1).  The *note Formatter: 9a9. class in the *note
string: f1. module allows you to create and customize your own string
formatting behaviors using the same implementation as the built-in *note
format(): 556. method.

 -- Class: string.Formatter

     The *note Formatter: 9a9. class has the following public methods:

      -- Method: format (format_string, *args, **kwargs)

          *note format(): 556. is the primary API method.  It takes a
          format string and an arbitrary set of positional and keyword
          arguments.  *note format(): 556. is just a wrapper that calls
          *note vformat(): ecc.

      -- Method: vformat (format_string, args, kwargs)

          This function does the actual work of formatting.  It is
          exposed as a separate function for cases where you want to
          pass in a predefined dictionary of arguments, rather than
          unpacking and repacking the dictionary as individual arguments
          using the ‘*args’ and ‘**kwargs’ syntax.  *note vformat():
          ecc. does the work of breaking up the format string into
          character data and replacement fields.  It calls the various
          methods described below.

     In addition, the *note Formatter: 9a9. defines a number of methods
     that are intended to be replaced by subclasses:

      -- Method: parse (format_string)

          Loop over the format_string and return an iterable of tuples
          (`literal_text', `field_name', `format_spec', `conversion').
          This is used by *note vformat(): ecc. to break the string into
          either literal text, or replacement fields.

          The values in the tuple conceptually represent a span of
          literal text followed by a single replacement field.  If there
          is no literal text (which can happen if two replacement fields
          occur consecutively), then `literal_text' will be a
          zero-length string.  If there is no replacement field, then
          the values of `field_name', `format_spec' and `conversion'
          will be ‘None’.

      -- Method: get_field (field_name, args, kwargs)

          Given `field_name' as returned by *note parse(): ecd. (see
          above), convert it to an object to be formatted.  Returns a
          tuple (obj, used_key).  The default version takes strings of
          the form defined in PEP 3101(2), such as "0[name]" or
          "label.title".  `args' and `kwargs' are as passed in to *note
          vformat(): ecc.  The return value `used_key' has the same
          meaning as the `key' parameter to *note get_value(): ecf.

      -- Method: get_value (key, args, kwargs)

          Retrieve a given field value.  The `key' argument will be
          either an integer or a string.  If it is an integer, it
          represents the index of the positional argument in `args'; if
          it is a string, then it represents a named argument in
          `kwargs'.

          The `args' parameter is set to the list of positional
          arguments to *note vformat(): ecc, and the `kwargs' parameter
          is set to the dictionary of keyword arguments.

          For compound field names, these functions are only called for
          the first component of the field name; Subsequent components
          are handled through normal attribute and indexing operations.

          So for example, the field expression ’0.name’ would cause
          *note get_value(): ecf. to be called with a `key' argument of
          0.  The ‘name’ attribute will be looked up after *note
          get_value(): ecf. returns by calling the built-in *note
          getattr(): 55f. function.

          If the index or keyword refers to an item that does not exist,
          then an *note IndexError: 908. or *note KeyError: 706. should
          be raised.

      -- Method: check_unused_args (used_args, args, kwargs)

          Implement checking for unused arguments if desired.  The
          arguments to this function is the set of all argument keys
          that were actually referred to in the format string (integers
          for positional arguments, and strings for named arguments),
          and a reference to the `args' and `kwargs' that was passed to
          vformat.  The set of unused args can be calculated from these
          parameters.  *note check_unused_args(): ed0. is assumed to
          raise an exception if the check fails.

      -- Method: format_field (value, format_spec)

          *note format_field(): ed1. simply calls the global *note
          format(): 556. built-in.  The method is provided so that
          subclasses can override it.

      -- Method: convert_field (value, conversion)

          Converts the value (returned by *note get_field(): ece.) given
          a conversion type (as in the tuple returned by the *note
          parse(): ecd. method).  The default version understands ’s’
          (str), ’r’ (repr) and ’a’ (ascii) conversion types.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-3101

   (2) https://www.python.org/dev/peps/pep-3101


File: python.info,  Node: Format String Syntax,  Next: Template strings,  Prev: String Formatting,  Up: string --- Common string operations

5.6.1.3 Format String Syntax
............................

The *note str.format(): 557. method and the *note Formatter: 9a9. class
share the same syntax for format strings (although in the case of *note
Formatter: 9a9, subclasses can define their own format string syntax).

Format strings contain "replacement fields" surrounded by curly braces
‘{}’.  Anything that is not contained in braces is considered literal
text, which is copied unchanged to the output.  If you need to include a
brace character in the literal text, it can be escaped by doubling: ‘{{’
and ‘}}’.

The grammar for a replacement field is as follows:

          replacement_field ::= "{" [field_name] ["!" conversion] [":" format_spec] "}"
          field_name        ::= arg_name ("." attribute_name | "[" element_index "]")*
          arg_name          ::= [identifier | integer]
          attribute_name    ::= identifier
          element_index     ::= integer | index_string
          index_string      ::= <any source character except "]"> +
          conversion        ::= "r" | "s" | "a"
          format_spec       ::= <described in the next section>

In less formal terms, the replacement field can start with a
`field_name' that specifies the object whose value is to be formatted
and inserted into the output instead of the replacement field.  The
`field_name' is optionally followed by a `conversion' field, which is
preceded by an exclamation point ‘'!'’, and a `format_spec', which is
preceded by a colon ‘':'’.  These specify a non-default format for the
replacement value.

See also the *note Format Specification Mini-Language: c0f. section.

The `field_name' itself begins with an `arg_name' that is either a
number or a keyword.  If it’s a number, it refers to a positional
argument, and if it’s a keyword, it refers to a named keyword argument.
If the numerical arg_names in a format string are 0, 1, 2, ...  in
sequence, they can all be omitted (not just some) and the numbers 0, 1,
2, ...  will be automatically inserted in that order.  Because
`arg_name' is not quote-delimited, it is not possible to specify
arbitrary dictionary keys (e.g., the strings ‘'10'’ or ‘':-]'’) within a
format string.  The `arg_name' can be followed by any number of index or
attribute expressions.  An expression of the form ‘'.name'’ selects the
named attribute using *note getattr(): 55f, while an expression of the
form ‘'[index]'’ does an index lookup using *note __getitem__(): 88d.

Changed in version 3.1: The positional argument specifiers can be
omitted, so ‘'{} {}'’ is equivalent to ‘'{0} {1}'’.

Some simple format string examples:

     "First, thou shalt count to {0}" # References first positional argument
     "Bring me a {}"                  # Implicitly references the first positional argument
     "From {} to {}"                  # Same as "From {0} to {1}"
     "My quest is {name}"             # References keyword argument 'name'
     "Weight in tons {0.weight}"      # 'weight' attribute of first positional arg
     "Units destroyed: {players[0]}"  # First element of keyword argument 'players'.

The `conversion' field causes a type coercion before formatting.
Normally, the job of formatting a value is done by the *note
__format__(): 308. method of the value itself.  However, in some cases
it is desirable to force a type to be formatted as a string, overriding
its own definition of formatting.  By converting the value to a string
before calling *note __format__(): 308, the normal formatting logic is
bypassed.

Three conversion flags are currently supported: ‘'!s'’ which calls *note
str(): 178. on the value, ‘'!r'’ which calls *note repr(): 3db. and
‘'!a'’ which calls *note ascii(): 7c8.

Some examples:

     "Harold's a clever {0!s}"        # Calls str() on the argument first
     "Bring out the holy {name!r}"    # Calls repr() on the argument first
     "More {!a}"                      # Calls ascii() on the argument first

The `format_spec' field contains a specification of how the value should
be presented, including such details as field width, alignment, padding,
decimal precision and so on.  Each value type can define its own
"formatting mini-language" or interpretation of the `format_spec'.

Most built-in types support a common formatting mini-language, which is
described in the next section.

A `format_spec' field can also include nested replacement fields within
it.  These nested replacement fields can contain only a field name;
conversion flags and format specifications are not allowed.  The
replacement fields within the format_spec are substituted before the
`format_spec' string is interpreted.  This allows the formatting of a
value to be dynamically specified.

See the *note Format examples: edc. section for some examples.

* Menu:

* Format Specification Mini-Language:: 
* Format examples:: 


File: python.info,  Node: Format Specification Mini-Language,  Next: Format examples,  Up: Format String Syntax

5.6.1.4 Format Specification Mini-Language
..........................................

"Format specifications" are used within replacement fields contained
within a format string to define how individual values are presented
(see *note Format String Syntax: 78a.).  They can also be passed
directly to the built-in *note format(): 556. function.  Each
formattable type may define how the format specification is to be
interpreted.

Most built-in types implement the following options for format
specifications, although some of the formatting options are only
supported by the numeric types.

A general convention is that an empty format string (‘""’) produces the
same result as if you had called *note str(): 178. on the value.  A
non-empty format string typically modifies the result.

The general form of a `standard format specifier' is:

     format_spec ::= [[fill]align][sign][#][0][width][,][.precision][type]
     fill        ::= <any character>
     align       ::= "<" | ">" | "=" | "^"
     sign        ::= "+" | "-" | " "
     width       ::= integer
     precision   ::= integer
     type        ::= "b" | "c" | "d" | "e" | "E" | "f" | "F" | "g" | "G" | "n" | "o" | "s" | "x" | "X" | "%"

If a valid `align' value is specified, it can be preceded by a `fill'
character that can be any character and defaults to a space if omitted.
Note that it is not possible to use ‘{’ and ‘}’ as `fill' char while
using the *note str.format(): 557. method; this limitation however
doesn’t affect the *note format(): 556. function.

The meaning of the various alignment options is as follows:

     Option        Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'<'’         Forces the field to be left-aligned within the available
                   space (this is the default for most objects).
                   
                   
     ‘'>'’         Forces the field to be right-aligned within the available
                   space (this is the default for numbers).
                   
                   
     ‘'='’         Forces the padding to be placed after the sign (if any) but
                   before the digits.  This is used for printing fields in the
                   form ’+000000120’.  This alignment option is only valid for
                   numeric types.
                   
                   
     ‘'^'’         Forces the field to be centered within the available space.
                   

Note that unless a minimum field width is defined, the field width will
always be the same size as the data to fill it, so that the alignment
option has no meaning in this case.

The `sign' option is only valid for number types, and can be one of the
following:

     Option        Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'+'’         indicates that a sign should be used for both positive as
                   well as negative numbers.
                   
                   
     ‘'-'’         indicates that a sign should be used only for negative
                   numbers (this is the default behavior).
                   
                   
     space         indicates that a leading space should be used on positive
                   numbers, and a minus sign on negative numbers.
                   

The ‘'#'’ option causes the "alternate form" to be used for the
conversion.  The alternate form is defined differently for different
types.  This option is only valid for integer, float, complex and
Decimal types.  For integers, when binary, octal, or hexadecimal output
is used, this option adds the prefix respective ‘'0b'’, ‘'0o'’, or
‘'0x'’ to the output value.  For floats, complex and Decimal the
alternate form causes the result of the conversion to always contain a
decimal-point character, even if no digits follow it.  Normally, a
decimal-point character appears in the result of these conversions only
if a digit follows it.  In addition, for ‘'g'’ and ‘'G'’ conversions,
trailing zeros are not removed from the result.

The ‘','’ option signals the use of a comma for a thousands separator.
For a locale aware separator, use the ‘'n'’ integer presentation type
instead.

Changed in version 3.1: Added the ‘','’ option (see also PEP 378(1)).

`width' is a decimal integer defining the minimum field width.  If not
specified, then the field width will be determined by the content.

Preceding the `width' field by a zero (‘'0'’) character enables
sign-aware zero-padding for numeric types.  This is equivalent to a
`fill' character of ‘'0'’ with an `alignment' type of ‘'='’.

The `precision' is a decimal number indicating how many digits should be
displayed after the decimal point for a floating point value formatted
with ‘'f'’ and ‘'F'’, or before and after the decimal point for a
floating point value formatted with ‘'g'’ or ‘'G'’.  For non-number
types the field indicates the maximum field size - in other words, how
many characters will be used from the field content.  The `precision' is
not allowed for integer values.

Finally, the `type' determines how the data should be presented.

The available string presentation types are:

     Type          Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'s'’         String format.  This is the default type for strings and may
                   be omitted.
                   
                   
     None          The same as ‘'s'’.
                   

The available integer presentation types are:

     Type          Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'b'’         Binary format.  Outputs the number in base 2.
                   
                   
     ‘'c'’         Character.  Converts the integer to the corresponding
                   unicode character before printing.
                   
                   
     ‘'d'’         Decimal Integer.  Outputs the number in base 10.
                   
                   
     ‘'o'’         Octal format.  Outputs the number in base 8.
                   
                   
     ‘'x'’         Hex format.  Outputs the number in base 16, using lower-
                   case letters for the digits above 9.
                   
                   
     ‘'X'’         Hex format.  Outputs the number in base 16, using upper-
                   case letters for the digits above 9.
                   
                   
     ‘'n'’         Number.  This is the same as ‘'d'’, except that it uses the
                   current locale setting to insert the appropriate number
                   separator characters.
                   
                   
     None          The same as ‘'d'’.
                   

In addition to the above presentation types, integers can be formatted
with the floating point presentation types listed below (except ‘'n'’
and None).  When doing so, *note float(): 327. is used to convert the
integer to a floating point number before formatting.

The available presentation types for floating point and decimal values
are:

     Type          Meaning
                   
     -----------------------------------------------------------------------------
                   
     ‘'e'’         Exponent notation.  Prints the number in scientific notation
                   using the letter ’e’ to indicate the exponent.  The default
                   precision is ‘6’.
                   
                   
     ‘'E'’         Exponent notation.  Same as ‘'e'’ except it uses an upper
                   case ’E’ as the separator character.
                   
                   
     ‘'f'’         Fixed point.  Displays the number as a fixed-point number.
                   The default precision is ‘6’.
                   
                   
     ‘'F'’         Fixed point.  Same as ‘'f'’, but converts ‘nan’ to ‘NAN’ and
                   ‘inf’ to ‘INF’.
                   
                   
     ‘'g'’         General format.  For a given precision ‘p >= 1’, this rounds
                   the number to ‘p’ significant digits and then formats the
                   result in either fixed-point format or in scientific
                   notation, depending on its magnitude.
                   
                   The precise rules are as follows: suppose that the result
                   formatted with presentation type ‘'e'’ and precision ‘p-1’
                   would have exponent ‘exp’.  Then if ‘-4 <= exp < p’, the
                   number is formatted with presentation type ‘'f'’ and
                   precision ‘p-1-exp’.  Otherwise, the number is formatted
                   with presentation type ‘'e'’ and precision ‘p-1’.  In both
                   cases insignificant trailing zeros are removed from the
                   significand, and the decimal point is also removed if there
                   are no remaining digits following it.
                   
                   Positive and negative infinity, positive and negative zero,
                   and nans, are formatted as ‘inf’, ‘-inf’, ‘0’, ‘-0’ and
                   ‘nan’ respectively, regardless of the precision.
                   
                   A precision of ‘0’ is treated as equivalent to a precision
                   of ‘1’.  The default precision is ‘6’.
                   
                   
     ‘'G'’         General format.  Same as ‘'g'’ except switches to ‘'E'’ if
                   the number gets too large.  The representations of infinity
                   and NaN are uppercased, too.
                   
                   
     ‘'n'’         Number.  This is the same as ‘'g'’, except that it uses the
                   current locale setting to insert the appropriate number
                   separator characters.
                   
                   
     ‘'%'’         Percentage.  Multiplies the number by 100 and displays in
                   fixed (‘'f'’) format, followed by a percent sign.
                   
                   
     None          Similar to ‘'g'’, except that fixed-point notation, when
                   used, has at least one digit past the decimal point.  The
                   default precision is as high as needed to represent the
                   particular value.  The overall effect is to match the output
                   of *note str(): 178. as altered by the other format
                   modifiers.
                   

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0378


File: python.info,  Node: Format examples,  Prev: Format Specification Mini-Language,  Up: Format String Syntax

5.6.1.5 Format examples
.......................

This section contains examples of the new format syntax and comparison
with the old ‘%’-formatting.

In most of the cases the syntax is similar to the old ‘%’-formatting,
with the addition of the ‘{}’ and with ‘:’ used instead of ‘%’.  For
example, ‘'%03.2f'’ can be translated to ‘'{:03.2f}'’.

The new format syntax also supports new and different options, shown in
the follow examples.

Accessing arguments by position:

     >>> '{0}, {1}, {2}'.format('a', 'b', 'c')
     'a, b, c'
     >>> '{}, {}, {}'.format('a', 'b', 'c')  # 3.1+ only
     'a, b, c'
     >>> '{2}, {1}, {0}'.format('a', 'b', 'c')
     'c, b, a'
     >>> '{2}, {1}, {0}'.format(*'abc')      # unpacking argument sequence
     'c, b, a'
     >>> '{0}{1}{0}'.format('abra', 'cad')   # arguments' indices can be repeated
     'abracadabra'

Accessing arguments by name:

     >>> 'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-115.81W')
     'Coordinates: 37.24N, -115.81W'
     >>> coord = {'latitude': '37.24N', 'longitude': '-115.81W'}
     >>> 'Coordinates: {latitude}, {longitude}'.format(**coord)
     'Coordinates: 37.24N, -115.81W'

Accessing arguments’ attributes:

     >>> c = 3-5j
     >>> ('The complex number {0} is formed from the real part {0.real} '
     ...  'and the imaginary part {0.imag}.').format(c)
     'The complex number (3-5j) is formed from the real part 3.0 and the imaginary part -5.0.'
     >>> class Point:
     ...     def __init__(self, x, y):
     ...         self.x, self.y = x, y
     ...     def __str__(self):
     ...         return 'Point({self.x}, {self.y})'.format(self=self)
     ...
     >>> str(Point(4, 2))
     'Point(4, 2)'

Accessing arguments’ items:

     >>> coord = (3, 5)
     >>> 'X: {0[0]};  Y: {0[1]}'.format(coord)
     'X: 3;  Y: 5'

Replacing ‘%s’ and ‘%r’:

     >>> "repr() shows quotes: {!r}; str() doesn't: {!s}".format('test1', 'test2')
     "repr() shows quotes: 'test1'; str() doesn't: test2"

Aligning the text and specifying a width:

     >>> '{:<30}'.format('left aligned')
     'left aligned                  '
     >>> '{:>30}'.format('right aligned')
     '                 right aligned'
     >>> '{:^30}'.format('centered')
     '           centered           '
     >>> '{:*^30}'.format('centered')  # use '*' as a fill char
     '***********centered***********'

Replacing ‘%+f’, ‘%-f’, and ‘% f’ and specifying a sign:

     >>> '{:+f}; {:+f}'.format(3.14, -3.14)  # show it always
     '+3.140000; -3.140000'
     >>> '{: f}; {: f}'.format(3.14, -3.14)  # show a space for positive numbers
     ' 3.140000; -3.140000'
     >>> '{:-f}; {:-f}'.format(3.14, -3.14)  # show only the minus -- same as '{:f}; {:f}'
     '3.140000; -3.140000'

Replacing ‘%x’ and ‘%o’ and converting the value to different bases:

     >>> # format also supports binary numbers
     >>> "int: {0:d};  hex: {0:x};  oct: {0:o};  bin: {0:b}".format(42)
     'int: 42;  hex: 2a;  oct: 52;  bin: 101010'
     >>> # with 0x, 0o, or 0b as prefix:
     >>> "int: {0:d};  hex: {0:#x};  oct: {0:#o};  bin: {0:#b}".format(42)
     'int: 42;  hex: 0x2a;  oct: 0o52;  bin: 0b101010'

Using the comma as a thousands separator:

     >>> '{:,}'.format(1234567890)
     '1,234,567,890'

Expressing a percentage:

     >>> points = 19
     >>> total = 22
     >>> 'Correct answers: {:.2%}'.format(points/total)
     'Correct answers: 86.36%'

Using type-specific formatting:

     >>> import datetime
     >>> d = datetime.datetime(2010, 7, 4, 12, 15, 58)
     >>> '{:%Y-%m-%d %H:%M:%S}'.format(d)
     '2010-07-04 12:15:58'

Nesting arguments and more complex examples:

     >>> for align, text in zip('<^>', ['left', 'center', 'right']):
     ...     '{0:{fill}{align}16}'.format(text, fill=align, align=align)
     ...
     'left<<<<<<<<<<<<'
     '^^^^^center^^^^^'
     '>>>>>>>>>>>right'
     >>>
     >>> octets = [192, 168, 0, 1]
     >>> '{:02X}{:02X}{:02X}{:02X}'.format(*octets)
     'C0A80001'
     >>> int(_, 16)
     3232235521
     >>>
     >>> width = 5
     >>> for num in range(5,12): #doctest: +NORMALIZE_WHITESPACE
     ...     for base in 'dXob':
     ...         print('{0:{width}{base}}'.format(num, base=base, width=width), end=' ')
     ...     print()
     ...
         5     5     5   101
         6     6     6   110
         7     7     7   111
         8     8    10  1000
         9     9    11  1001
        10     A    12  1010
        11     B    13  1011


File: python.info,  Node: Template strings,  Next: Helper functions,  Prev: Format String Syntax,  Up: string --- Common string operations

5.6.1.6 Template strings
........................

Templates provide simpler string substitutions as described in PEP
292(1).  Instead of the normal ‘%’-based substitutions, Templates
support ‘$’-based substitutions, using the following rules:

   * ‘$$’ is an escape; it is replaced with a single ‘$’.

   * ‘$identifier’ names a substitution placeholder matching a mapping
     key of ‘"identifier"’.  By default, ‘"identifier"’ must spell a
     Python identifier.  The first non-identifier character after the
     ‘$’ character terminates this placeholder specification.

   * ‘${identifier}’ is equivalent to ‘$identifier’.  It is required
     when valid identifier characters follow the placeholder but are not
     part of the placeholder, such as ‘"${noun}ification"’.

Any other appearance of ‘$’ in the string will result in a *note
ValueError: 321. being raised.

The *note string: f1. module provides a *note Template: 5aa. class that
implements these rules.  The methods of *note Template: 5aa. are:

 -- Class: string.Template (template)

     The constructor takes a single argument which is the template
     string.

      -- Method: substitute (mapping, **kwds)

          Performs the template substitution, returning a new string.
          `mapping' is any dictionary-like object with keys that match
          the placeholders in the template.  Alternatively, you can
          provide keyword arguments, where the keywords are the
          placeholders.  When both `mapping' and `kwds' are given and
          there are duplicates, the placeholders from `kwds' take
          precedence.

      -- Method: safe_substitute (mapping, **kwds)

          Like *note substitute(): aec, except that if placeholders are
          missing from `mapping' and `kwds', instead of raising a *note
          KeyError: 706. exception, the original placeholder will appear
          in the resulting string intact.  Also, unlike with *note
          substitute(): aec, any other appearances of the ‘$’ will
          simply return ‘$’ instead of raising *note ValueError: 321.

          While other exceptions may still occur, this method is called
          "safe" because substitutions always tries to return a usable
          string instead of raising an exception.  In another sense,
          *note safe_substitute(): aed. may be anything other than safe,
          since it will silently ignore malformed templates containing
          dangling delimiters, unmatched braces, or placeholders that
          are not valid Python identifiers.

     *note Template: 5aa. instances also provide one public data
     attribute:

      -- Attribute: template

          This is the object passed to the constructor’s `template'
          argument.  In general, you shouldn’t change it, but read-only
          access is not enforced.

Here is an example of how to use a Template:

     >>> from string import Template
     >>> s = Template('$who likes $what')
     >>> s.substitute(who='tim', what='kung pao')
     'tim likes kung pao'
     >>> d = dict(who='tim')
     >>> Template('Give $who $100').substitute(d)
     Traceback (most recent call last):
     ...
     ValueError: Invalid placeholder in string: line 1, col 11
     >>> Template('$who likes $what').substitute(d)
     Traceback (most recent call last):
     ...
     KeyError: 'what'
     >>> Template('$who likes $what').safe_substitute(d)
     'tim likes $what'

Advanced usage: you can derive subclasses of *note Template: 5aa. to
customize the placeholder syntax, delimiter character, or the entire
regular expression used to parse template strings.  To do this, you can
override these class attributes:

   * `delimiter' – This is the literal string describing a placeholder
     introducing delimiter.  The default value is ‘$’.  Note that this
     should `not' be a regular expression, as the implementation will
     call *note re.escape(): ee9. on this string as needed.

   * `idpattern' – This is the regular expression describing the pattern
     for non-braced placeholders (the braces will be added automatically
     as appropriate).  The default value is the regular expression
     ‘[_a-z][_a-z0-9]*’.

   * `flags' – The regular expression flags that will be applied when
     compiling the regular expression used for recognizing
     substitutions.  The default value is ‘re.IGNORECASE’.  Note that
     ‘re.VERBOSE’ will always be added to the flags, so custom
     `idpattern's must follow conventions for verbose regular
     expressions.

     New in version 3.2.

Alternatively, you can provide the entire regular expression pattern by
overriding the class attribute `pattern'.  If you do this, the value
must be a regular expression object with four named capturing groups.
The capturing groups correspond to the rules given above, along with the
invalid placeholder rule:

   * `escaped' – This group matches the escape sequence, e.g.  ‘$$’, in
     the default pattern.

   * `named' – This group matches the unbraced placeholder name; it
     should not include the delimiter in capturing group.

   * `braced' – This group matches the brace enclosed placeholder name;
     it should not include either the delimiter or braces in the
     capturing group.

   * `invalid' – This group matches any other delimiter pattern (usually
     a single delimiter), and it should appear last in the regular
     expression.

   ---------- Footnotes ----------

   (1) https://www.python.org/dev/peps/pep-0292


File: python.info,  Node: Helper functions,  Prev: Template strings,  Up: string --- Common string operations

5.6.1.7 Helper functions
........................

 -- Function: string.capwords (s, sep=None)

     Split the argument into words using *note str.split(): dff,
     capitalize each word using *note str.capitalize(): de3, and join
     the capitalized words using *note str.join(): dd6.  If the optional
     second argument `sep' is absent or ‘None’, runs of whitespace
     characters are replaced by a single space and leading and trailing
     whitespace are removed, otherwise `sep' is used to split and join
     the words.


File: python.info,  Node: re --- Regular expression operations,  Next: difflib --- Helpers for computing deltas,  Prev: string --- Common string operations,  Up: Text Processing Services

5.6.2 ‘re’ — Regular expression operations
------------------------------------------

This module provides regular expression matching operations similar to
those found in Perl.

Both patterns and strings to be searched can be Unicode strings as well
as 8-bit strings.  However, Unicode strings and 8-bit strings cannot be
mixed: that is, you cannot match an Unicode string with a byte pattern
or vice-versa; similarly, when asking for a substitution, the
replacement string must be of the same type as both the pattern and the
search string.

Regular expressions use the backslash character (‘'\'’) to indicate
special forms or to allow special characters to be used without invoking
their special meaning.  This collides with Python’s usage of the same
character for the same purpose in string literals; for example, to match
a literal backslash, one might have to write ‘'\\\\'’ as the pattern
string, because the regular expression must be ‘\\’, and each backslash
must be expressed as ‘\\’ inside a regular Python string literal.

The solution is to use Python’s raw string notation for regular
expression patterns; backslashes are not handled in any special way in a
string literal prefixed with ‘'r'’.  So ‘r"\n"’ is a two-character
string containing ‘'\'’ and ‘'n'’, while ‘"\n"’ is a one-character
string containing a newline.  Usually patterns will be expressed in
Python code using this raw string notation.

It is important to note that most regular expression operations are
available as module-level functions and methods on *note compiled
regular expressions: 235.  The functions are shortcuts that don’t
require you to compile a regex object first, but miss some fine-tuning
parameters.

* Menu:

* Regular Expression Syntax:: 
* Module Contents:: 
* Regular Expression Objects:: 
* Match Objects:: 
* Regular Expression Examples:: 


File: python.info,  Node: Regular Expression Syntax,  Next: Module Contents,  Up: re --- Regular expression operations

5.6.2.1 Regular Expression Syntax
.................................

A regular expression (or RE) specifies a set of strings that matches it;
the functions in this module let you check if a particular string
matches a given regular expression (or if a given regular expression
matches a particular string, which comes down to the same thing).

Regular expressions can be concatenated to form new regular expressions;
if `A' and `B' are both regular expressions, then `AB' is also a regular
expression.  In general, if a string `p' matches `A' and another string
`q' matches `B', the string `pq' will match AB. This holds unless `A' or
`B' contain low precedence operations; boundary conditions between `A'
and `B'; or have numbered group references.  Thus, complex expressions
can easily be constructed from simpler primitive expressions like the
ones described here.  For details of the theory and implementation of
regular expressions, consult the Friedl book referenced above, or almost
any textbook about compiler construction.

A brief explanation of the format of regular expressions follows.  For
further information and a gentler presentation, consult the *note
Regular Expression HOWTO: ef0.

Regular expressions can contain both special and ordinary characters.
Most ordinary characters, like ‘'A'’, ‘'a'’, or ‘'0'’, are the simplest
regular expressions; they simply match themselves.  You can concatenate
ordinary characters, so ‘last’ matches the string ‘'last'’.  (In the
rest of this section, we’ll write RE’s in ‘this special style’, usually
without quotes, and strings to be matched ‘'in single quotes'’.)

Some characters, like ‘'|'’ or ‘'('’, are special.  Special characters
either stand for classes of ordinary characters, or affect how the
regular expressions around them are interpreted.  Regular expression
pattern strings may not contain null bytes, but can specify the null
byte using a ‘\number’ notation such as ‘'\x00'’.

The special characters are:

‘'.'’

     (Dot.)  In the default mode, this matches any character except a
     newline.  If the *note DOTALL: ef1. flag has been specified, this
     matches any character including a newline.

‘'^'’

     (Caret.)  Matches the start of the string, and in *note MULTILINE:
     ef2. mode also matches immediately after each newline.

‘'$'’

     Matches the end of the string or just before the newline at the end
     of the string, and in *note MULTILINE: ef2. mode also matches
     before a newline.  ‘foo’ matches both ’foo’ and ’foobar’, while the
     regular expression ‘foo$’ matches only ’foo’.  More interestingly,
     searching for ‘foo.$’ in ‘'foo1\nfoo2\n'’ matches ’foo2’ normally,
     but ’foo1’ in *note MULTILINE: ef2. mode; searching for a single
     ‘$’ in ‘'foo\n'’ will find two (empty) matches: one just before the
     newline, and one at the end of the string.

‘'*'’

     Causes the resulting RE to match 0 or more repetitions of the
     preceding RE, as many repetitions as are possible.  ‘ab*’ will
     match ’a’, ’ab’, or ’a’ followed by any number of ’b’s.

‘'+'’

     Causes the resulting RE to match 1 or more repetitions of the
     preceding RE. ‘ab+’ will match ’a’ followed by any non-zero number
     of ’b’s; it will not match just ’a’.

‘'?'’

     Causes the resulting RE to match 0 or 1 repetitions of the
     preceding RE. ‘ab?’ will match either ’a’ or ’ab’.

‘*?’, ‘+?’, ‘??’

     The ‘'*'’, ‘'+'’, and ‘'?'’ qualifiers are all `greedy'; they match
     as much text as possible.  Sometimes this behaviour isn’t desired;
     if the RE ‘<.*>’ is matched against ‘'<H1>title</H1>'’, it will
     match the entire string, and not just ‘'<H1>'’.  Adding ‘'?'’ after
     the qualifier makes it perform the match in `non-greedy' or
     `minimal' fashion; as `few' characters as possible will be matched.
     Using ‘.*?’ in the previous expression will match only ‘'<H1>'’.

‘{m}’

     Specifies that exactly `m' copies of the previous RE should be
     matched; fewer matches cause the entire RE not to match.  For
     example, ‘a{6}’ will match exactly six ‘'a'’ characters, but not
     five.

‘{m,n}’

     Causes the resulting RE to match from `m' to `n' repetitions of the
     preceding RE, attempting to match as many repetitions as possible.
     For example, ‘a{3,5}’ will match from 3 to 5 ‘'a'’ characters.
     Omitting `m' specifies a lower bound of zero, and omitting `n'
     specifies an infinite upper bound.  As an example, ‘a{4,}b’ will
     match ‘aaaab’ or a thousand ‘'a'’ characters followed by a ‘b’, but
     not ‘aaab’.  The comma may not be omitted or the modifier would be
     confused with the previously described form.

‘{m,n}?’

     Causes the resulting RE to match from `m' to `n' repetitions of the
     preceding RE, attempting to match as `few' repetitions as possible.
     This is the non-greedy version of the previous qualifier.  For
     example, on the 6-character string ‘'aaaaaa'’, ‘a{3,5}’ will match
     5 ‘'a'’ characters, while ‘a{3,5}?’ will only match 3 characters.

‘'\'’

     Either escapes special characters (permitting you to match
     characters like ‘'*'’, ‘'?'’, and so forth), or signals a special
     sequence; special sequences are discussed below.

     If you’re not using a raw string to express the pattern, remember
     that Python also uses the backslash as an escape sequence in string
     literals; if the escape sequence isn’t recognized by Python’s
     parser, the backslash and subsequent character are included in the
     resulting string.  However, if Python would recognize the resulting
     sequence, the backslash should be repeated twice.  This is
     complicated and hard to understand, so it’s highly recommended that
     you use raw strings for all but the simplest expressions.

‘[]’

     Used to indicate a set of characters.  In a set:

        * Characters can be listed individually, e.g.  ‘[amk]’ will
          match ‘'a'’, ‘'m'’, or ‘'k'’.

        * Ranges of characters can be indicated by giving two characters
          and separating them by a ‘'-'’, for example ‘[a-z]’ will match
          any lowercase ASCII letter, ‘[0-5][0-9]’ will match all the
          two-digits numbers from ‘00’ to ‘59’, and ‘[0-9A-Fa-f]’ will
          match any hexadecimal digit.  If ‘-’ is escaped (e.g.
          ‘[a\-z]’) or if it’s placed as the first or last character
          (e.g.  ‘[a-]’), it will match a literal ‘'-'’.

        * Special characters lose their special meaning inside sets.
          For example, ‘[(+*)]’ will match any of the literal characters
          ‘'('’, ‘'+'’, ‘'*'’, or ‘')'’.

        * Character classes such as ‘\w’ or ‘\S’ (defined below) are
          also accepted inside a set, although the characters they match
          depends on whether *note ASCII: ef3. or *note LOCALE: ef4.
          mode is in force.

        * Characters that are not within a range can be matched by
          `complementing' the set.  If the first character of the set is
          ‘'^'’, all the characters that are `not' in the set will be
          matched.  For example, ‘[^5]’ will match any character except
          ‘'5'’, and ‘[^^]’ will match any character except ‘'^'’.  ‘^’
          has no special meaning if it’s not the first character in the
          set.

        * To match a literal ‘']'’ inside a set, precede it with a
          backslash, or place it at the beginning of the set.  For
          example, both ‘[()[\]{}]’ and ‘[]()[{}]’ will both match a
          parenthesis.

‘'|'’

     ‘A|B’, where A and B can be arbitrary REs, creates a regular
     expression that will match either A or B. An arbitrary number of
     REs can be separated by the ‘'|'’ in this way.  This can be used
     inside groups (see below) as well.  As the target string is
     scanned, REs separated by ‘'|'’ are tried from left to right.  When
     one pattern completely matches, that branch is accepted.  This
     means that once ‘A’ matches, ‘B’ will not be tested further, even
     if it would produce a longer overall match.  In other words, the
     ‘'|'’ operator is never greedy.  To match a literal ‘'|'’, use
     ‘\|’, or enclose it inside a character class, as in ‘[|]’.

‘(...)’

     Matches whatever regular expression is inside the parentheses, and
     indicates the start and end of a group; the contents of a group can
     be retrieved after a match has been performed, and can be matched
     later in the string with the ‘\number’ special sequence, described
     below.  To match the literals ‘'('’ or ‘')'’, use ‘\(’ or ‘\)’, or
     enclose them inside a character class: ‘[(] [)]’.

‘(?...)’

     This is an extension notation (a ‘'?'’ following a ‘'('’ is not
     meaningful otherwise).  The first character after the ‘'?'’
     determines what the meaning and further syntax of the construct is.
     Extensions usually do not create a new group; ‘(?P<name>...)’ is
     the only exception to this rule.  Following are the currently
     supported extensions.

‘(?aiLmsux)’

     (One or more letters from the set ‘'a'’, ‘'i'’, ‘'L'’, ‘'m'’,
     ‘'s'’, ‘'u'’, ‘'x'’.)  The group matches the empty string; the
     letters set the corresponding flags: *note re.A: ef5. (ASCII-only
     matching), *note re.I: ef6. (ignore case), *note re.L: ef7. (locale
     dependent), *note re.M: ef8. (multi-line), *note re.S: ef9. (dot
     matches all), and *note re.X: efa. (verbose), for the entire
     regular expression.  (The flags are described in *note Module
     Contents: efb.)  This is useful if you wish to include the flags as
     part of the regular expression, instead of passing a `flag'
     argument to the *note re.compile(): efc. function.

     Note that the ‘(?x)’ flag changes how the expression is parsed.  It
     should be used first in the expression string, or after one or more
     whitespace characters.  If there are non-whitespace characters
     before the flag, the results are undefined.

‘(?:...)’

     A non-capturing version of regular parentheses.  Matches whatever
     regular expression is inside the parentheses, but the substring
     matched by the group `cannot' be retrieved after performing a match
     or referenced later in the pattern.

‘(?P<name>...)’

     Similar to regular parentheses, but the substring matched by the
     group is accessible via the symbolic group name `name'.  Group
     names must be valid Python identifiers, and each group name must be
     defined only once within a regular expression.  A symbolic group is
     also a numbered group, just as if the group were not named.

     Named groups can be referenced in three contexts.  If the pattern
     is ‘(?P<quote>['"]).*?(?P=quote)’ (i.e.  matching a string quoted
     with either single or double quotes):

     Context of reference to group "quote"       Ways to reference it
                                                 
     -----------------------------------------------------------------------------------
                                                 
     in the same pattern itself                     * ‘(?P=quote)’ (as shown)
                                                 
                                                    * ‘\1’
                                                 
                                                 
     when processing match object ‘m’               * ‘m.group('quote')’
                                                 
                                                    * ‘m.end('quote')’ (etc.)
                                                 
                                                 
     in a string passed to the ‘repl’ argument      * ‘\g<quote>’
     of ‘re.sub()’                               
                                                    * ‘\g<1>’
                                                 
                                                    * ‘\1’
                                                 

‘(?P=name)’

     A backreference to a named group; it matches whatever text was
     matched by the earlier group named `name'.

‘(?#...)’

     A comment; the contents of the parentheses are simply ignored.

‘(?=...)’

     Matches if ‘...’ matches next, but doesn’t consume any of the
     string.  This is called a lookahead assertion.  For example, ‘Isaac
     (?=Asimov)’ will match ‘'Isaac '’ only if it’s followed by
     ‘'Asimov'’.

‘(?!...)’

     Matches if ‘...’ doesn’t match next.  This is a negative lookahead
     assertion.  For example, ‘Isaac (?!Asimov)’ will match ‘'Isaac '’
     only if it’s `not' followed by ‘'Asimov'’.

‘(?<=...)’

     Matches if the current position in the string is preceded by a
     match for ‘...’ that ends at the current position.  This is called
     a `positive lookbehind assertion'.  ‘(?<=abc)def’ will find a match
     in ‘abcdef’, since the lookbehind will back up 3 characters and
     check if the contained pattern matches.  The contained pattern must
     only match strings of some fixed length, meaning that ‘abc’ or
     ‘a|b’ are allowed, but ‘a*’ and ‘a{3,4}’ are not.  Note that
     patterns which start with positive lookbehind assertions will not
     match at the beginning of the string being searched; you will most
     likely want to use the *note search(): 5fc. function rather than
     the *note match(): 5fd. function:

          >>> import re
          >>> m = re.search('(?<=abc)def', 'abcdef')
          >>> m.group(0)
          'def'

     This example looks for a word following a hyphen:

          >>> m = re.search('(?<=-)\w+', 'spam-egg')
          >>> m.group(0)
          'egg'

‘(?<!...)’

     Matches if the current position in the string is not preceded by a
     match for ‘...’.  This is called a `negative lookbehind assertion'.
     Similar to positive lookbehind assertions, the contained pattern
     must only match strings of some fixed length.  Patterns which start
     with negative lookbehind assertions may match at the beginning of
     the string being searched.

‘(?(id/name)yes-pattern|no-pattern)’

     Will try to match with ‘yes-pattern’ if the group with given `id'
     or `name' exists, and with ‘no-pattern’ if it doesn’t.
     ‘no-pattern’ is optional and can be omitted.  For example,
     ‘(<)?(\w+@\w+(?:\.\w+)+)(?(1)>|$)’ is a poor email matching
     pattern, which will match with ‘'<user@host.com>'’ as well as
     ‘'user@host.com'’, but not with ‘'<user@host.com'’ nor
     ‘'user@host.com>'’.

The special sequences consist of ‘'\'’ and a character from the list
below.  If the ordinary character is not on the list, then the resulting
RE will match the second character.  For example, ‘\$’ matches the
character ‘'$'’.

‘\number’

     Matches the contents of the group of the same number.  Groups are
     numbered starting from 1.  For example, ‘(.+) \1’ matches ‘'the
     the'’ or ‘'55 55'’, but not ‘'thethe'’ (note the space after the
     group).  This special sequence can only be used to match one of the
     first 99 groups.  If the first digit of `number' is 0, or `number'
     is 3 octal digits long, it will not be interpreted as a group
     match, but as the character with octal value `number'.  Inside the
     ‘'['’ and ‘']'’ of a character class, all numeric escapes are
     treated as characters.

‘\A’

     Matches only at the start of the string.

‘\b’

     Matches the empty string, but only at the beginning or end of a
     word.  A word is defined as a sequence of Unicode alphanumeric or
     underscore characters, so the end of a word is indicated by
     whitespace or a non-alphanumeric, non-underscore Unicode character.
     Note that formally, ‘\b’ is defined as the boundary between a ‘\w’
     and a ‘\W’ character (or vice versa), or between ‘\w’ and the
     beginning/end of the string.  This means that ‘r'\bfoo\b'’ matches
     ‘'foo'’, ‘'foo.'’, ‘'(foo)'’, ‘'bar foo baz'’ but not ‘'foobar'’ or
     ‘'foo3'’.

     By default Unicode alphanumerics are the ones used, but this can be
     changed by using the *note ASCII: ef3. flag.  Inside a character
     range, ‘\b’ represents the backspace character, for compatibility
     with Python’s string literals.

‘\B’

     Matches the empty string, but only when it is `not' at the
     beginning or end of a word.  This means that ‘r'py\B'’ matches
     ‘'python'’, ‘'py3'’, ‘'py2'’, but not ‘'py'’, ‘'py.'’, or ‘'py!'’.
     ‘\B’ is just the opposite of ‘\b’, so word characters are Unicode
     alphanumerics or the underscore, although this can be changed by
     using the *note ASCII: ef3. flag.

‘\d’

     For Unicode (str) patterns:

          Matches any Unicode decimal digit (that is, any character in
          Unicode character category [Nd]).  This includes ‘[0-9]’, and
          also many other digit characters.  If the *note ASCII: ef3.
          flag is used only ‘[0-9]’ is matched (but the flag affects the
          entire regular expression, so in such cases using an explicit
          ‘[0-9]’ may be a better choice).

     For 8-bit (bytes) patterns:

          Matches any decimal digit; this is equivalent to ‘[0-9]’.

‘\D’

     Matches any character which is not a Unicode decimal digit.  This
     is the opposite of ‘\d’.  If the *note ASCII: ef3. flag is used
     this becomes the equivalent of ‘[^0-9]’ (but the flag affects the
     entire regular expression, so in such cases using an explicit
     ‘[^0-9]’ may be a better choice).

‘\s’

     For Unicode (str) patterns:

          Matches Unicode whitespace characters (which includes ‘[
          \t\n\r\f\v]’, and also many other characters, for example the
          non-breaking spaces mandated by typography rules in many
          languages).  If the *note ASCII: ef3. flag is used, only ‘[
          \t\n\r\f\v]’ is matched (but the flag affects the entire
          regular expression, so in such cases using an explicit ‘[
          \t\n\r\f\v]’ may be a better choice).

     For 8-bit (bytes) patterns:

          Matches characters considered whitespace in the ASCII
          character set; this is equivalent to ‘[ \t\n\r\f\v]’.

‘\S’

     Matches any character which is not a Unicode whitespace character.
     This is the opposite of ‘\s’.  If the *note ASCII: ef3. flag is
     used this becomes the equivalent of ‘[^ \t\n\r\f\v]’ (but the flag
     affects the entire regular expression, so in such cases using an
     explicit ‘[^ \t\n\r\f\v]’ may be a better choice).

‘\w’

     For Unicode (str) patterns:

          Matches Unicode word characters; this includes most characters
          that can be part of a word in any language, as well as numbers
          and the underscore.  If the *note ASCII: ef3. flag is used,
          only ‘[a-zA-Z0-9_]’ is matched (but the flag affects the
          entire regular expression, so in such cases using an explicit
          ‘[a-zA-Z0-9_]’ may be a better choice).

     For 8-bit (bytes) patterns:

          Matches characters considered alphanumeric in the ASCII
          character set; this is equivalent to ‘[a-zA-Z0-9_]’.

‘\W’

     Matches any character which is not a Unicode word character.  This
     is the opposite of ‘\w’.  If the *note ASCII: ef3. flag is used
     this becomes the equivalent of ‘[^a-zA-Z0-9_]’ (but the flag
     affects the entire regular expression, so in such cases using an
     explicit ‘[^a-zA-Z0-9_]’ may be a better choice).

‘\Z’

     Matches only at the end of the string.

Most of the standard escapes supported by Python string literals are
also accepted by the regular expression parser:

     \a      \b      \f      \n
     \r      \t      \u      \U
     \v      \x      \\

(Note that ‘\b’ is used to represent word boundaries, and means
"backspace" only inside character classes.)

‘'\u'’ and ‘'\U'’ escape sequences are only recognized in Unicode
patterns.  In bytes patterns they are not treated specially.

Octal escapes are included in a limited form.  If the first digit is a
0, or if there are three octal digits, it is considered an octal escape.
Otherwise, it is a group reference.  As for string literals, octal
escapes are always at most three digits in length.

Changed in version 3.3: The ‘'\u'’ and ‘'\U'’ escape sequences have been
added.

See also
........

Mastering Regular Expressions

     Book on regular expressions by Jeffrey Friedl, published by
     O’Reilly.  The second edition of the book no longer covers Python
     at all, but the first edition covered writing good regular
     expression patterns in great detail.


File: python.info,  Node: Module Contents,  Next: Regular Expression Objects,  Prev: Regular Expression Syntax,  Up: re --- Regular expression operations

5.6.2.2 Module Contents
.......................

The module defines several functions, constants, and an exception.  Some
of the functions are simplified versions of the full featured methods
for compiled regular expressions.  Most non-trivial applications always
use the compiled form.

 -- Function: re.compile (pattern, flags=0)

     Compile a regular expression pattern into a regular expression
     object, which can be used for matching using its *note match():
     efe. and *note search(): eff. methods, described below.

     The expression’s behaviour can be modified by specifying a `flags'
     value.  Values can be any of the following variables, combined
     using bitwise OR (the ‘|’ operator).

     The sequence

          prog = re.compile(pattern)
          result = prog.match(string)

     is equivalent to

          result = re.match(pattern, string)

     but using *note re.compile(): efc. and saving the resulting regular
     expression object for reuse is more efficient when the expression
     will be used several times in a single program.

          Note: The compiled versions of the most recent patterns passed
          to *note re.compile(): efc. and the module-level matching
          functions are cached, so programs that use only a few regular
          expressions at a time needn’t worry about compiling regular
          expressions.

 -- Data: re.A
 -- Data: re.ASCII

     Make ‘\w’, ‘\W’, ‘\b’, ‘\B’, ‘\d’, ‘\D’, ‘\s’ and ‘\S’ perform
     ASCII-only matching instead of full Unicode matching.  This is only
     meaningful for Unicode patterns, and is ignored for byte patterns.

     Note that for backward compatibility, the ‘re.U’ flag still exists
     (as well as its synonym ‘re.UNICODE’ and its embedded counterpart
     ‘(?u)’), but these are redundant in Python 3 since matches are
     Unicode by default for strings (and Unicode matching isn’t allowed
     for bytes).

 -- Data: re.DEBUG

     Display debug information about compiled expression.

 -- Data: re.I
 -- Data: re.IGNORECASE

     Perform case-insensitive matching; expressions like ‘[A-Z]’ will
     match lowercase letters, too.  This is not affected by the current
     locale and works for Unicode characters as expected.

 -- Data: re.L
 -- Data: re.LOCALE

     Make ‘\w’, ‘\W’, ‘\b’, ‘\B’, ‘\s’ and ‘\S’ dependent on the current
     locale.  The use of this flag is discouraged as the locale
     mechanism is very unreliable, and it only handles one "culture" at
     a time anyway; you should use Unicode matching instead, which is
     the default in Python 3 for Unicode (str) patterns.

 -- Data: re.M
 -- Data: re.MULTILINE

     When specified, the pattern character ‘'^'’ matches at the
     beginning of the string and at the beginning of each line
     (immediately following each newline); and the pattern character
     ‘'$'’ matches at the end of the string and at the end of each line
     (immediately preceding each newline).  By default, ‘'^'’ matches
     only at the beginning of the string, and ‘'$'’ only at the end of
     the string and immediately before the newline (if any) at the end
     of the string.

 -- Data: re.S
 -- Data: re.DOTALL

     Make the ‘'.'’ special character match any character at all,
     including a newline; without this flag, ‘'.'’ will match anything
     `except' a newline.

 -- Data: re.X
 -- Data: re.VERBOSE

     This flag allows you to write regular expressions that look nicer.
     Whitespace within the pattern is ignored, except when in a
     character class or preceded by an unescaped backslash, and, when a
     line contains a ‘'#'’ neither in a character class or preceded by
     an unescaped backslash, all characters from the leftmost such ‘'#'’
     through the end of the line are ignored.

     That means that the two following regular expression objects that
     match a decimal number are functionally equal:

          a = re.compile(r"""\d +  # the integral part
                             \.    # the decimal point
                             \d *  # some fractional digits""", re.X)
          b = re.compile(r"\d+\.\d*")

 -- Function: re.search (pattern, string, flags=0)

     Scan through `string' looking for the first location where the
     regular expression `pattern' produces a match, and return a
     corresponding *note match object: 236.  Return ‘None’ if no
     position in the string matches the pattern; note that this is
     different from finding a zero-length match at some point in the
     string.

 -- Function: re.match (pattern, string, flags=0)

     If zero or more characters at the beginning of `string' match the
     regular expression `pattern', return a corresponding *note match
     object: 236.  Return ‘None’ if the string does not match the
     pattern; note that this is different from a zero-length match.

     Note that even in *note MULTILINE: ef2. mode, *note re.match():
     5fd. will only match at the beginning of the string and not at the
     beginning of each line.

     If you want to locate a match anywhere in `string', use *note
     search(): 5fc. instead (see also *note search() vs.  match():
     f03.).

 -- Function: re.fullmatch (pattern, string, flags=0)

     If the whole `string' matches the regular expression `pattern',
     return a corresponding *note match object: 236.  Return ‘None’ if
     the string does not match the pattern; note that this is different
     from a zero-length match.

     New in version 3.4.

 -- Function: re.split (pattern, string, maxsplit=0, flags=0)

     Split `string' by the occurrences of `pattern'.  If capturing
     parentheses are used in `pattern', then the text of all groups in
     the pattern are also returned as part of the resulting list.  If
     `maxsplit' is nonzero, at most `maxsplit' splits occur, and the
     remainder of the string is returned as the final element of the
     list.

          >>> re.split('\W+', 'Words, words, words.')
          ['Words', 'words', 'words', '']
          >>> re.split('(\W+)', 'Words, words, words.')
          ['Words', ', ', 'words', ', ', 'words', '.', '']
          >>> re.split('\W+', 'Words, words, words.', 1)
          ['Words', 'words, words.']
          >>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE)
          ['0', '3', '9']

     If there are capturing groups in the separator and it matches at
     the start of the string, the result will start with an empty
     string.  The same holds for the end of the string:

          >>> re.split('(\W+)', '...words, words...')
          ['', '...', 'words', ', ', 'words', '...', '']

     That way, separator components are always found at the same
     relative indices within the result list.

     Note that `split' will never split a string on an empty pattern
     match.  For example:

          >>> re.split('x*', 'foo')
          ['foo']
          >>> re.split("(?m)^$", "foo\n\nbar\n")
          ['foo\n\nbar\n']

     Changed in version 3.1: Added the optional flags argument.

 -- Function: re.findall (pattern, string, flags=0)

     Return all non-overlapping matches of `pattern' in `string', as a
     list of strings.  The `string' is scanned left-to-right, and
     matches are returned in the order found.  If one or more groups are
     present in the pattern, return a list of groups; this will be a
     list of tuples if the pattern has more than one group.  Empty
     matches are included in the result unless they touch the beginning
     of another match.

 -- Function: re.finditer (pattern, string, flags=0)

     Return an *note iterator: d91. yielding *note match objects: 236.
     over all non-overlapping matches for the RE `pattern' in `string'.
     The `string' is scanned left-to-right, and matches are returned in
     the order found.  Empty matches are included in the result unless
     they touch the beginning of another match.

 -- Function: re.sub (pattern, repl, string, count=0, flags=0)

     Return the string obtained by replacing the leftmost
     non-overlapping occurrences of `pattern' in `string' by the
     replacement `repl'.  If the pattern isn’t found, `string' is
     returned unchanged.  `repl' can be a string or a function; if it is
     a string, any backslash escapes in it are processed.  That is, ‘\n’
     is converted to a single newline character, ‘\r’ is converted to a
     carriage return, and so forth.  Unknown escapes such as ‘\j’ are
     left alone.  Backreferences, such as ‘\6’, are replaced with the
     substring matched by group 6 in the pattern.  For example:

          >>> re.sub(r'def\s+([a-zA-Z_][a-zA-Z_0-9]*)\s*\(\s*\):',
          ...        r'static PyObject*\npy_\1(void)\n{',
          ...        'def myfunc():')
          'static PyObject*\npy_myfunc(void)\n{'

     If `repl' is a function, it is called for every non-overlapping
     occurrence of `pattern'.  The function takes a single match object
     argument, and returns the replacement string.  For example:

          >>> def dashrepl(matchobj):
          ...     if matchobj.group(0) == '-': return ' '
          ...     else: return '-'
          >>> re.sub('-{1,2}', dashrepl, 'pro----gram-files')
          'pro--gram files'
          >>> re.sub(r'\sAND\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE)
          'Baked Beans & Spam'

     The pattern may be a string or an RE object.

     The optional argument `count' is the maximum number of pattern
     occurrences to be replaced; `count' must be a non-negative integer.
     If omitted or zero, all occurrences will be replaced.  Empty
     matches for the pattern are replaced only when not adjacent to a
     previous match, so ‘sub('x*', '-', 'abc')’ returns ‘'-a-b-c-'’.

     In string-type `repl' arguments, in addition to the character
     escapes and backreferences described above, ‘\g<name>’ will use the
     substring matched by the group named ‘name’, as defined by the
     ‘(?P<name>...)’ syntax.  ‘\g<number>’ uses the corresponding group
     number; ‘\g<2>’ is therefore equivalent to ‘\2’, but isn’t
     ambiguous in a replacement such as ‘\g<2>0’.  ‘\20’ would be
     interpreted as a reference to group 20, not a reference to group 2
     followed by the literal character ‘'0'’.  The backreference ‘\g<0>’
     substitutes in the entire substring matched by the RE.

     Changed in version 3.1: Added the optional flags argument.

 -- Function: re.subn (pattern, repl, string, count=0, flags=0)

     Perform the same operation as *note sub(): 32c, but return a tuple
     ‘(new_string, number_of_subs_made)’.

     Changed in version 3.1: Added the optional flags argument.

 -- Function: re.escape (string)

     Escape all the characters in pattern except ASCII letters, numbers
     and ‘'_'’.  This is useful if you want to match an arbitrary
     literal string that may have regular expression metacharacters in
     it.

     Changed in version 3.3: The ‘'_'’ character is no longer escaped.

 -- Function: re.purge ()

     Clear the regular expression cache.

 -- Exception: re.error

     Exception raised when a string passed to one of the functions here
     is not a valid regular expression (for example, it might contain
     unmatched parentheses) or when some other error occurs during
     compilation or matching.  It is never an error if a string contains
     no match for a pattern.


File: python.info,  Node: Regular Expression Objects,  Next: Match Objects,  Prev: Module Contents,  Up: re --- Regular expression operations

5.6.2.3 Regular Expression Objects
..................................

Compiled regular expression objects support the following methods and
attributes:

 -- Method: regex.search (string[, pos[, endpos]])

     Scan through `string' looking for a location where this regular
     expression produces a match, and return a corresponding *note match
     object: 236.  Return ‘None’ if no position in the string matches
     the pattern; note that this is different from finding a zero-length
     match at some point in the string.

     The optional second parameter `pos' gives an index in the string
     where the search is to start; it defaults to ‘0’.  This is not
     completely equivalent to slicing the string; the ‘'^'’ pattern
     character matches at the real beginning of the string and at
     positions just after a newline, but not necessarily at the index
     where the search is to start.

     The optional parameter `endpos' limits how far the string will be
     searched; it will be as if the string is `endpos' characters long,
     so only the characters from `pos' to ‘endpos - 1’ will be searched
     for a match.  If `endpos' is less than `pos', no match will be
     found; otherwise, if `rx' is a compiled regular expression object,
     ‘rx.search(string, 0, 50)’ is equivalent to ‘rx.search(string[:50],
     0)’.

          >>> pattern = re.compile("d")
          >>> pattern.search("dog")     # Match at index 0
          <_sre.SRE_Match object; span=(0, 1), match='d'>
          >>> pattern.search("dog", 1)  # No match; search doesn't include the "d"

 -- Method: regex.match (string[, pos[, endpos]])

     If zero or more characters at the `beginning' of `string' match
     this regular expression, return a corresponding *note match object:
     236.  Return ‘None’ if the string does not match the pattern; note
     that this is different from a zero-length match.

     The optional `pos' and `endpos' parameters have the same meaning as
     for the *note search(): eff. method.

          >>> pattern = re.compile("o")
          >>> pattern.match("dog")      # No match as "o" is not at the start of "dog".
          >>> pattern.match("dog", 1)   # Match as "o" is the 2nd character of "dog".
          <_sre.SRE_Match object; span=(1, 2), match='o'>

     If you want to locate a match anywhere in `string', use *note
     search(): eff. instead (see also *note search() vs.  match():
     f03.).

 -- Method: regex.fullmatch (string[, pos[, endpos]])

     If the whole `string' matches this regular expression, return a
     corresponding *note match object: 236.  Return ‘None’ if the string
     does not match the pattern; note that this is different from a
     zero-length match.

     The optional `pos' and `endpos' parameters have the same meaning as
     for the *note search(): eff. method.

          >>> pattern = re.compile("o[gh]")
          >>> pattern.fullmatch("dog")      # No match as "o" is not at the start of "dog".
          >>> pattern.fullmatch("ogre")     # No match as not the full string matches.
          >>> pattern.fullmatch("doggie", 1, 3)   # Matches within given limits.
          <_sre.SRE_Match object; span=(1, 3), match='og'>

     New in version 3.4.

 -- Method: regex.split (string, maxsplit=0)

     Identical to the *note split(): 32a. function, using the compiled
     pattern.

 -- Method: regex.findall (string[, pos[, endpos]])

     Similar to the *note findall(): 32b. function, using the compiled
     pattern, but also accepts optional `pos' and `endpos' parameters
     that limit the search region like for *note match(): 5fd.

 -- Method: regex.finditer (string[, pos[, endpos]])

     Similar to the *note finditer(): f04. function, using the compiled
     pattern, but also accepts optional `pos' and `endpos' parameters
     that limit the search region like for *note match(): 5fd.

 -- Method: regex.sub (repl, string, count=0)

     Identical to the *note sub(): 32c. function, using the compiled
     pattern.

 -- Method: regex.subn (repl, string, count=0)

     Identical to the *note subn(): 672. function, using the compiled
     pattern.

 -- Attribute: regex.flags

     The regex matching flags.  This is a combination of the flags given
     to *note compile(): efc, any ‘(?...)’ inline flags in the pattern,
     and implicit flags such as ‘UNICODE’ if the pattern is a Unicode
     string.

 -- Attribute: regex.groups

     The number of capturing groups in the pattern.

 -- Attribute: regex.groupindex

     A dictionary mapping any symbolic group names defined by ‘(?P<id>)’
     to group numbers.  The dictionary is empty if no symbolic groups
     were used in the pattern.

 -- Attribute: regex.pattern

     The pattern string from which the RE object was compiled.


File: python.info,  Node: Match Objects,  Next: Regular Expression Examples,  Prev: Regular Expression Objects,  Up: re --- Regular expression operations

5.6.2.4 Match Objects
.....................

Match objects always have a boolean value of ‘True’.  Since *note
match(): efe. and *note search(): eff. return ‘None’ when there is no
match, you can test whether there was a match with a simple ‘if’
statement:

     match = re.search(pattern, string)
     if match:
         process(match)

Match objects support the following methods and attributes:

 -- Method: match.expand (template)

     Return the string obtained by doing backslash substitution on the
     template string `template', as done by the *note sub(): f0b.
     method.  Escapes such as ‘\n’ are converted to the appropriate
     characters, and numeric backreferences (‘\1’, ‘\2’) and named
     backreferences (‘\g<1>’, ‘\g<name>’) are replaced by the contents
     of the corresponding group.

 -- Method: match.group ([group1, ...])

     Returns one or more subgroups of the match.  If there is a single
     argument, the result is a single string; if there are multiple
     arguments, the result is a tuple with one item per argument.
     Without arguments, `group1' defaults to zero (the whole match is
     returned).  If a `groupN' argument is zero, the corresponding
     return value is the entire matching string; if it is in the
     inclusive range [1..99], it is the string matching the
     corresponding parenthesized group.  If a group number is negative
     or larger than the number of groups defined in the pattern, an
     *note IndexError: 908. exception is raised.  If a group is
     contained in a part of the pattern that did not match, the
     corresponding result is ‘None’.  If a group is contained in a part
     of the pattern that matched multiple times, the last match is
     returned.

          >>> m = re.match(r"(\w+) (\w+)", "Isaac Newton, physicist")
          >>> m.group(0)       # The entire match
          'Isaac Newton'
          >>> m.group(1)       # The first parenthesized subgroup.
          'Isaac'
          >>> m.group(2)       # The second parenthesized subgroup.
          'Newton'
          >>> m.group(1, 2)    # Multiple arguments give us a tuple.
          ('Isaac', 'Newton')

     If the regular expression uses the ‘(?P<name>...)’ syntax, the
     `groupN' arguments may also be strings identifying groups by their
     group name.  If a string argument is not used as a group name in
     the pattern, an *note IndexError: 908. exception is raised.

     A moderately complicated example:

          >>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
          >>> m.group('first_name')
          'Malcolm'
          >>> m.group('last_name')
          'Reynolds'

     Named groups can also be referred to by their index:

          >>> m.group(1)
          'Malcolm'
          >>> m.group(2)
          'Reynolds'

     If a group matches multiple times, only the last match is
     accessible:

          >>> m = re.match(r"(..)+", "a1b2c3")  # Matches 3 times.
          >>> m.group(1)                        # Returns only the last match.
          'c3'

 -- Method: match.groups (default=None)

     Return a tuple containing all the subgroups of the match, from 1 up
     to however many groups are in the pattern.  The `default' argument
     is used for groups that did not participate in the match; it
     defaults to ‘None’.

     For example:

          >>> m = re.match(r"(\d+)\.(\d+)", "24.1632")
          >>> m.groups()
          ('24', '1632')

     If we make the decimal place and everything after it optional, not
     all groups might participate in the match.  These groups will
     default to ‘None’ unless the `default' argument is given:

          >>> m = re.match(r"(\d+)\.?(\d+)?", "24")
          >>> m.groups()      # Second group defaults to None.
          ('24', None)
          >>> m.groups('0')   # Now, the second group defaults to '0'.
          ('24', '0')

 -- Method: match.groupdict (default=None)

     Return a dictionary containing all the `named' subgroups of the
     match, keyed by the subgroup name.  The `default' argument is used
     for groups that did not participate in the match; it defaults to
     ‘None’.  For example:

          >>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
          >>> m.groupdict()
          {'first_name': 'Malcolm', 'last_name': 'Reynolds'}

 -- Method: match.start ([group])
 -- Method: match.end ([group])

     Return the indices of the start and end of the substring matched by
     `group'; `group' defaults to zero (meaning the whole matched
     substring).  Return ‘-1’ if `group' exists but did not contribute
     to the match.  For a match object `m', and a group `g' that did
     contribute to the match, the substring matched by group `g'
     (equivalent to ‘m.group(g)’) is

          m.string[m.start(g):m.end(g)]

     Note that ‘m.start(group)’ will equal ‘m.end(group)’ if `group'
     matched a null string.  For example, after ‘m = re.search('b(c?)',
     'cba')’, ‘m.start(0)’ is 1, ‘m.end(0)’ is 2, ‘m.start(1)’ and
     ‘m.end(1)’ are both 2, and ‘m.start(2)’ raises an *note IndexError:
     908. exception.

     An example that will remove `remove_this' from email addresses:

          >>> email = "tony@tiremove_thisger.net"
          >>> m = re.search("remove_this", email)
          >>> email[:m.start()] + email[m.end():]
          'tony@tiger.net'

 -- Method: match.span ([group])

     For a match `m', return the 2-tuple ‘(m.start(group),
     m.end(group))’.  Note that if `group' did not contribute to the
     match, this is ‘(-1, -1)’.  `group' defaults to zero, the entire
     match.

 -- Attribute: match.pos

     The value of `pos' which was passed to the *note search(): eff. or
     *note match(): efe. method of a *note regex object: 235.  This is
     the index into the string at which the RE engine started looking
     for a match.

 -- Attribute: match.endpos

     The value of `endpos' which was passed to the *note search(): eff.
     or *note match(): efe. method of a *note regex object: 235.  This
     is the index into the string beyond which the RE engine will not
     go.

 -- Attribute: match.lastindex

     The integer index of the last matched capturing group, or ‘None’ if
     no group was matched at all.  For example, the expressions ‘(a)b’,
     ‘((a)(b))’, and ‘((ab))’ will have ‘lastindex == 1’ if applied to
     the string ‘'ab'’, while the expression ‘(a)(b)’ will have
     ‘lastindex == 2’, if applied to the same string.

 -- Attribute: match.lastgroup

     The name of the last matched capturing group, or ‘None’ if the
     group didn’t have a name, or if no group was matched at all.

 -- Attribute: match.re

     The regular expression object whose *note match(): efe. or *note
     search(): eff. method produced this match instance.

 -- Attribute: match.string

     The string passed to *note match(): efe. or *note search(): eff.


File: python.info,  Node: Regular Expression Examples,  Prev: Match Objects,  Up: re --- Regular expression operations

5.6.2.5 Regular Expression Examples
...................................

* Menu:

* Checking for a Pair:: 
* Simulating scanf(): Simulating scanf. 
* search() vs. match(): search vs match. 
* Making a Phonebook:: 
* Text Munging:: 
* Finding all Adverbs:: 
* Finding all Adverbs and their Positions:: 
* Raw String Notation:: 
* Writing a Tokenizer:: 


File: python.info,  Node: Checking for a Pair,  Next: Simulating scanf,  Up: Regular Expression Examples

5.6.2.6 Checking for a Pair
...........................

In this example, we’ll use the following helper function to display
match objects a little more gracefully:

     def displaymatch(match):
         if match is None:
             return None
         return '<Match: %r, groups=%r>' % (match.group(), match.groups())

Suppose you are writing a poker program where a player’s hand is
represented as a 5-character string with each character representing a
card, "a" for ace, "k" for king, "q" for queen, "j" for jack, "t" for
10, and "2" through "9" representing the card with that value.

To see if a given string is a valid hand, one could do the following:

     >>> valid = re.compile(r"^[a2-9tjqk]{5}$")
     >>> displaymatch(valid.match("akt5q"))  # Valid.
     "<Match: 'akt5q', groups=()>"
     >>> displaymatch(valid.match("akt5e"))  # Invalid.
     >>> displaymatch(valid.match("akt"))    # Invalid.
     >>> displaymatch(valid.match("727ak"))  # Valid.
     "<Match: '727ak', groups=()>"

That last hand, ‘"727ak"’, contained a pair, or two of the same valued
cards.  To match this with a regular expression, one could use
backreferences as such:

     >>> pair = re.compile(r".*(.).*\1")
     >>> displaymatch(pair.match("717ak"))     # Pair of 7s.
     "<Match: '717', groups=('7',)>"
     >>> displaymatch(pair.match("718ak"))     # No pairs.
     >>> displaymatch(pair.match("354aa"))     # Pair of aces.
     "<Match: '354aa', groups=('a',)>"

To find out what card the pair consists of, one could use the *note
group(): 32d. method of the match object in the following manner:

     >>> pair.match("717ak").group(1)
     '7'

     # Error because re.match() returns None, which doesn't have a group() method:
     >>> pair.match("718ak").group(1)
     Traceback (most recent call last):
       File "<pyshell#23>", line 1, in <module>
         re.match(r".*(.).*\1", "718ak").group(1)
     AttributeError: 'NoneType' object has no attribute 'group'

     >>> pair.match("354aa").group(1)
     'a'


File: python.info,  Node: Simulating scanf,  Next: search vs match,  Prev: Checking for a Pair,  Up: Regular Expression Examples

5.6.2.7 Simulating scanf()
..........................

Python does not currently have an equivalent to ‘scanf()’.  Regular
expressions are generally more powerful, though also more verbose, than
‘scanf()’ format strings.  The table below offers some more-or-less
equivalent mappings between ‘scanf()’ format tokens and regular
expressions.

‘scanf()’ Token                      Regular Expression
                                     
---------------------------------------------------------------------------------------
                                     
‘%c’                                 ‘.’
                                     
                                     
‘%5c’                                ‘.{5}’
                                     
                                     
‘%d’                                 ‘[-+]?\d+’
                                     
                                     
‘%e’, ‘%E’, ‘%f’, ‘%g’               ‘[-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?’
                                     
                                     
‘%i’                                 ‘[-+]?(0[xX][\dA-Fa-f]+|0[0-7]*|\d+)’
                                     
                                     
‘%o’                                 ‘[-+]?[0-7]+’
                                     
                                     
‘%s’                                 ‘\S+’
                                     
                                     
‘%u’                                 ‘\d+’
                                     
                                     
‘%x’, ‘%X’                           ‘[-+]?(0[xX])?[\dA-Fa-f]+’
                                     

To extract the filename and numbers from a string like

     /usr/sbin/sendmail - 0 errors, 4 warnings

you would use a ‘scanf()’ format like

     %s - %d errors, %d warnings

The equivalent regular expression would be

     (\S+) - (\d+) errors, (\d+) warnings


File: python.info,  Node: search vs match,  Next: Making a Phonebook,  Prev: Simulating scanf,  Up: Regular Expression Examples

5.6.2.8 search() vs. match()
............................

Python offers two different primitive operations based on regular
expressions: *note re.match(): 5fd. checks for a match only at the
beginning of the string, while *note re.search(): 5fc. checks for a
match anywhere in the string (this is what Perl does by default).

For example:

     >>> re.match("c", "abcdef")  # No match
     >>> re.search("c", "abcdef") # Match
     <_sre.SRE_Match object; span=(2, 3), match='c'>

Regular expressions beginning with ‘'^'’ can be used with *note
search(): 5fc. to restrict the match at the beginning of the string:

     >>> re.match("c", "abcdef")  # No match
     >>> re.search("^c", "abcdef") # No match
     >>> re.search("^a", "abcdef")  # Match
     <_sre.SRE_Match object; span=(0, 1), match='a'>

Note however that in *note MULTILINE: ef2. mode *note match(): 5fd. only
matches at the beginning of the string, whereas using *note search():
5fc. with a regular expression beginning with ‘'^'’ will match at the
beginning of each line.

     >>> re.match('X', 'A\nB\nX', re.MULTILINE)  # No match
     >>> re.search('^X', 'A\nB\nX', re.MULTILINE)  # Match
     <_sre.SRE_Match object; span=(4, 5), match='X'>


File: python.info,  Node: Making a Phonebook,  Next: Text Munging,  Prev: search vs match,  Up: Regular Expression Examples

5.6.2.9 Making a Phonebook
..........................

*note split(): 32a. splits a string into a list delimited by the passed
pattern.  The method is invaluable for converting textual data into data
structures that can be easily read and modified by Python as
demonstrated in the following example that creates a phonebook.

First, here is the input.  Normally it may come from a file, here we are
using triple-quoted string syntax:

     >>> text = """Ross McFluff: 834.345.1254 155 Elm Street
     ...
     ... Ronald Heathmore: 892.345.3428 436 Finley Avenue
     ... Frank Burger: 925.541.7625 662 South Dogwood Way
     ...
     ...
     ... Heather Albrecht: 548.326.4584 919 Park Place"""

The entries are separated by one or more newlines.  Now we convert the
string into a list with each nonempty line having its own entry:

     >>> entries = re.split("\n+", text)
     >>> entries
     ['Ross McFluff: 834.345.1254 155 Elm Street',
     'Ronald Heathmore: 892.345.3428 436 Finley Avenue',
     'Frank Burger: 925.541.7625 662 South Dogwood Way',
     'Heather Albrecht: 548.326.4584 919 Park Place']

Finally, split each entry into a list with first name, last name,
telephone number, and address.  We use the ‘maxsplit’ parameter of *note
split(): 32a. because the address has spaces, our splitting pattern, in
it:

     >>> [re.split(":? ", entry, 3) for entry in entries]
     [['Ross', 'McFluff', '834.345.1254', '155 Elm Street'],
     ['Ronald', 'Heathmore', '892.345.3428', '436 Finley Avenue'],
     ['Frank', 'Burger', '925.541.7625', '662 South Dogwood Way'],
     ['Heather', 'Albrecht', '548.326.4584', '919 Park Place']]

The ‘:?’ pattern matches the colon after the last name, so that it does
not occur in the result list.  With a ‘maxsplit’ of ‘4’, we could
separate the house number from the street name:

     >>> [re.split(":? ", entry, 4) for entry in entries]
     [['Ross', 'McFluff', '834.345.1254', '155', 'Elm Street'],
     ['Ronald', 'Heathmore', '892.345.3428', '436', 'Finley Avenue'],
     ['Frank', 'Burger', '925.541.7625', '662', 'South Dogwood Way'],
     ['Heather', 'Albrecht', '548.326.4584', '919', 'Park Place']]


File: python.info,  Node: Text Munging,  Next: Finding all Adverbs,  Prev: Making a Phonebook,  Up: Regular Expression Examples

5.6.2.10 Text Munging
.....................

*note sub(): 32c. replaces every occurrence of a pattern with a string
or the result of a function.  This example demonstrates using *note
sub(): 32c. with a function to "munge" text, or randomize the order of
all the characters in each word of a sentence except for the first and
last characters:

     >>> def repl(m):
     ...   inner_word = list(m.group(2))
     ...   random.shuffle(inner_word)
     ...   return m.group(1) + "".join(inner_word) + m.group(3)
     >>> text = "Professor Abdolmalek, please report your absences promptly."
     >>> re.sub(r"(\w)(\w+)(\w)", repl, text)
     'Poefsrosr Aealmlobdk, pslaee reorpt your abnseces plmrptoy.'
     >>> re.sub(r"(\w)(\w+)(\w)", repl, text)
     'Pofsroser Aodlambelk, plasee reoprt yuor asnebces potlmrpy.'


File: python.info,  Node: Finding all Adverbs,  Next: Finding all Adverbs and their Positions,  Prev: Text Munging,  Up: Regular Expression Examples

5.6.2.11 Finding all Adverbs
............................

*note findall(): 32b. matches `all' occurrences of a pattern, not just
the first one as *note search(): 5fc. does.  For example, if one was a
writer and wanted to find all of the adverbs in some text, he or she
might use *note findall(): 32b. in the following manner:

     >>> text = "He was carefully disguised but captured quickly by police."
     >>> re.findall(r"\w+ly", text)
     ['carefully', 'quickly']


File: python.info,  Node: Finding all Adverbs and their Positions,  Next: Raw String Notation,  Prev: Finding all Adverbs,  Up: Regular Expression Examples

5.6.2.12 Finding all Adverbs and their Positions
................................................

If one wants more information about all matches of a pattern than the
matched text, *note finditer(): f04. is useful as it provides *note
match objects: 236. instead of strings.  Continuing with the previous
example, if one was a writer who wanted to find all of the adverbs `and
their positions' in some text, he or she would use *note finditer():
f04. in the following manner:

     >>> text = "He was carefully disguised but captured quickly by police."
     >>> for m in re.finditer(r"\w+ly", text):
     ...     print('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))
     07-16: carefully
     40-47: quickly


File: python.info,  Node: Raw String Notation,  Next: Writing a Tokenizer,  Prev: Finding all Adverbs and their Positions,  Up: Regular Expression Examples

5.6.2.13 Raw String Notation
............................

Raw string notation (‘r"text"’) keeps regular expressions sane.  Without
it, every backslash (‘'\'’) in a regular expression would have to be
prefixed with another one to escape it.  For example, the two following
lines of code are functionally identical:

     >>> re.match(r"\W(.)\1\W", " ff ")
     <_sre.SRE_Match object; span=(0, 4), match=' ff '>
     >>> re.match("\\W(.)\\1\\W", " ff ")
     <_sre.SRE_Match object; span=(0, 4), match=' ff '>

When one wants to match a literal backslash, it must be escaped in the
regular expression.  With raw string notation, this means ‘r"\\"’.
Without raw string notation, one must use ‘"\\\\"’, making the following
lines of code functionally identical:

     >>> re.match(r"\\", r"\\")
     <_sre.SRE_Match object; span=(0, 1), match='\\'>
     >>> re.match("\\\\", r"\\")
     <_sre.SRE_Match object; span=(0, 1), match='\\'>


File: python.info,  Node: Writing a Tokenizer,  Prev: Raw String Notation,  Up: Regular Expression Examples

5.6.2.14 Writing a Tokenizer
............................

A tokenizer or scanner(1) analyzes a string to categorize groups of
characters.  This is a useful first step in writing a compiler or
interpreter.

The text categories are specified with regular expressions.  The
technique is to combine those into a single master regular expression
and to loop over successive matches:

     import collections
     import re

     Token = collections.namedtuple('Token', ['typ', 'value', 'line', 'column'])

     def tokenize(code):
         keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'}
         token_specification = [
             ('NUMBER',  r'\d+(\.\d*)?'), # Integer or decimal number
             ('ASSIGN',  r':='),          # Assignment operator
             ('END',     r';'),           # Statement terminator
             ('ID',      r'[A-Za-z]+'),   # Identifiers
             ('OP',      r'[+\-*/]'),     # Arithmetic operators
             ('NEWLINE', r'\n'),          # Line endings
             ('SKIP',    r'[ \t]+'),      # Skip over spaces and tabs
             ('MISMATCH',r'.'),           # Any other character
         ]
         tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)
         line_num = 1
         line_start = 0
         for mo in re.finditer(tok_regex, code):
             kind = mo.lastgroup
             value = mo.group(kind)
             if kind == 'NEWLINE':
                 line_start = mo.end()
                 line_num += 1
             elif kind == 'SKIP':
                 pass
             elif kind == 'MISMATCH':
                 raise RuntimeError('%r unexpected on line %d' % (value, line_num))
             else:
                 if kind == 'ID' and value in keywords:
                     kind = value
                 column = mo.start() - line_start
                 yield Token(kind, value, line_num, column)

     statements = '''
         IF quantity THEN
             total := total + price * quantity;
             tax := price * 0.05;
         ENDIF;
     '''

     for token in tokenize(statements):
         print(token)

The tokenizer produces the following output:

     Token(typ='IF', value='IF', line=2, column=4)
     Token(typ='ID', value='quantity', line=2, column=7)
     Token(typ='THEN', value='THEN', line=2, column=16)
     Token(typ='ID', value='total', line=3, column=8)
     Token(typ='ASSIGN', value=':=', line=3, column=14)
     Token(typ='ID', value='total', line=3, column=17)
     Token(typ='OP', value='+', line=3, column=23)
     Token(typ='ID', value='price', line=3, column=25)
     Token(typ='OP', value='*', line=3, column=31)
     Token(typ='ID', value='quantity', line=3, column=33)
     Token(typ='END', value=';', line=3, column=41)
     Token(typ='ID', value='tax', line=4, column=8)
     Token(typ='ASSIGN', value=':=', line=4, column=12)
     Token(typ='ID', value='price', line=4, column=15)
     Token(typ='OP', value='*', line=4, column=21)
     Token(typ='NUMBER', value='0.05', line=4, column=23)
     Token(typ='END', value=';', line=4, column=27)
     Token(typ='ENDIF', value='ENDIF', line=5, column=4)
     Token(typ='END', value=';', line=5, column=9)

   ---------- Footnotes ----------

   (1) http://en.wikipedia.org/wiki/Lexical_analysis


File: python.info,  Node: difflib --- Helpers for computing deltas,  Next: textwrap --- Text wrapping and filling,  Prev: re --- Regular expression operations,  Up: Text Processing Services

5.6.3 ‘difflib’ — Helpers for computing deltas
----------------------------------------------

This module provides classes and functions for comparing sequences.  It
can be used for example, for comparing files, and can produce difference
information in various formats, including HTML and context and unified
diffs.  For comparing directories and files, see also, the *note
filecmp: 7d. module.

 -- Class: difflib.SequenceMatcher

     This is a flexible class for comparing pairs of sequences of any
     type, so long as the sequence elements are *note hashable: bfd.
     The basic algorithm predates, and is a little fancier than, an
     algorithm published in the late 1980’s by Ratcliff and Obershelp
     under the hyperbolic name "gestalt pattern matching."  The idea is
     to find the longest contiguous matching subsequence that contains
     no "junk" elements (the Ratcliff and Obershelp algorithm doesn’t
     address junk).  The same idea is then applied recursively to the
     pieces of the sequences to the left and to the right of the
     matching subsequence.  This does not yield minimal edit sequences,
     but does tend to yield matches that "look right" to people.

     `Timing:' The basic Ratcliff-Obershelp algorithm is cubic time in
     the worst case and quadratic time in the expected case.  *note
     SequenceMatcher: 30a. is quadratic time for the worst case and has
     expected-case behavior dependent in a complicated way on how many
     elements the sequences have in common; best case time is linear.

     `Automatic junk heuristic:' *note SequenceMatcher: 30a. supports a
     heuristic that automatically treats certain sequence items as junk.
     The heuristic counts how many times each individual item appears in
     the sequence.  If an item’s duplicates (after the first one)
     account for more than 1% of the sequence and the sequence is at
     least 200 items long, this item is marked as "popular" and is
     treated as junk for the purpose of sequence matching.  This
     heuristic can be turned off by setting the ‘autojunk’ argument to
     ‘False’ when creating the *note SequenceMatcher: 30a.

     New in version 3.2: The `autojunk' parameter.

 -- Class: difflib.Differ

     This is a class for comparing sequences of lines of text, and
     producing human-readable differences or deltas.  Differ uses *note
     SequenceMatcher: 30a. both to compare sequences of lines, and to
     compare sequences of characters within similar (near-matching)
     lines.

     Each line of a *note Differ: f29. delta begins with a two-letter
     code:

     Code           Meaning
                    
     ---------------------------------------------------------------
                    
     ‘'- '’         line unique to sequence 1
                    
                    
     ‘'+ '’         line unique to sequence 2
                    
                    
     ‘' '’          line common to both sequences
                    
                    
     ‘'? '’         line not present in either input sequence
                    

     Lines beginning with ’‘?’’ attempt to guide the eye to intraline
     differences, and were not present in either input sequence.  These
     lines can be confusing if the sequences contain tab characters.

 -- Class: difflib.HtmlDiff

     This class can be used to create an HTML table (or a complete HTML
     file containing the table) showing a side by side, line by line
     comparison of text with inter-line and intra-line change
     highlights.  The table can be generated in either full or
     contextual difference mode.

     The constructor for this class is:

      -- Method: __init__ (tabsize=8, wrapcolumn=None, linejunk=None,
               charjunk=IS_CHARACTER_JUNK)

          Initializes instance of *note HtmlDiff: f2a.

          `tabsize' is an optional keyword argument to specify tab stop
          spacing and defaults to ‘8’.

          `wrapcolumn' is an optional keyword to specify column number
          where lines are broken and wrapped, defaults to ‘None’ where
          lines are not wrapped.

          `linejunk' and `charjunk' are optional keyword arguments
          passed into ‘ndiff()’ (used by *note HtmlDiff: f2a. to
          generate the side by side HTML differences).  See ‘ndiff()’
          documentation for argument default values and descriptions.

     The following methods are public:

      -- Method: make_file (fromlines, tolines, fromdesc='', todesc='',
               context=False, numlines=5)

          Compares `fromlines' and `tolines' (lists of strings) and
          returns a string which is a complete HTML file containing a
          table showing line by line differences with inter-line and
          intra-line changes highlighted.

          `fromdesc' and `todesc' are optional keyword arguments to
          specify from/to file column header strings (both default to an
          empty string).

          `context' and `numlines' are both optional keyword arguments.
          Set `context' to ‘True’ when contextual differences are to be
          shown, else the default is ‘False’ to show the full files.
          `numlines' defaults to ‘5’.  When `context' is ‘True’
          `numlines' controls the number of context lines which surround
          the difference highlights.  When `context' is ‘False’
          `numlines' controls the number of lines which are shown before
          a difference highlight when using the "next" hyperlinks
          (setting to zero would cause the "next" hyperlinks to place
          the next difference highlight at the top of the browser
          without any leading context).

      -- Method: make_table (fromlines, tolines, fromdesc='', todesc='',
               context=False, numlines=5)

          Compares `fromlines' and `tolines' (lists of strings) and
          returns a string which is a complete HTML table showing line
          by line differences with inter-line and intra-line changes
          highlighted.

          The arguments for this method are the same as those for the
          *note make_file(): f2c. method.

     ‘Tools/scripts/diff.py’ is a command-line front-end to this class
     and contains a good example of its use.

 -- Function: difflib.context_diff (a, b, fromfile='', tofile='',
          fromfiledate='', tofiledate='', n=3, lineterm='\n')

     Compare `a' and `b' (lists of strings); return a delta (a *note
     generator: 374. generating the delta lines) in context diff format.

     Context diffs are a compact way of showing just the lines that have
     changed plus a few lines of context.  The changes are shown in a
     before/after style.  The number of context lines is set by `n'
     which defaults to three.

     By default, the diff control lines (those with ‘***’ or ‘---’) are
     created with a trailing newline.  This is helpful so that inputs
     created from *note io.IOBase.readlines(): f2f. result in diffs that
     are suitable for use with *note io.IOBase.writelines(): f30. since
     both the inputs and outputs have trailing newlines.

     For inputs that do not have trailing newlines, set the `lineterm'
     argument to ‘""’ so that the output will be uniformly newline free.

     The context diff format normally has a header for filenames and
     modification times.  Any or all of these may be specified using
     strings for `fromfile', `tofile', `fromfiledate', and `tofiledate'.
     The modification times are normally expressed in the ISO 8601
     format.  If not specified, the strings default to blanks.

          >>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
          >>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
          >>> for line in context_diff(s1, s2, fromfile='before.py', tofile='after.py'):
          ...     sys.stdout.write(line)  # doctest: +NORMALIZE_WHITESPACE
          *** before.py
          --- after.py
          ***************
          *** 1,4 ****
          ! bacon
          ! eggs
          ! ham
            guido
          --- 1,4 ----
          ! python
          ! eggy
          ! hamster
            guido

     See *note A command-line interface to difflib: f31. for a more
     detailed example.

 -- Function: difflib.get_close_matches (word, possibilities, n=3,
          cutoff=0.6)

     Return a list of the best "good enough" matches.  `word' is a
     sequence for which close matches are desired (typically a string),
     and `possibilities' is a list of sequences against which to match
     `word' (typically a list of strings).

     Optional argument `n' (default ‘3’) is the maximum number of close
     matches to return; `n' must be greater than ‘0’.

     Optional argument `cutoff' (default ‘0.6’) is a float in the range
     [0, 1].  Possibilities that don’t score at least that similar to
     `word' are ignored.

     The best (no more than `n') matches among the possibilities are
     returned in a list, sorted by similarity score, most similar first.

          >>> get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy'])
          ['apple', 'ape']
          >>> import keyword
          >>> get_close_matches('wheel', keyword.kwlist)
          ['while']
          >>> get_close_matches('apple', keyword.kwlist)
          []
          >>> get_close_matches('accept', keyword.kwlist)
          ['except']

 -- Function: difflib.ndiff (a, b, linejunk=None,
          charjunk=IS_CHARACTER_JUNK)

     Compare `a' and `b' (lists of strings); return a *note Differ:
     f29.-style delta (a *note generator: 374. generating the delta
     lines).

     Optional keyword parameters `linejunk' and `charjunk' are for
     filter functions (or ‘None’):

     `linejunk': A function that accepts a single string argument, and
     returns true if the string is junk, or false if not.  The default
     is ‘None’.  There is also a module-level function *note
     IS_LINE_JUNK(): f34, which filters out lines without visible
     characters, except for at most one pound character (‘'#'’) –
     however the underlying *note SequenceMatcher: 30a. class does a
     dynamic analysis of which lines are so frequent as to constitute
     noise, and this usually works better than using this function.

     `charjunk': A function that accepts a character (a string of length
     1), and returns if the character is junk, or false if not.  The
     default is module-level function *note IS_CHARACTER_JUNK(): f35,
     which filters out whitespace characters (a blank or tab; note: bad
     idea to include newline in this!).

     ‘Tools/scripts/ndiff.py’ is a command-line front-end to this
     function.

          >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
          ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
          >>> print(''.join(diff), end="")
          - one
          ?  ^
          + ore
          ?  ^
          - two
          - three
          ?  -
          + tree
          + emu

 -- Function: difflib.restore (sequence, which)

     Return one of the two sequences that generated a delta.

     Given a `sequence' produced by *note Differ.compare(): f37. or
     *note ndiff(): f33, extract lines originating from file 1 or 2
     (parameter `which'), stripping off line prefixes.

     Example:

          >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
          ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
          >>> diff = list(diff) # materialize the generated delta into a list
          >>> print(''.join(restore(diff, 1)), end="")
          one
          two
          three
          >>> print(''.join(restore(diff, 2)), end="")
          ore
          tree
          emu

 -- Function: difflib.unified_diff (a, b, fromfile='', tofile='',
          fromfiledate='', tofiledate='', n=3, lineterm='\n')

     Compare `a' and `b' (lists of strings); return a delta (a *note
     generator: 374. generating the delta lines) in unified diff format.

     Unified diffs are a compact way of showing just the lines that have
     changed plus a few lines of context.  The changes are shown in a
     inline style (instead of separate before/after blocks).  The number
     of context lines is set by `n' which defaults to three.

     By default, the diff control lines (those with ‘---’, ‘+++’, or
     ‘@@’) are created with a trailing newline.  This is helpful so that
     inputs created from *note io.IOBase.readlines(): f2f. result in
     diffs that are suitable for use with *note io.IOBase.writelines():
     f30. since both the inputs and outputs have trailing newlines.

     For inputs that do not have trailing newlines, set the `lineterm'
     argument to ‘""’ so that the output will be uniformly newline free.

     The context diff format normally has a header for filenames and
     modification times.  Any or all of these may be specified using
     strings for `fromfile', `tofile', `fromfiledate', and `tofiledate'.
     The modification times are normally expressed in the ISO 8601
     format.  If not specified, the strings default to blanks.

          >>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
          >>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
          >>> for line in unified_diff(s1, s2, fromfile='before.py', tofile='after.py'):
          ...     sys.stdout.write(line)   # doctest: +NORMALIZE_WHITESPACE
          --- before.py
          +++ after.py
          @@ -1,4 +1,4 @@
          -bacon
          -eggs
          -ham
          +python
          +eggy
          +hamster
           guido

     See *note A command-line interface to difflib: f31. for a more
     detailed example.

 -- Function: difflib.IS_LINE_JUNK (line)

     Return true for ignorable lines.  The line `line' is ignorable if
     `line' is blank or contains a single ‘'#'’, otherwise it is not
     ignorable.  Used as a default for parameter `linejunk' in *note
     ndiff(): f33. in older versions.

 -- Function: difflib.IS_CHARACTER_JUNK (ch)

     Return true for ignorable characters.  The character `ch' is
     ignorable if `ch' is a space or tab, otherwise it is not ignorable.
     Used as a default for parameter `charjunk' in *note ndiff(): f33.

See also
........

Pattern Matching: The Gestalt Approach(1)

     Discussion of a similar algorithm by John W. Ratcliff and D. E.
     Metzener.  This was published in Dr.  Dobb’s Journal(2) in July,
     1988.

* Menu:

* SequenceMatcher Objects:: 
* SequenceMatcher Examples:: 
* Differ Objects:: 
* Differ Example:: 
* A command-line interface to difflib:: 

   ---------- Footnotes ----------

   (1) 
http://www.drdobbs.com/database/pattern-matching-the-gestalt-approach/184407970

   (2) http://www.drdobbs.com/


File: python.info,  Node: SequenceMatcher Objects,  Next: SequenceMatcher Examples,  Up: difflib --- Helpers for computing deltas

5.6.3.1 SequenceMatcher Objects
...............................

The *note SequenceMatcher: 30a. class has this constructor:

 -- Class: difflib.SequenceMatcher (isjunk=None, a='', b='',
          autojunk=True)

     Optional argument `isjunk' must be ‘None’ (the default) or a
     one-argument function that takes a sequence element and returns
     true if and only if the element is "junk" and should be ignored.
     Passing ‘None’ for `isjunk' is equivalent to passing ‘lambda x: 0’;
     in other words, no elements are ignored.  For example, pass:

          lambda x: x in " \t"

     if you’re comparing lines as sequences of characters, and don’t
     want to synch up on blanks or hard tabs.

     The optional arguments `a' and `b' are sequences to be compared;
     both default to empty strings.  The elements of both sequences must
     be *note hashable: bfd.

     The optional argument `autojunk' can be used to disable the
     automatic junk heuristic.

     New in version 3.2: The `autojunk' parameter.

     SequenceMatcher objects get three data attributes: `bjunk' is the
     set of elements of `b' for which `isjunk' is ‘True’; `bpopular' is
     the set of non-junk elements considered popular by the heuristic
     (if it is not disabled); `b2j' is a dict mapping the remaining
     elements of `b' to a list of positions where they occur.  All three
     are reset whenever `b' is reset with *note set_seqs(): f3b. or
     *note set_seq2(): f3c.

     New in version 3.2: The `bjunk' and `bpopular' attributes.

     *note SequenceMatcher: 30a. objects have the following methods:

      -- Method: set_seqs (a, b)

          Set the two sequences to be compared.

     *note SequenceMatcher: 30a. computes and caches detailed
     information about the second sequence, so if you want to compare
     one sequence against many sequences, use *note set_seq2(): f3c. to
     set the commonly used sequence once and call *note set_seq1(): f3d.
     repeatedly, once for each of the other sequences.

      -- Method: set_seq1 (a)

          Set the first sequence to be compared.  The second sequence to
          be compared is not changed.

      -- Method: set_seq2 (b)

          Set the second sequence to be compared.  The first sequence to
          be compared is not changed.

      -- Method: find_longest_match (alo, ahi, blo, bhi)

          Find longest matching block in ‘a[alo:ahi]’ and ‘b[blo:bhi]’.

          If `isjunk' was omitted or ‘None’, *note find_longest_match():
          f3e. returns ‘(i, j, k)’ such that ‘a[i:i+k]’ is equal to
          ‘b[j:j+k]’, where ‘alo <= i <= i+k <= ahi’ and ‘blo <= j <=
          j+k <= bhi’.  For all ‘(i', j', k')’ meeting those conditions,
          the additional conditions ‘k >= k'’, ‘i <= i'’, and if ‘i ==
          i'’, ‘j <= j'’ are also met.  In other words, of all maximal
          matching blocks, return one that starts earliest in `a', and
          of all those maximal matching blocks that start earliest in
          `a', return the one that starts earliest in `b'.

               >>> s = SequenceMatcher(None, " abcd", "abcd abcd")
               >>> s.find_longest_match(0, 5, 0, 9)
               Match(a=0, b=4, size=5)

          If `isjunk' was provided, first the longest matching block is
          determined as above, but with the additional restriction that
          no junk element appears in the block.  Then that block is
          extended as far as possible by matching (only) junk elements
          on both sides.  So the resulting block never matches on junk
          except as identical junk happens to be adjacent to an
          interesting match.

          Here’s the same example as before, but considering blanks to
          be junk.  That prevents ‘' abcd'’ from matching the ‘' abcd'’
          at the tail end of the second sequence directly.  Instead only
          the ‘'abcd'’ can match, and matches the leftmost ‘'abcd'’ in
          the second sequence:

               >>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
               >>> s.find_longest_match(0, 5, 0, 9)
               Match(a=1, b=0, size=4)

          If no blocks match, this returns ‘(alo, blo, 0)’.

          This method returns a *note named tuple: 565. ‘Match(a, b,
          size)’.

      -- Method: get_matching_blocks ()

          Return list of triples describing matching subsequences.  Each
          triple is of the form ‘(i, j, n)’, and means that ‘a[i:i+n] ==
          b[j:j+n]’.  The triples are monotonically increasing in `i'
          and `j'.

          The last triple is a dummy, and has the value ‘(len(a),
          len(b), 0)’.  It is the only triple with ‘n == 0’.  If ‘(i, j,
          n)’ and ‘(i', j', n')’ are adjacent triples in the list, and
          the second is not the last triple in the list, then ‘i+n !=
          i'’ or ‘j+n != j'’; in other words, adjacent triples always
          describe non-adjacent equal blocks.

               >>> s = SequenceMatcher(None, "abxcd", "abcd")
               >>> s.get_matching_blocks()
               [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]

      -- Method: get_opcodes ()

          Return list of 5-tuples describing how to turn `a' into `b'.
          Each tuple is of the form ‘(tag, i1, i2, j1, j2)’.  The first
          tuple has ‘i1 == j1 == 0’, and remaining tuples have `i1'
          equal to the `i2' from the preceding tuple, and, likewise,
          `j1' equal to the previous `j2'.

          The `tag' values are strings, with these meanings:

          Value               Meaning
                              
          ----------------------------------------------------------------------
                              
          ‘'replace'’         ‘a[i1:i2]’ should be replaced by ‘b[j1:j2]’.
                              
                              
          ‘'delete'’          ‘a[i1:i2]’ should be deleted.  Note that ‘j1 ==
                              j2’ in this case.
                              
                              
          ‘'insert'’          ‘b[j1:j2]’ should be inserted at ‘a[i1:i1]’.
                              Note that ‘i1 == i2’ in this case.
                              
                              
          ‘'equal'’           ‘a[i1:i2] == b[j1:j2]’ (the sub-sequences are
                              equal).
                              

          For example:

                    >>> a = "qabxcd"
                    >>> b = "abycdf"
                    >>> s = SequenceMatcher(None, a, b)
                    >>> for tag, i1, i2, j1, j2 in s.get_opcodes():
                        print('{:7}   a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format(
                            tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2]))

               delete a[0:1] –> b[0:0] ’q’ –> ’’ equal a[1:3] –> b[0:2]
               ’ab’ –> ’ab’ replace a[3:4] –> b[2:3] ’x’ –> ’y’ equal
               a[4:6] –> b[3:5] ’cd’ –> ’cd’ insert a[6:6] –> b[5:6] ’’
               –> ’f’

      -- Method: get_grouped_opcodes (n=3)

          Return a *note generator: 374. of groups with up to `n' lines
          of context.

          Starting with the groups returned by *note get_opcodes(): f40,
          this method splits out smaller change clusters and eliminates
          intervening ranges which have no changes.

          The groups are returned in the same format as *note
          get_opcodes(): f40.

      -- Method: ratio ()

          Return a measure of the sequences’ similarity as a float in
          the range [0, 1].

          Where T is the total number of elements in both sequences, and
          M is the number of matches, this is 2.0*M / T. Note that this
          is ‘1.0’ if the sequences are identical, and ‘0.0’ if they
          have nothing in common.

          This is expensive to compute if *note get_matching_blocks():
          f3f. or *note get_opcodes(): f40. hasn’t already been called,
          in which case you may want to try *note quick_ratio(): f43. or
          *note real_quick_ratio(): f44. first to get an upper bound.

      -- Method: quick_ratio ()

          Return an upper bound on *note ratio(): f42. relatively
          quickly.

      -- Method: real_quick_ratio ()

          Return an upper bound on *note ratio(): f42. very quickly.

The three methods that return the ratio of matching to total characters
can give different results due to differing levels of approximation,
although ‘quick_ratio()’ and ‘real_quick_ratio()’ are always at least as
large as ‘ratio()’:

     >>> s = SequenceMatcher(None, "abcd", "bcde")
     >>> s.ratio()
     0.75
     >>> s.quick_ratio()
     0.75
     >>> s.real_quick_ratio()
     1.0


File: python.info,  Node: SequenceMatcher Examples,  Next: Differ Objects,  Prev: SequenceMatcher Objects,  Up: difflib --- Helpers for computing deltas

5.6.3.2 SequenceMatcher Examples
................................

This example compares two strings, considering blanks to be "junk":

     >>> s = SequenceMatcher(lambda x: x == " ",
     ...                     "private Thread currentThread;",
     ...                     "private volatile Thread currentThread;")

‘ratio()’ returns a float in [0, 1], measuring the similarity of the
sequences.  As a rule of thumb, a ‘ratio()’ value over 0.6 means the
sequences are close matches:

     >>> print(round(s.ratio(), 3))
     0.866

If you’re only interested in where the sequences match,
‘get_matching_blocks()’ is handy:

     >>> for block in s.get_matching_blocks():
     ...     print("a[%d] and b[%d] match for %d elements" % block)
     a[0] and b[0] match for 8 elements
     a[8] and b[17] match for 21 elements
     a[29] and b[38] match for 0 elements

Note that the last tuple returned by ‘get_matching_blocks()’ is always a
dummy, ‘(len(a), len(b), 0)’, and this is the only case in which the
last tuple element (number of elements matched) is ‘0’.

If you want to know how to change the first sequence into the second,
use ‘get_opcodes()’:

     >>> for opcode in s.get_opcodes():
     ...     print("%6s a[%d:%d] b[%d:%d]" % opcode)
      equal a[0:8] b[0:8]
     insert a[8:8] b[8:17]
      equal a[8:29] b[17:38]

See also
........

   * The *note get_close_matches(): f32. function in this module which
     shows how simple code building on *note SequenceMatcher: 30a. can
     be used to do useful work.

   * Simple version control recipe(1) for a small application built with
     *note SequenceMatcher: 30a.

   ---------- Footnotes ----------

   (1) http://code.activestate.com/recipes/576729/


File: python.info,  Node: Differ Objects,  Next: Differ Example,  Prev: SequenceMatcher Examples,  Up: difflib --- Helpers for computing deltas

5.6.3.3 Differ Objects
......................

Note that *note Differ: f29.-generated deltas make no claim to be
`minimal' diffs.  To the contrary, minimal diffs are often
counter-intuitive, because they synch up anywhere possible, sometimes
accidental matches 100 pages apart.  Restricting synch points to
contiguous matches preserves some notion of locality, at the occasional
cost of producing a longer diff.

The *note Differ: f29. class has this constructor:

 -- Class: difflib.Differ (linejunk=None, charjunk=None)

     Optional keyword parameters `linejunk' and `charjunk' are for
     filter functions (or ‘None’):

     `linejunk': A function that accepts a single string argument, and
     returns true if the string is junk.  The default is ‘None’, meaning
     that no line is considered junk.

     `charjunk': A function that accepts a single character argument (a
     string of length 1), and returns true if the character is junk.
     The default is ‘None’, meaning that no character is considered
     junk.

     *note Differ: f29. objects are used (deltas generated) via a single
     method:

      -- Method: compare (a, b)

          Compare two sequences of lines, and generate the delta (a
          sequence of lines).

          Each sequence must contain individual single-line strings
          ending with newlines.  Such sequences can be obtained from the
          *note readlines(): f2f. method of file-like objects.  The
          delta generated also consists of newline-terminated strings,
          ready to be printed as-is via the *note writelines(): f30.
          method of a file-like object.


File: python.info,  Node: Differ Example,  Next: A command-line interface to difflib,  Prev: Differ Objects,  Up: difflib --- Helpers for computing deltas

5.6.3.4 Differ Example
......................

This example compares two texts.  First we set up the texts, sequences
of individual single-line strings ending with newlines (such sequences
can also be obtained from the ‘readlines()’ method of file-like
objects):

     >>> text1 = '''  1. Beautiful is better than ugly.
     ...   2. Explicit is better than implicit.
     ...   3. Simple is better than complex.
     ...   4. Complex is better than complicated.
     ... '''.splitlines(keepends=True)
     >>> len(text1)
     4
     >>> text1[0][-1]
     '\n'
     >>> text2 = '''  1. Beautiful is better than ugly.
     ...   3.   Simple is better than complex.
     ...   4. Complicated is better than complex.
     ...   5. Flat is better than nested.
     ... '''.splitlines(keepends=True)

Next we instantiate a Differ object:

     >>> d = Differ()

Note that when instantiating a *note Differ: f29. object we may pass
functions to filter out line and character "junk."  See the *note
Differ(): f29. constructor for details.

Finally, we compare the two:

     >>> result = list(d.compare(text1, text2))

‘result’ is a list of strings, so let’s pretty-print it:

     >>> from pprint import pprint
     >>> pprint(result)
     ['    1. Beautiful is better than ugly.\n',
      '-   2. Explicit is better than implicit.\n',
      '-   3. Simple is better than complex.\n',
      '+   3.   Simple is better than complex.\n',
      '?     ++\n',
      '-   4. Complex is better than complicated.\n',
      '?            ^                     ---- ^\n',
      '+   4. Complicated is better than complex.\n',
      '?           ++++ ^                      ^\n',
      '+   5. Flat is better than nested.\n']

As a single multi-line string it looks like this:

     >>> import sys
     >>> sys.stdout.writelines(result)
         1. Beautiful is better than ugly.
     -   2. Explicit is better than implicit.
     -   3. Simple is better than complex.
     +   3.   Simple is better than complex.
     ?     ++
     -   4. Complex is better than complicated.
     ?            ^                     ---- ^
     +   4. Complicated is better than complex.
     ?           ++++ ^                      ^
     +   5. Flat is better than nested.


File: python.info,  Node: A command-line interface to difflib,  Prev: Differ Example,  Up: difflib --- Helpers for computing deltas

5.6.3.5 A command-line interface to difflib
...........................................

This example shows how to use difflib to create a ‘diff’-like utility.
It is also contained in the Python source distribution, as
‘Tools/scripts/diff.py’.

     """ Command line interface to difflib.py providing diffs in four formats:

     * ndiff:    lists every line and highlights interline changes.
     * context:  highlights clusters of changes in a before/after format.
     * unified:  highlights clusters of changes in an inline format.
     * html:     generates side by side comparison with change highlights.

     """

     import sys, os, time, difflib, optparse

     def main():
          # Configure the option parser
         usage = "usage: %prog [options] fromfile tofile"
         parser = optparse.OptionParser(usage)
         parser.add_option("-c", action="store_true", default=False,
                           help='Produce a context format diff (default)')
         parser.add_option("-u", action="store_true", default=False,
                           help='Produce a unified format diff')
         hlp = 'Produce HTML side by side diff (can use -c and -l in conjunction)'
         parser.add_option("-m", action="store_true", default=False, help=hlp)
         parser.add_option("-n", action="store_true", default=False,
                           help='Produce a ndiff format diff')
         parser.add_option("-l", "--lines", type="int", default=3,
                           help='Set number of context lines (default 3)')
         (options, args) = parser.parse_args()

         if len(args) == 0:
             parser.print_help()
             sys.exit(1)
         if len(args) != 2:
             parser.error("need to specify both a fromfile and tofile")

         n = options.lines
         fromfile, tofile = args # as specified in the usage string

         # we're passing these as arguments to the diff function
         fromdate = time.ctime(os.stat(fromfile).st_mtime)
         todate = time.ctime(os.stat(tofile).st_mtime)
         with open(fromfile) as fromf, open(tofile) as tof:
             fromlines, tolines = list(fromf), list(tof)

         if options.u:
             diff = difflib.unified_diff(fromlines, tolines, fromfile, tofile,
                                         fromdate, todate, n=n)
         elif options.n:
             diff = difflib.ndiff(fromlines, tolines)
         elif options.m:
             diff = difflib.HtmlDiff().make_file(fromlines, tolines, fromfile,
                                                 tofile, context=options.c,
                                                 numlines=n)
         else:
             diff = difflib.context_diff(fromlines, tolines, fromfile, tofile,
                                         fromdate, todate, n=n)

         # we're using writelines because diff is a generator
         sys.stdout.writelines(diff)

     if __name__ == '__main__':
         main()


File: python.info,  Node: textwrap --- Text wrapping and filling,  Next: unicodedata --- Unicode Database,  Prev: difflib --- Helpers for computing deltas,  Up: Text Processing Services

5.6.4 ‘textwrap’ — Text wrapping and filling
--------------------------------------------

`Source code:' Lib/textwrap.py(1)

__________________________________________________________________

The *note textwrap: 102. module provides some convenience functions, as
well as *note TextWrapper: 289, the class that does all the work.  If
you’re just wrapping or filling one or two text strings, the convenience
functions should be good enough; otherwise, you should use an instance
of *note TextWrapper: 289. for efficiency.

 -- Function: textwrap.wrap (text, width=70, **kwargs)

     Wraps the single paragraph in `text' (a string) so every line is at
     most `width' characters long.  Returns a list of output lines,
     without final newlines.

     Optional keyword arguments correspond to the instance attributes of
     *note TextWrapper: 289, documented below.  `width' defaults to
     ‘70’.

     See the *note TextWrapper.wrap(): f4f. method for additional
     details on how *note wrap(): f4e. behaves.

 -- Function: textwrap.fill (text, width=70, **kwargs)

     Wraps the single paragraph in `text', and returns a single string
     containing the wrapped paragraph.  *note fill(): f50. is shorthand
     for

          "\n".join(wrap(text, ...))

     In particular, *note fill(): f50. accepts exactly the same keyword
     arguments as *note wrap(): f4e.

 -- Function: textwrap.shorten (text, width, **kwargs)

     Collapse and truncate the given `text' to fit in the given `width'.

     First the whitespace in `text' is collapsed (all whitespace is
     replaced by single spaces).  If the result fits in the `width', it
     is returned.  Otherwise, enough words are dropped from the end so
     that the remaining words plus the ‘placeholder’ fit within ‘width’:

          >>> textwrap.shorten("Hello  world!", width=12)
          'Hello world!'
          >>> textwrap.shorten("Hello  world!", width=11)
          'Hello [...]'
          >>> textwrap.shorten("Hello world", width=10, placeholder="...")
          'Hello...'

     Optional keyword arguments correspond to the instance attributes of
     *note TextWrapper: 289, documented below.  Note that the whitespace
     is collapsed before the text is passed to the *note TextWrapper:
     289. *note fill(): f50. function, so changing the value of *note
     tabsize: f51, *note expand_tabs: f52, *note drop_whitespace: f53,
     and *note replace_whitespace: f54. will have no effect.

     New in version 3.4.

 -- Function: textwrap.dedent (text)

     Remove any common leading whitespace from every line in `text'.

     This can be used to make triple-quoted strings line up with the
     left edge of the display, while still presenting them in the source
     code in indented form.

     Note that tabs and spaces are both treated as whitespace, but they
     are not equal: the lines ‘" hello"’ and ‘"\thello"’ are considered
     to have no common leading whitespace.

     For example:

          def test():
              # end first line with \ to avoid the empty line!
              s = '''\
              hello
                world
              '''
              print(repr(s))          # prints '    hello\n      world\n    '
              print(repr(dedent(s)))  # prints 'hello\n  world\n'

 -- Function: textwrap.indent (text, prefix, predicate=None)

     Add `prefix' to the beginning of selected lines in `text'.

     Lines are separated by calling ‘text.splitlines(True)’.

     By default, `prefix' is added to all lines that do not consist
     solely of whitespace (including any line endings).

     For example:

          >>> s = 'hello\n\n \nworld'
          >>> indent(s, '  ')
          '  hello\n\n \n  world'

     The optional `predicate' argument can be used to control which
     lines are indented.  For example, it is easy to add `prefix' to
     even empty and whitespace-only lines:

          >>> print(indent(s, '+ ', lambda line: True))
          + hello
          +
          +
          + world

     New in version 3.3.

*note wrap(): f4e, *note fill(): f50. and *note shorten(): 28c. work by
creating a *note TextWrapper: 289. instance and calling a single method
on it.  That instance is not reused, so for applications that process
many text strings using *note wrap(): f4e. and/or *note fill(): f50, it
may be more efficient to create your own *note TextWrapper: 289. object.

Text is preferably wrapped on whitespaces and right after the hyphens in
hyphenated words; only then will long words be broken if necessary,
unless *note TextWrapper.break_long_words: f56. is set to false.

 -- Class: textwrap.TextWrapper (**kwargs)

     The *note TextWrapper: 289. constructor accepts a number of
     optional keyword arguments.  Each keyword argument corresponds to
     an instance attribute, so for example

          wrapper = TextWrapper(initial_indent="* ")

     is the same as

          wrapper = TextWrapper()
          wrapper.initial_indent = "* "

     You can re-use the same *note TextWrapper: 289. object many times,
     and you can change any of its options through direct assignment to
     instance attributes between uses.

     The *note TextWrapper: 289. instance attributes (and keyword
     arguments to the constructor) are as follows:

      -- Attribute: width

          (default: ‘70’) The maximum length of wrapped lines.  As long
          as there are no individual words in the input text longer than
          *note width: f57, *note TextWrapper: 289. guarantees that no
          output line will be longer than *note width: f57. characters.

      -- Attribute: expand_tabs

          (default: ‘True’) If true, then all tab characters in `text'
          will be expanded to spaces using the ‘expandtabs()’ method of
          `text'.

      -- Attribute: tabsize

          (default: ‘8’) If *note expand_tabs: f52. is true, then all
          tab characters in `text' will be expanded to zero or more
          spaces, depending on the current column and the given tab
          size.

          New in version 3.3.

      -- Attribute: replace_whitespace

          (default: ‘True’) If true, after tab expansion but before
          wrapping, the *note wrap(): f4e. method will replace each
          whitespace character with a single space.  The whitespace
          characters replaced are as follows: tab, newline, vertical
          tab, formfeed, and carriage return (‘'\t\n\v\f\r'’).

               Note: If *note expand_tabs: f52. is false and *note
               replace_whitespace: f54. is true, each tab character will
               be replaced by a single space, which is `not' the same as
               tab expansion.

               Note: If *note replace_whitespace: f54. is false,
               newlines may appear in the middle of a line and cause
               strange output.  For this reason, text should be split
               into paragraphs (using *note str.splitlines(): e01. or
               similar) which are wrapped separately.

      -- Attribute: drop_whitespace

          (default: ‘True’) If true, whitespace at the beginning and
          ending of every line (after wrapping but before indenting) is
          dropped.  Whitespace at the beginning of the paragraph,
          however, is not dropped if non-whitespace follows it.  If
          whitespace being dropped takes up an entire line, the whole
          line is dropped.

      -- Attribute: initial_indent

          (default: ‘''’) String that will be prepended to the first
          line of wrapped output.  Counts towards the length of the
          first line.  The empty string is not indented.

      -- Attribute: subsequent_indent

          (default: ‘''’) String that will be prepended to all lines of
          wrapped output except the first.  Counts towards the length of
          each line except the first.

      -- Attribute: fix_sentence_endings

          (default: ‘False’) If true, *note TextWrapper: 289. attempts
          to detect sentence endings and ensure that sentences are
          always separated by exactly two spaces.  This is generally
          desired for text in a monospaced font.  However, the sentence
          detection algorithm is imperfect: it assumes that a sentence
          ending consists of a lowercase letter followed by one of
          ‘'.'’, ‘'!'’, or ‘'?'’, possibly followed by one of ‘'"'’ or
          ‘"'"’, followed by a space.  One problem with this is
          algorithm is that it is unable to detect the difference
          between "Dr."  in

               [...] Dr. Frankenstein's monster [...]

          and "Spot."  in

               [...] See Spot. See Spot run [...]

          *note fix_sentence_endings: f5a. is false by default.

          Since the sentence detection algorithm relies on
          ‘string.lowercase’ for the definition of "lowercase letter,"
          and a convention of using two spaces after a period to
          separate sentences on the same line, it is specific to
          English-language texts.

      -- Attribute: break_long_words

          (default: ‘True’) If true, then words longer than *note width:
          f57. will be broken in order to ensure that no lines are
          longer than *note width: f57.  If it is false, long words will
          not be broken, and some lines may be longer than *note width:
          f57.  (Long words will be put on a line by themselves, in
          order to minimize the amount by which *note width: f57. is
          exceeded.)

      -- Attribute: break_on_hyphens

          (default: ‘True’) If true, wrapping will occur preferably on
          whitespaces and right after hyphens in compound words, as it
          is customary in English.  If false, only whitespaces will be
          considered as potentially good places for line breaks, but you
          need to set *note break_long_words: f56. to false if you want
          truly insecable words.  Default behaviour in previous versions
          was to always allow breaking hyphenated words.

      -- Attribute: max_lines

          (default: ‘None’) If not ‘None’, then the output will contain
          at most `max_lines' lines, with `placeholder' appearing at the
          end of the output.

          New in version 3.4.

      -- Attribute: placeholder

          (default: ‘' [...]'’) String that will appear at the end of
          the output text if it has been truncated.

          New in version 3.4.

     *note TextWrapper: 289. also provides some public methods,
     analogous to the module-level convenience functions:

      -- Method: wrap (text)

          Wraps the single paragraph in `text' (a string) so every line
          is at most *note width: f57. characters long.  All wrapping
          options are taken from instance attributes of the *note
          TextWrapper: 289. instance.  Returns a list of output lines,
          without final newlines.  If the wrapped output has no content,
          the returned list is empty.

      -- Method: fill (text)

          Wraps the single paragraph in `text', and returns a single
          string containing the wrapped paragraph.

   ---------- Footnotes ----------

   (1) https://hg.python.org/cpython/file/3.4/Lib/textwrap.py


File: python.info,  Node: unicodedata --- Unicode Database,  Next: stringprep --- Internet String Preparation,  Prev: textwrap --- Text wrapping and filling,  Up: Text Processing Services

5.6.5 ‘unicodedata’ — Unicode Database
--------------------------------------

This module provides access to the Unicode Character Database (UCD)
which defines character properties for all Unicode characters.  The data
contained in this database is compiled from the UCD version 6.3.0(1).

The module uses the same names and symbols as defined by Unicode
Standard Annex #44, "Unicode Character Database"(2).  It defines the
following functions:

 -- Function: unicodedata.lookup (name)

     Look up character by name.  If a character with the given name is
     found, return the corresponding character.  If not found, *note
     KeyError: 706. is raised.

     Changed in version 3.3: Support for name aliases (3) and named
     sequences (4) has been added.

 -- Function: unicodedata.name (chr[, default])

     Returns the name assigned to the character `chr' as a string.  If
     no name is defined, `default' is returned, or, if not given, *note
     ValueError: 321. is raised.

 -- Function: unicodedata.decimal (chr[, default])

     Returns the decimal value assigned to the character `chr' as
     integer.  If no such value is defined, `default' is returned, or,
     if not given, *note ValueError: 321. is raised.

 -- Function: unicodedata.digit (chr[, default])

     Returns the digit value assigned to the character `chr' as integer.
     If no such value is defined, `default' is returned, or, if not
     given, *note ValueError: 321. is raised.

 -- Function: unicodedata.numeric (chr[, default])

     Returns the numeric value assigned to the character `chr' as float.
     If no such value is defined, `default' is returned, or, if not
     given, *note ValueError: 321. is raised.

 -- Function: unicodedata.category (chr)

     Returns the general category assigned to the character `chr' as
     string.

 -- Function: unicodedata.bidirectional (chr)

     Returns the bidirectional class assigned to the character `chr' as
     string.  If no such value is defined, an empty string is returned.

 -- Function: unicodedata.combining (chr)

     Returns the canonical combining class assigned to the character
     `chr' as integer.  Returns ‘0’ if no combining class is defined.

 -- Function: unicodedata.east_asian_width (chr)

     Returns the east asian width assigned to the character `chr' as
     string.

 -- Function: unicodedata.mirrored (chr)

     Returns the mirrored property assigned to the character `chr' as
     integer.  Returns ‘1’ if the character has been identified as a
     "mirrored" character in bidirectional text, ‘0’ otherwise.

 -- Function: unicodedata.decomposition (chr)

     Returns the character decomposition mapping assigned to the
     character `chr' as string.  An empty string is returned in case no
     such mapping is defined.

 -- Function: unicodedata.normalize (form, unistr)

     Return the normal form `form' for the Unicode string `unistr'.
     Valid values for `form' are ’NFC’, ’NFKC’, ’NFD’, and ’NFKD’.

     The Unicode standard defines various normalization forms of a
     Unicode string, based on the definition of canonical equivalence
     and compatibility equivalence.  In Unicode, several characters can
     be expressed in various way.  For example, the character U+00C7
     (LATIN CAPITAL LETTER C WITH CEDILLA) can also be expressed as the
     sequence U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING
     CEDILLA).

     For each character, there are two normal forms: normal form C and
     normal form D. Normal form D (NFD) is also known as canonical
     decomposition, and translates each character into its decomposed
     form.  Normal form C (NFC) first applies a canonical decomposition,
     then composes pre-combined characters again.

     In addition to these two forms, there are two additional normal
     forms based on compatibility equivalence.  In Unicode, certain
     characters are supported which normally would be unified with other
     characters.  For example, U+2160 (ROMAN NUMERAL ONE) is really the
     same thing as U+0049 (LATIN CAPITAL LETTER I). However, it is
     supported in Unicode for compatibility with existing character sets
     (e.g.  gb2312).

     The normal form KD (NFKD) will apply the compatibility
     decomposition, i.e.  replace all compatibility characters with
     their equivalents.  The normal form KC (NFKC) first applies the
     compatibility decomposition, followed by the canonical composition.

     Even if two unicode strings are normalized and look the same to a
     human reader, if one has combining characters and the other
     doesn’t, they may not compare equal.

In addition, the module exposes the following constant:

 -- Data: unicodedata.unidata_version

     The version of the Unicode database used in this module.

 -- Data: unicodedata.ucd_3_2_0

     This is an object that has the same methods as the entire module,
     but uses the Unicode database version 3.2 instead, for applications
     that require this specific version of the Unicode database (such as
     IDNA).

Examples:

     >>> import unicodedata
     >>> unicodedata.lookup('LEFT CURLY BRACKET')
     '{'
     >>> unicodedata.name('/')
     'SOLIDUS'
     >>> unicodedata.decimal('9')
     9
     >>> unicodedata.decimal('a')
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     ValueError: not a decimal
     >>> unicodedata.category('A')  # 'L'etter, 'u'ppercase
     'Lu'
     >>> unicodedata.bidirectional('\u0660') # 'A'rabic, 'N'umber
     'AN'

   ---------- Footnotes ----------

   (1) http://www.unicode.org/Public/6.3.0/ucd

   (2) http://www.unicode.org/reports/tr44/tr44-6.html

   (3) ‘http://www.unicode.org/Public/6.3.0/ucd/NameAliases.txt’

   (4) ‘http://www.unicode.org/Public/6.3.0/ucd/NamedSequences.txt’


File: python.info,  Node: stringprep --- Internet String Preparation,  Next: readline --- GNU readline interface,  Prev: unicodedata --- Unicode Database,  Up: Text Processing Services

5.6.6 ‘stringprep’ — Internet String Preparation
------------------------------------------------

When identifying things (such as host names) in the internet, it is
often necessary to compare such identifications for "equality".  Exactly
how this comparison is executed may depend on the application domain,
e.g.  whether it should be case-insensitive or not.  It may be also
necessary to restrict the possible identifications, to allow only
identifications consisting of "printable" characters.

RFC 3454(1) defines a procedure for "preparing" Unicode strings in
internet protocols.  Before passing strings onto the wire, they are
processed with the preparation procedure, after which they have a
certain normalized form.  The RFC defines a set of tables, which can be
combined into profiles.  Each profile must define which tables it uses,
and what other optional parts of the ‘stringprep’ procedure are part of
the profile.  One example of a ‘stringprep’ profile is ‘nameprep’, which
is used for internationalized domain names.

The module *note stringprep: f2. only exposes the tables from RFC 3454.
As these tables would be very large to represent them as dictionaries or
lists, the module uses the Unicode character database internally.  The
module source code itself was generated using the ‘mkstringprep.py’
utility.

As a result, these tables are exposed as functions, not as data
structures.  There are two kinds of tables in the RFC: sets and
mappings.  For a set, *note stringprep: f2. provides the "characteristic
function", i.e.  a function that returns true if the parameter is part
of the set.  For mappings, it provides the mapping function: given the
key, it returns the associated value.  Below is a list of all functions
available in the module.

 -- Function: stringprep.in_table_a1 (code)

     Determine whether `code' is in tableA.1 (Unassigned code points in
     Unicode 3.2).

 -- Function: stringprep.in_table_b1 (code)

     Determine whether `code' is in tableB.1 (Commonly mapped to
     nothing).

 -- Function: stringprep.map_table_b2 (code)

     Return the mapped value for `code' according to tableB.2 (Mapping
     for case-folding used with NFKC).

 -- Function: stringprep.map_table_b3 (code)

     Return the mapped value for `code' according to tableB.3 (Mapping
     for case-folding used with no normalization).

 -- Function: stringprep.in_table_c11 (code)

     Determine whether `code' is in tableC.1.1 (ASCII space characters).

 -- Function: stringprep.in_table_c12 (code)

     Determine whether `code' is in tableC.1.2 (Non-ASCII space
     characters).

 -- Function: stringprep.in_table_c11_c12 (code)

     Determine whether `code' is in tableC.1 (Space characters, union of
     C.1.1 and C.1.2).

 -- Function: stringprep.in_table_c21 (code)

     Determine whether `code' is in tableC.2.1 (ASCII control
     characters).

 -- Function: stringprep.in_table_c22 (code)

     Determine whether `code' is in tableC.2.2 (Non-ASCII control
     characters).

 -- Function: stringprep.in_table_c21_c22 (code)

     Determine whether `code' is in tableC.2 (Control characters, union
     of C.2.1 and C.2.2).

 -- Function: stringprep.in_table_c3 (code)

     Determine whether `code' is in tableC.3 (Private use).

 -- Function: stringprep.in_table_c4 (code)

     Determine whether `code' is in tableC.4 (Non-character code
     points).

 -- Function: stringprep.in_table_c5 (code)

     Determine whether `code' is in tableC.5 (Surrogate codes).

 -- Function: stringprep.in_table_c6 (code)

     Determine whether `code' is in tableC.6 (Inappropriate for plain
     text).

 -- Function: stringprep.in_table_c7 (code)

     Determine whether `code' is in tableC.7 (Inappropriate for
     canonical representation).

 -- Function: stringprep.in_table_c8 (code)

     Determine whether `code' is in tableC.8 (Change display properties
     or are deprecated).

 -- Function: stringprep.in_table_c9 (code)

     Determine whether `code' is in tableC.9 (Tagging characters).

 -- Function: stringprep.in_table_d1 (code)

     Determine whether `code' is in tableD.1 (Characters with
     bidirectional property "R" or "AL").

 -- Function: stringprep.in_table_d2 (code)

     Determine whether `code' is in tableD.2 (Characters with
     bidirectional property "L").

   ---------- Footnotes ----------

   (1) https://tools.ietf.org/html/rfc3454.html

